{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Eduardo Furlan","text":"<p>I am a PhD student at the National Institute for Space Research (INPE), within the Postgraduate Program in Applied Computing (CAP). My research field is High Performance Computing (HPC), advised by Stephan Stephany and Roberto Souto, focusing on the solution of advanced scientific and engineering problems. I earned my MSc in Applied Computing from INPE in 2022, and I also teach undergraduate courses, bringing extensive experience from the industrial engineering field.</p> <p> Lattes ORCID Google Scholar Zenodo Linkedin Github </p>"},{"location":"#updates","title":"Updates","text":"<ul> <li>Dez 2025: Renewal of the AMPEMI project at SDumont.</li> <li>Oct 2025: Paper accepted at CIACA.</li> <li>Aug 2024: Approved in the Exam Proposal at INPE.</li> <li>May 2024: Approved in the Qualification Proposal at INPE.</li> <li>Feb 2023: I started my PhD at INPE.</li> <li>Mar 2022: I graduated from my MSc.</li> <li>Jul 2021: Paper accepted at BreSci.</li> <li>Jun 2021: Paper accepted at Revista Cereus.</li> <li>Feb 2019: I started my MSc at INPE.</li> </ul>"},{"location":"#research-interests","title":"Research interests","text":"<ul> <li>New technologies and methods applied in HPC.</li> <li>Solution of scientific and engineering problems using HPC.</li> </ul>"},{"location":"#projects","title":"Projects","text":"<ul> <li>PIML - application of physics-based machine learning in solving scientific problems.</li> <li>MPI-based HPC Approaches - use of recent high-performance computing resources in solving scientific problems.</li> </ul> <p>More information can be found on the research page.</p>"},{"location":"#teaching","title":"Teaching","text":"<p>I teach undergraduate classes in engineering and computing courses, where I try to conduct classes in order to bring reflections on the practical experience of the profession, working on the relationship between the professional and academic performance of the student, stimulating critical thinking based on specialized literature, and encouraging the production of knowledge.</p>"},{"location":"#industrial-experience","title":"Industrial experience","text":"<p>I have 15+ years of experience in the packaging, machinery, automotive, and engineering design sectors. I worked in the areas of production and final assembly in the automotive industry, manufacturing of industrial machinery and equipment, and industrial engineering in the packaging industry.</p>"},{"location":"#address","title":"Address","text":"<p>National Institute for Space Research (INPE) 1758 Astronautas Avenue S\u00e3o Jos\u00e9 dos Campos, SP 12210-000  </p>"},{"location":"#contact","title":"Contact","text":"<p>\u2709  mailto:efurlanm@gmail.com</p>"},{"location":"courses/","title":"Courses","text":"<p>List of courses I took at INPE.</p> <p>The following links point to repositories containing my personal notes and assignments.</p> <ul> <li>Computational Mathematics (CAP 239)</li> <li>Neurocomputing (CAP 351)</li> <li>Data Mining Principles and Applications (CAP 359)</li> <li>High Performance Computing (CAP 372)</li> <li>Earth Observation Topics (CAP 378)</li> <li>Topics in Spatial Science (CAP 379)</li> <li>Topics in Space Technologies (CAP 382)</li> <li>\u200b\u200bFundamentals of Structured Programming (CAP 390)</li> <li>Introduction to Data Science (CAP 394)</li> <li>Massively Parallel Systems Programming (CAP 399)</li> <li>Numerical Methods I (CAP 418)</li> <li>Deep Learning (CAP 421)</li> <li>Advanced Topics in Environmental Modeling (CAP 425)</li> </ul>"},{"location":"courses/#seminars-at-inpe","title":"Seminars at INPE","text":"<p>Some seminars that I participated as part of the course at INPE</p> <p>(in construction)</p> <ul> <li>BEISL, C. H. Detec\u00e7\u00e3o de manchas de \u00f3leo no mar com imagens SAR e IA. [Seminar]. YouTube, 2022. Available at: https://youtu.be/S57JsFH-3yo.</li> <li>CAMPAIGNO, A. S. L. de O. Use of complex networks in automatic detection, diagnosis and classification of Alzheimer\u2019s disease. [Seminar]. YouTube, 2022. Available at: https://youtu.be/AeaNkL_Z-cI.</li> <li>CATSUMI, O. Projeto de arquitetura de seguran\u00e7a de sistemas embarcados. [Seminar]. YouTube, 2022. Available at: https://youtu.be/hQQfv9K239A.</li> <li>FREITAS, S. R. MONAN: A new paradigm of focus and organization for the advance of the numerical prediction of time, climate and environment in Brazil. [Seminar]. YouTube, 2022. Available at: https://youtu.be/48eut2vWzvQ.</li> <li>FRERY, A. Como ter sucesso com publica\u00e7\u00f5es cient\u00edficas. [Seminar]. YouTube, 2023. Available at: https://youtu.be/EoBpKMXvCJ0.</li> <li>GHEYI, R. Testing Refactoring Implementations. [Seminar]. YouTube, 2022. Available at: https://youtu.be/huV6HDdTdOk.</li> <li>HERBERT, J. Sa\u00fade Digital Aplicada \u00e0s Miss\u00f5es Espaciais. [Seminar]. YouTube, 2022. Available at: https://youtu.be/M4vn_wmB9KE.</li> <li>KRUG, T. What does science predict for the future of the climate? [Seminar]. YouTube, 2022. Available at: https://youtu.be/lZgjOLAnAkM.</li> <li>KUCK, T. Machine learning techniques applied to SAR images for detecting selective logging in the Brazilian Amazon. [Seminar]. YouTube, 2022. Available at: https://youtu.be/X_s8PBu2pZY.</li> <li>LAGE, C. Aplica\u00e7\u00f5es de Intelig\u00eancia Artificial em Maritime Domain Awareness. [Seminar]. YouTube, 2022. Available at: https://youtu.be/rdiqi3lqYOQ.</li> <li>NATALINO, C. Network automation: Enablers and challenges. [Seminar]. YouTube, 2022. Available at: https://youtu.be/m2tiMCMD3JI.</li> <li>REBELO, L. Architectures in the Space Domain with AI and DevOps. [Seminar]. YouTube, 2023. Available at: https://youtu.be/xURMiY57SWU.</li> <li>ROMANO, R. Transforma\u00e7\u00e3o Digital e o Impacto nas Cidades e nos Neg\u00f3cios. [Seminar]. YouTube, 2022. Available at: https://youtu.be/j--7HTMw0D0.</li> <li>SANTOS, J. C. da S. Challenges in Engineering Secure Software Systems. [Seminar]. YouTube, 2022. Available at: https://youtu.be/DVBCkBXyqj0.</li> <li>SILVA, G. A. da. Partnerships between Companies and Research Institutions: Cooperation for innovation. [Seminar]. YouTube, 2021. Available at: https://youtu.be/8G-E6bWT42k.</li> <li>SILVA, N. Ve\u00edculos A\u00e9reos N\u00e3o Tripulados e sua autonomia de opera\u00e7\u00e3o. [Seminar]. YouTube, 2022. Available at: https://youtu.be/yVIrjVQvVUo.</li> </ul>"},{"location":"engineering/","title":"Engineering","text":""},{"location":"engineering/#specialist-in-industrial-engineering-and-operations","title":"Specialist in Industrial Engineering and Operations","text":"<p>My professional trajectory and academic background converge in the field of Industrial Engineering and Operations, with a focus on Project Development, Infrastructure Construction, Automation Systems, Maintenance Strategies, and the Assurance of Production Line Reliability. My expertise is built upon extensive practical experience gained across diverse industrial sectors, including Machinery, Automotive, Beverage Packaging, and Engineering (at companies such as Engepack, Volkswagen, Siemens Dematic, and MAN Ferrostaal). This practical foundation is complemented by a solid academic background, fostering a commitment to technical rigor, methodological application, and continuous learning.</p>"},{"location":"engineering/#my-areas-of-specialization-and-interest","title":"My Areas of Specialization and Interest","text":"<ul> <li>Methodologies for Industrial Project Management and Execution: covering the lifecycle from initial conceptualization and feasibility assessment (technical and economic) through planning, control, commissioning, and final acceptance.</li> <li>Process Automation and Control Systems: design, implementation, integration, and troubleshooting of automated systems, robotics, and complex industrial machinery, including advanced handling and warehousing solutions.</li> <li>Industrial Infrastructure Development: participation and leadership in construction, expansion, and significant maintenance projects for industrial plants, coordinating multidisciplinary engineering efforts (Electrical, Automation, Instrumentation, Civil).</li> <li>Operational Reliability and Maintenance Engineering: analysis and implementation of strategies to enhance the robustness and performance of production assets and processes.</li> <li>Optimization Techniques for Industrial Systems: application of methodologies for process improvement, efficiency gains, and data-driven decision-making based on industrial databases.</li> <li>Introduction of New Technologies and Products: methodologies for integrating new systems and products into existing industrial environments.</li> <li>Technical Team Leadership and Development: coordination and guidance of multidisciplinary technical teams in project and operational settings.</li> </ul> <p>My experience highlights include comprehensive involvement in defining project parameters, rigorous schedule and cost control, development of technical specifications and procedures, and meticulous execution of testing and commissioning phases. I have contributed to the design and implementation of complex automation solutions, including specialized sorting and automated warehousing systems. Furthermore, my work in manufacturing, particularly within the plastic packaging sector, has emphasized operational excellence, process optimization, and seamless integration of IT with factory floor activities.</p>"},{"location":"engineering/#academic-and-professional-credentials","title":"Academic and Professional Credentials","text":"<ul> <li>Electrical Production Engineer</li> <li>Specialization in Power Systems</li> <li>MBA in Strategic and Economic Project Management (FGV SP)</li> <li>Background as an Electromechanical Technician</li> <li>Fluent in English and Spanish</li> </ul> <p>This profile reflects a blend of theoretical knowledge and practical application, aiming to contribute to the advancement and effective implementation of solutions in complex industrial environments.</p>"},{"location":"engineering/#contact","title":"Contact","text":"<p>\u2709\ufe0f mailto:efurlanm@gmail.com</p>"},{"location":"notes/","title":"Notes","text":"<p>On research, technology, scientific computing, and engineering.</p>"},{"location":"notes/#works","title":"Works","text":"<p>This section includes some of the work I have completed for my own use, for postgraduate coursework, and for my classes. The research page contains works pertaining to my research activity. The following items are not ordered.</p> <ul> <li> <p>PD1B24 - repository containing code, data, manuscripts, and other files used in my research on PIML for the Qualifying and Proposal Exams.</p> </li> <li> <p>MSC22 - repository containing the research material generated for my master's degree.</p> </li> <li> <p>PINN Discovery - repository containing my work on data-driven parameter discovery of a 1D Burgers' equation using a physics-informed neural network. There is also an online HTML version of the manuscript.</p> </li> <li> <p>PINN GQM - repository containing my work related to solving the Burgers' equation using two methods, physics-informed neural network and Gaussian quadrature. There is also an online HTML version of the manuscript.</p> </li> <li> <p>Stencil - comparison of high-performance computing approaches in the Python environment for a five-point Stencil test problem. There is also an online HTML version of the manuscript.</p> </li> <li> <p>TAMA21 - repository containing a work developed for presentations in courses, on examples of HPC approaches in a Python environment for a 5-point stencil testing problem, executed on the Santos Dumont supercomputer and also on Google Colab.</p> </li> <li> <p>ML - repository containing my personal notes on Machine Learning and related topics.</p> </li> <li> <p>CNN &amp; MLP - repository containing my notes on the CAP 351 course, and also the manuscript generated from the work, entitled \"Comparison of CNN and MLP artificial neural network models, for an optical character recognition test case\" (in Portuguese).</p> </li> <li> <p>Books - selected books, ebooks, wikibooks, papers, publications, and related topics that I collect over time.</p> </li> </ul>"},{"location":"notes/#random-bookmarks","title":"Random bookmarks","text":"<p>Collection of links I found interesting.</p> <ul> <li>Stephan Stephany's page at INPE.</li> <li>Celso Mendes's page at INPE.</li> <li>Rafael Santos's page at INPE.</li> <li>Valdemar Setzer's page at USP.</li> <li>Marcio Delamaro's page at USP.</li> <li>Tomasz Kowaltowski's page at UNICAMP.</li> <li>Lectures by Walter Lewin at MIT. (Youtube video)</li> <li>Jeff Huang's page at Brown University.</li> <li>Maziar Raissi's page at University of Colorado Boulder.</li> <li>Jason Blevins' page at Ohio State University.</li> <li>John Burkardt's page at Florida State University.</li> </ul>"},{"location":"pub-all/","title":"All publications","text":"<p>Long listing of all publications including from courses, my classroom materials, and my academic research-related.</p>"},{"location":"pub-all/#courses","title":"Courses","text":"<p>Publications developed as part of the classroom activities developed in the courses I teach:</p> <p>Course publications page</p>"},{"location":"pub-all/#h2-2023-classroom-material","title":"H2 2023 classroom material","text":"<p>Teaching material published by me, as part of the Machine Design course.</p> <ul> <li>MIRANDA, E. F. An\u00e1lise de falhas e c\u00e1lculo de esfor\u00e7os. Projeto de M\u00e1quina. S\u00e3o Paulo: Scientia, 2023a. Available at: https://repositorio.pgsscogna.com.br/handle/123456789/59641.</li> <li>MIRANDA, E. F. An\u00e1lise dimensional e estrutural. Projeto de M\u00e1quina. S\u00e3o Paulo: Scientia, 2023b. Available at: https://repositorio.pgsscogna.com.br/handle/123456789/59642.</li> <li>MIRANDA, E. F. Avalia\u00e7\u00e3o de aspectos t\u00e9cnicos e econ\u00f4micos. Projeto de M\u00e1quina. S\u00e3o Paulo: Scientia, 2023c. Available at: https://repositorio.pgsscogna.com.br/handle/123456789/59639.</li> <li>MIRANDA, E. F. Dimensionamento do sistema de transmiss\u00e3o de pot\u00eancia. Projeto de M\u00e1quina. S\u00e3o Paulo: Scientia, 2023d. Available at: https://repositorio.pgsscogna.com.br/handle/123456789/59644.</li> <li>MIRANDA, E. F. Elementos auxiliares de pot\u00eancia. Projeto de M\u00e1quina. S\u00e3o Paulo: Scientia, 2023e. Available at: https://repositorio.pgsscogna.com.br/handle/123456789/59649.</li> <li>MIRANDA, E. F. Elementos de liga\u00e7\u00e3o. Projeto de M\u00e1quina. S\u00e3o Paulo: Scientia, 2023f. Available at: https://repositorio.pgsscogna.com.br/handle/123456789/59645.</li> <li>MIRANDA, E. F. Elementos de pot\u00eancia. Projeto de M\u00e1quina. S\u00e3o Paulo: Scientia, 2023g. Available at: https://repositorio.pgsscogna.com.br/handle/123456789/59648.</li> <li>MIRANDA, E. F. Introdu\u00e7\u00e3o ao projeto de m\u00e1quina. Projeto de M\u00e1quina. S\u00e3o Paulo: Scientia, 2023h. Available at: https://repositorio.pgsscogna.com.br/handle/123456789/59638.</li> <li>MIRANDA, E. F. Mancais, freios e cilindros pressurizados. Projeto de M\u00e1quina. S\u00e3o Paulo: Scientia, 2023i. Available at: https://repositorio.pgsscogna.com.br/handle/123456789/59647.</li> <li>MIRANDA, E. F. M\u00e9todos, custos, ferramental, materiais, cronograma. Projeto de M\u00e1quina. S\u00e3o Paulo: Scientia, 2023j. Available at: https://repositorio.pgsscogna.com.br/handle/123456789/59640.</li> <li>MIRANDA, E. F. Projeto de elementos de transmiss\u00e3o. Projeto de M\u00e1quina. S\u00e3o Paulo: Scientia, 2023k. Available at: https://repositorio.pgsscogna.com.br/handle/123456789/59646.</li> <li>MIRANDA, E. F. Prototipagem. Projeto de M\u00e1quina. S\u00e3o Paulo: Scientia, 2023l. Available at: https://repositorio.pgsscogna.com.br/handle/123456789/59643.</li> </ul>"},{"location":"pub-all/#publications-from-my-research","title":"Publications from my research","text":"<p>Publications from my academic postgraduate research at INPE.</p> <ul> <li>MIRANDA, E. F. Common MPI-based HPC Approaches in Python Evaluated for Selected Test Cases. 2022. 195 f. Master\u2019s Thesis \u2013 National Institute for Space Research (INPE), S\u00e3o Jos\u00e9 dos Campos, 2022. http://urlib.net/ibi/QABCDSTQQW/46C4U9H.</li> <li>MIRANDA, E. F. Comparison of CNN and MLP Artificial Neural Network Models for an Optical Character Recognition Test Case. 2022. https://doi.org/10.5281/zenodo.10676917.</li> <li>MIRANDA, E. F. Solution of a One-Dimensional Viscous Burgers\u2019 Equation Using a Physics-Informed Neural Network and a Gaussian Quadrature Method. 2022. https://doi.org/10.5281/zenodo.10676900.</li> <li>MIRANDA, E. F.; SANTOS, L. B. L.; STEPHANY, S. Data-Driven Parameter Discovery of a One-Dimensional Burgers\u2019 Equation Using a Physics-Informed Neural Network. 2023. https://doi.org/10.5281/zenodo.10676770.</li> <li>MIRANDA, E. F.; STEPHANY, S. Common HPC Approaches in Python Evaluated for a Scientific Computing Test Case. Revista Cereus, vol. 13, no. 2, p. 84\u201398, 5 Jul. 2021. DOI 10.18605/2175-7275/cereus.v13n2p84-98.  http://www.ojs.unirg.edu.br/index.php/1/article/view/3408.</li> <li>MIRANDA, E. F.; STEPHANY, S. Common MPI-Based Solutions for High-Performance Processing in Python Evaluated on Selected Test Cases. [S. l.: s. n.], 2022. https://zenodo.org/doi/10.5281/zenodo.10676832.</li> <li>MIRANDA, E. F.; STEPHANY, S. Comparison of high-performance computing approaches in the Python environment for a five-point stencil case study. Online: [s. n.], 2021. https://zenodo.org/doi/10.5281/zenodo.10672456.</li> <li>MIRANDA, E. F.; STEPHANY, S. Comparison of High-performance Computing Approaches in the Python Environment for a Five-point Stencil Test Problem. 2021. XV Brazilian e-Science Workshop, at XLI Congress of the Brazilian Computer Society (CSBC-2021).  SBC, 2021. pp. 33\u201340. DOI: 10.5753/bresci.2021.15786. Available at: https://sol.sbc.org.br/index.php/bresci/article/view/15786. Code repository: GitHub - efurlanm/bs21: Python resources in HPC.</li> </ul>"},{"location":"pub-courses/","title":"Course publications","text":"<p>The following items are student publications (in Portuguese) resulting from classroom activities in my courses. These activities are designed to introduce students to the fundamentals of research project development, academic publishing, and seminar evaluation and presentation.</p>"},{"location":"pub-courses/#h2-2025-28o-eac-conference","title":"H2 2025 28\u00ba EAC conference","text":"<p>Conference website |  Proceedings</p> <ul> <li>DA SILVA, F. V.; MIRANDA, E. F. Corrida Urbana: Desenvolvimento de um Jogo Arcade 2D em Python com a Biblioteca Pygame e a Aplica\u00e7\u00e3o de Intelig\u00eancia Artificial como Ferramenta de Suporte. 2025. Anais do 28\u00ba Encontro de Atividades Cient\u00edficas. Londrina: Unopar, 2025. Dispon\u00edvel em: https://eventos.pgsscogna.com.br/anais/trabalho/23838.</li> <li>GAMA, J. V. N.; ARANIBAR, S. E. G.; SILVA, K. F.; TANCARA, P. F. M.; LIMA, M.; MIRANDA, E. F. PROJETO DE UM CARRINHO ROB\u00d4 SEGUIDOR DE LINHA UTILIZANDO A PLATAFORMA ARDUINO. 2025. Anais do 28\u00ba Encontro de Atividades Cient\u00edficas. Londrina: Unopar, 2025. Dispon\u00edvel em: https://eventos.pgsscogna.com.br/anais/trabalho/25835.</li> <li>GON\u00c7ALVES, M. N.; DOS SANTOS, G. P.; DA SILVA, P. P.; MESQUITA, L. G. P.; COSTA, G. A.; MIRANDA, E. F. ROB\u00d4 SEGUIDOR DE LINHA COM ARDUINO NANO. 2025. Anais do 28\u00ba Encontro de Atividades Cient\u00edficas. Londrina: Unopar, 2025. Dispon\u00edvel em: https://eventos.pgsscogna.com.br/anais/trabalho/23882.</li> <li>PEREIRA, I. S.; DE SOUZA, L. V.; MIRANDA, E. F. Carrinho seguidor de linhas. 2025. Anais do 28\u00ba Encontro de Atividades Cient\u00edficas. Londrina: Unopar, 2025. Dispon\u00edvel em: https://eventos.pgsscogna.com.br/anais/trabalho/25263.</li> <li>REIS, O. S.; PEDROZA, G. D. M.; BRAGA, P. L.; COSTA, B. D. M. S.; BRITO, H. M. S.; MIRANDA, E. F. Projeto Rob\u00f4 - Corrida Maluca. 2025. Anais do 28\u00ba Encontro de Atividades Cient\u00edficas. Londrina: Unopar, 2025. Dispon\u00edvel em: https://eventos.pgsscogna.com.br/anais/trabalho/26380.</li> <li>SILVA, E. D. O.; DA COSTA, L. D.; FERREIRA JUNIOR, E. M.; DOS SANTOS, C. M.; CARVALHO, L. G. M.; MIRANDA, E. F. Engenharia de Software e An\u00e1lise de Sistemas: Fundamentos, Processos e Impactos da Intelig\u00eancia Artificial. 2025. Anais do 28\u00ba Encontro de Atividades Cient\u00edficas. Londrina: Unopar, 2025. Dispon\u00edvel em: https://eventos.pgsscogna.com.br/anais/trabalho/23961.</li> <li>SILVA, G. T.; SARDINHA, V. A. M.; FIGUEREDO, L. F.; DIONIZIO, G. S.; MIRANDA, E. F. Desenvolvimento de um Rob\u00f4 Seguidor de Linha com Arduino Uno para Aplica\u00e7\u00f5es Educacionais e de Automa\u00e7\u00e3o. 2025. Anais do 28\u00ba Encontro de Atividades Cient\u00edficas. Londrina: Unopar, 2025. Dispon\u00edvel em: https://eventos.pgsscogna.com.br/anais/trabalho/25654.</li> </ul>"},{"location":"pub-courses/#h1-2025-preprint","title":"H1 2025 Preprint","text":"<ul> <li>ARAUJO, C.; FONSECA, B.; FREITAS, C.; FURTADO, P.; PEREIRA, V. Constru\u00e7\u00e3o de um rob\u00f4 segue-linha. [S. l.]: Zenodo, [S. d.]. DOI: 10.5281/zenodo.15529820. Dispon\u00edvel em: https://doi.org/10.5281/zenodo.15529820.</li> </ul>"},{"location":"pub-courses/#h2-2024-27o-eac-conference","title":"H2 2024 27\u00ba EAC conference","text":"<p>Conference website |  Proceedings</p> <ul> <li>CRUZ, P. D. S.; NASCIMENTO, J. N. D.; SANTOS, E. D. C. D.; ARAUJO, I. E. O. D.; FLORES, W. R. B.; CLAVA, G. D. V.; SOUZA, L. S. B.; MIRANDA, E. F. SISTEMA DE GEST\u00c3O DE VENDAS. Encontro de Atividades Cient\u00edficas, [S. l.], n. 27, 2024. Dispon\u00edvel em: https://repositorio.pgsscogna.com.br/handle/123456789/71319.</li> <li>DAREZZO, V. R. F.; BRUM, D. M. M.; MULLER, G. R.; SILVA, D. F. A. D.; VOGIANTZIS, N. IMPACTO DAS ENCHENTES NO RIO GRANDE DO SUL: UM MAPA DE CALOR DAS FATALIDADES. Encontro de Atividades Cient\u00edficas, [S. l.], n. 27, 2024. Dispon\u00edvel em: https://repositorio.pgsscogna.com.br/handle/123456789/70022.</li> <li>MOTA, W. M. D.; MIRANDA, E. F. EMPOWERU. Encontro de Atividades Cient\u00edficas, [S. l.], n. 27, 2024. Dispon\u00edvel em: https://repositorio.pgsscogna.com.br/handle/123456789/71001.</li> <li>NETO, M. G. P.; GOES, A. P. C. D.; MARTINS, K. O.; GUERREIRO, E. S.; MIRANDA, E. F. PLATAFORMA DE CADASTRO E GERENCIAMENTO DE ALUNOS PARA FACULDADE. Encontro de Atividades Cient\u00edficas, [S. l.], n. 27, 2024. Dispon\u00edvel em: https://repositorio.pgsscogna.com.br/handle/123456789/71061.</li> <li>RODRIGUES, G. N.; SANTOS, L. S.; CAMPOS, K. M. D.; BATISTA, I. F. B.; ARAUJO, I. A. D.; MENDES, J. V.; MIRANDA, E. F. TO DO LIST. Encontro de Atividades Cient\u00edficas, [S. l.], n. 27, 2024. Dispon\u00edvel em: https://repositorio.pgsscogna.com.br/handle/123456789/70688.</li> <li>SOUZA, Y. A. R. D.; MACHADO, T. S.; MIRANDA, E. F. DESENVOLVIMENTO E IMPACTO DE UM APLICATIVO DE SUSTENTABILIDADE PARA INCENTIVAR PR\u00c1TICAS ECOL\u00d3GICAS NO COTIDIANO. Encontro de Atividades Cient\u00edficas, [S. l.], n. 27, 2024. Dispon\u00edvel em: https://repositorio.pgsscogna.com.br/handle/123456789/70894.</li> <li>TAMBERI, G. G.; RIBEIRO, M. H. J.; NASCIMENTO, M. C. A. D.; VOGIANTZIS, N.; ARRUDA, A. H. L.; SILVA, G. E. D. PROJETO INTEGRADO 2\u00b0 SEMESTRE - FACULDADE ANHANGUERA. Encontro de Atividades Cient\u00edficas, [S. l.], n. 27, 2024. Dispon\u00edvel em: https://repositorio.pgsscogna.com.br/handle/123456789/70941.</li> <li>TAVARES, P. H. D. D. S.; CHAMBI, C. M. P.; MIRANDA, E. F. PROJETO DE GESTAO DE ESTOQUE. Encontro de Atividades Cient\u00edficas, [S. l.], n. 27, 2024. Dispon\u00edvel em: https://repositorio.pgsscogna.com.br/handle/123456789/70653.</li> </ul>"},{"location":"pub-courses/#h2-2024-preprints","title":"H2 2024 Preprints","text":"<ul> <li>ALMEIDA, L. G. S. de; OLIVEIRA, R. O. F.; APARECIDA, J. da S. O.; JESUS, D. V. ADEP - Ambiente Digital das Escolas P\u00fablicas. Zenodo, 8 nov. 2024. DOI: 10.5281/zenodo.14058447. Dispon\u00edvel em: https://zenodo.org/records/14058448.</li> <li>ANDRE, C., Marcelo, Walter e Andre; ADS. Projeto TI Entrevista. [S. n.], 9 nov. 2024. DOI: 10.5281/zenodo.14058486. Dispon\u00edvel em: https://zenodo.org/records/14058487.</li> <li>BARBOSA, B. F.; ARAUJO, C. Q. D.; RAMOS, J. V. A. P.; ALVES, L. K.; FURTADO, P. H. D. S. Desenvolvimento de Mec\u00e2nicas B\u00e1sicas para um RPG 2D. Zenodo, 1 nov. 2024. DOI: 10.5281/zenodo.14025670. Dispon\u00edvel em: https://zenodo.org/records/14025671.</li> <li>FAGUNDES, F. Treinando html/css. [S. n.], 6 nov. 2024. DOI: 10.5281/zenodo.14047990. Dispon\u00edvel em: https://zenodo.org/records/14047991.</li> <li>FERREIRA, R. Condominium-RESTful-API. [S. n.], 6 nov. 2024. DOI: 10.5281/zenodo.14046062. Dispon\u00edvel em: https://zenodo.org/records/14046063.</li> <li>MIGUEL, M. Happy Dogs: Facilitando a Vida dos Donos de C\u00e3es. Zenodo, 25 set. 2024. DOI: 10.5281/zenodo.13839897. Dispon\u00edvel em: https://zenodo.org/records/13839898.</li> <li>NASCIMENTO, E. M. D. S.; SOUZA, G. C. D.; ALMEIDA, K. S. D.; SCARANELLO, L.; CERQUEIRA, N.; PEDRO EDUARDO ALVES DA SILVA; RAISSA CAVALCANTI LIMA; TAMIRES DA SILVA BEZERRA. Hora Marcada - PHP. [S. n.], 7 nov. 2024. DOI: 10.5281/zenodo.14053068. Dispon\u00edvel em: https://zenodo.org/records/14053069.</li> <li>NETO, T.; ARA\u00daJO, R. Safira. [S. n.], 9 nov. 2024. DOI: 10.5281/zenodo.14058417. Dispon\u00edvel em: https://zenodo.org/records/14058418.</li> <li>RAMOS, A. V.; LEMOS, B. L.; SILVA, D. D. A.; SOUZA, I. R. D.; SILVA, R. D. S.; AGUILAR, V. H. L. Artigo do projeto: CodeAI. [S. n.], 12 nov. 2024. DOI: 10.5281/zenodo.14083688. Dispon\u00edvel em: https://zenodo.org/records/14083689.</li> <li>RIBEIRO, P. H. D. S.; QUEIROZ, R. K. F. D. Cria\u00e7\u00e3o de Projeto com SQL Server, Visal Studio Code e Power BI. [S. l.]: [S. n.], [S. d.]. Dispon\u00edvel em: https://github.com/PedroHenrique0033/projeto-integrado.</li> <li>SANTOS PEREIRA, I.; VIEIRA DE SOUZA, L. Carrinho com arduino Uno Controlado por um controle de PS2. Zenodo, 8 nov. 2024. DOI: 10.5281/zenodo.14053075. Dispon\u00edvel em: https://zenodo.org/records/14053076.</li> <li>SILVA, B. V. da; THOMAZ, B.; SANTOS, D.; SILVA, G.; DIAS, G.; MACHADO, L.; SOUZA, T.; MATOS, V. Projeto Atlas BGTV. Zenodo, 11 nov. 2024. DOI: 10.5281/zenodo.14075075. Dispon\u00edvel em: https://zenodo.org/records/14083391.</li> <li>SOUZA, A. A. T.; SOUZA, G. S. de. Projeto do programa gerenciamento de estacionamento. [S. n.], 6 nov. 2024. DOI: 10.5281/zenodo.14047981. Dispon\u00edvel em: https://zenodo.org/records/14047982.</li> <li>ZANOLA, M. V. C.; HIRAMATSU, N. F. Rela\u00e7\u00e3o ben\u00e9fica entre a tecnologia e a sa\u00fade aliment\u00edcia. Zenodo, 8 nov. 2024. DOI: 10.5281/zenodo.14056829. Dispon\u00edvel em: https://zenodo.org/records/14056830.</li> </ul>"},{"location":"pub-courses/#h1-2024-preprints","title":"H1 2024 Preprints","text":"<ul> <li>AZUL, E. S. Site de Pesquisas de TI. [S. n.], 2024. DOI: 10.5281/zenodo.10914369. Dispon\u00edvel em: https://zenodo.org/records/10914369.</li> <li>BORTOLOTTO, M.; CESAR, R. Python e MySQL. Zenodo, 27 mar. 2024. DOI: 10.5281/zenodo.10888698. Dispon\u00edvel em: https://zenodo.org/records/10888698.</li> <li>JONATHAN, E.; KIMURA, H.; MIRANDA, E. F. IMPLEMENTA\u00c7\u00c3O DE UM ALGORITMO DE ORDENA\u00c7\u00c3O R\u00c1PIDA EM JAVASCRIPT. Zenodo, 27 maio 2024. DOI: 10.5281/zenodo.11327516. Dispon\u00edvel em: https://zenodo.org/records/11327516.</li> <li>JONATHAN, E.; MIRANDA, E. F.; KIMURA, H. IMPLEMENTA\u00c7\u00c3O DE UM ALGORITMO DE ORDENA\u00c7\u00c3O R\u00c1PIDA EM PYTHON. Zenodo, 2 abr. 2024. DOI: 10.5281/zenodo.10905998. Dispon\u00edvel em: https://zenodo.org/records/10905998.</li> <li>SANTOS, S. Algoritmo de compress\u00e3o de dados Huffman. Zenodo, 2024. DOI: 10.5281/zenodo.11053066. Dispon\u00edvel em: https://zenodo.org/records/11053066.</li> </ul>"},{"location":"pub-courses/#h2-2023-26o-eac-conference","title":"H2 2023 26\u00ba EAC conference","text":"<p>Conference website |  Proceedings</p> <ul> <li>BARONE, H. M.; CONCEICAO, L. M. D.; FERREIRA, L. de A.; AMORIM, L. O. D.; OLIVEIRA, G. L. D.; FERNANDES, R. E. D. S.; BARRETO, V. N. D. A.; MIRANDA, E. F. Programa\u00e7\u00e3o e Desenvolvimento de Banco de Dados. [S. l.]: [S. n.], [S. d.]. Dispon\u00edvel em: https://repositorio.pgsscogna.com.br/handle/123456789/72992.</li> <li>FILENO, J. D. S.; SILVA, G. C.; SANTOS, E. D. R.; MARCOLINO, A. S. D. A.; LIDUINO, T. D. J.; FACCI, R.; GARCIA, G. M. D. P.; MIRANDA, E. F. Passo a Passo da Cria\u00e7\u00e3o de um Rob\u00f4 com Placa de Arduino. [S. l.]: [S. n.], [S. d.]. Dispon\u00edvel em: https://repositorio.pgsscogna.com.br/handle/123456789/73782.</li> <li>JUNIOR, M. R. D. M.; GEREZ, L. M. D. O.; SILVA, J. V. D.; MIRANDA, E. F. Trabalho de Linguagem de Programa\u00e7\u00e3o. [S. l.]: [S. n.], [S. d.]. Dispon\u00edvel em: https://repositorio.pgsscogna.com.br/handle/123456789/73471.</li> <li>LIMA, M. A. O.; DANTAS, P. C. C. R.; PINHA, G. G. A.; CONCEICAO, J. S.; MIRANDA, E. F. Dando Asas \u00e0 Criatividade com a Plataforma Arduino: Explorando o Potencial da Eletr\u00f4nica Acess\u00edvel e Programa\u00e7\u00e3o Intuitiva. [S. l.]: [S. n.], [S. d.]. Dispon\u00edvel em: https://repositorio.pgsscogna.com.br/handle/123456789/71957.</li> <li>NERO, J. C. C. D.; MIRANDA, E. F. Gerenciamento de Banco de Dados. [S. l.]: [S. n.], [S. d.]. Dispon\u00edvel em: https://repositorio.pgsscogna.com.br/handle/123456789/73614.</li> <li>PEREIRA, M. E.; RUBIO, M.; SOUZA, A. V. A. de; COSTA, L. R. da; CARDOSO, D. M.; LIMA, F. F.; FREITAS, F. D.; MIRANDA, E. F. Robo Seguidor de Linha. [S. l.]: [S. n.], [S. d.]. Dispon\u00edvel em: https://repositorio.pgsscogna.com.br/handle/123456789/71813.</li> <li>SILVA, J. V. B. D.; MIRANDA, E. F. Carrinho Educativo Controlado por Bluetooth e Aplicativo. [S. l.]: [S. n.], [S. d.]. Dispon\u00edvel em: https://repositorio.pgsscogna.com.br/handle/123456789/73423.</li> <li>SOUZA, L. D. A.; KIMURA, H. T.; NARDINI, D. A.; SANTOS, L. S. D.; POMA, K. G. S.; SILVA, E. J. A. V. D.; MIRANDA, E. F. Fases da Compila\u00e7\u00e3o na Utiliza\u00e7\u00e3o do Arduino Uno. [S. l.]: [S. n.], [S. d.]. Dispon\u00edvel em: https://repositorio.pgsscogna.com.br/handle/123456789/72000.</li> <li>SOUZA, L. D. A.; SILVA, E. J. A. V. D.; SANTOS, L. S. D.; SAMO, K.; NARDINI, D. A.; KIMURA, H. T.; MIRANDA, E. F. Utiliza\u00e7\u00e3o do Microcontrolador Arduino para a Constru\u00e7\u00e3o de um Rob\u00f4 Seguidor de Linha. [S. l.]: [S. n.], [S. d.]. Dispon\u00edvel em: https://repositorio.pgsscogna.com.br/handle/123456789/73747.</li> </ul>"},{"location":"research/","title":"Research","text":"<p>My current postgraduate research explores the application of high performance computing (HPC) and machine learning (ML) methodologies to scientific problems, with a focus on areas like radiation schemes in climate prediction models.</p>"},{"location":"research/#publications","title":"Publications","text":"<p>Publications related to my postgraduate course.</p> <ul> <li>MIRANDA, E. F.; SOUTO, R. P.; STEPHANY, S. Descoberta de par\u00e2metro na equa\u00e7\u00e3o 2D de burgers por rede neural informada pela f\u00edsica. Dec. 2025. CIACA CIAWI 2025 Proceedings. Lisboa: IADIS, Dec. 2025. pp. 87\u201394. Available at: https://www.iadisportal.org/ciaca-ciawi-2025-proceedings.</li> <li>MIRANDA, E. F. Common MPI-based HPC Approaches in Python Evaluated for Selected Test Cases. 2022. Master\u2019s Thesis (Applied Computing) - National Institute for Space Research (INPE), S\u00e3o Jos\u00e9 dos Campos, 2022. Available at: http://urlib.net/ibi/QABCDSTQQW/46C4U9H.</li> <li>MIRANDA, E. F.; STEPHANY, S. Common MPI-Based Solutions for High-Performance Processing in Python Evaluated on Selected Test Cases. [Presentation]. 2022. DOI: https://doi.org/10.5281/zenodo.10676832.</li> <li>MIRANDA, E. F.; STEPHANY, S. Comparison of High-performance Computing Approaches in the Python Environment for a Five-point Stencil Test Problem. In: XV Brazilian E-Science Workshop (CSBC), 2021, Online. Proceedings [...]. Porto Alegre: Sociedade Brasileira de Computa\u00e7\u00e3o, 2021. pp. 33\u201340. DOI: https://doi.org/10.5753/bresci.2021.15786.</li> <li>MIRANDA, E. F.; STEPHANY, S. Common HPC Approaches in Python Evaluated for a Scientific Computing Test Case. Revista Cereus, vol. 13, no. 2, pp. 84\u201398, 2021. DOI: https://doi.org/10.18605/2175-7275/cereus.v13n2p84-98.</li> <li>MIRANDA, E. F.; STEPHANY, S. Comparison of high-performance computing approaches in the Python environment for a five-point stencil case study. In: XV Brazilian e-Science Workshop (BreSci), 2021, Online. [Presentation]. DOI: https://doi.org/10.5281/zenodo.10672456.</li> </ul>"},{"location":"research/#manuscripts","title":"Manuscripts","text":"<p>Manuscripts related to my postgraduate course. </p> <ul> <li>MIRANDA, E. F.; SANTOS, L. B. L.; STEPHANY, S. Data-Driven Parameter Discovery of a One-Dimensional Burgers\u2019 Equation Using a Physics-Informed Neural Network. [Manuscript]. 2023. DOI: https://doi.org/10.5281/zenodo.10676770. Available at: https://efurlanm.github.io/425/.</li> <li>MIRANDA, E. F. Solution of a One-Dimensional Viscous Burgers' Equation Using a Physics-Informed Neural Network and a Gaussian Quadrature Method. [Manuscript]. 2022. DOI: https://doi.org/10.5281/zenodo.10676900. Available at: https://efurlanm.github.io/421/.</li> <li>MIRANDA, E. F. Comparison of CNN and MLP Artificial Neural Network Models for an Optical Character Recognition Test Case. [Manuscript]. 2022. DOI: https://doi.org/10.5281/zenodo.10676917.</li> </ul>"},{"location":"research/#projects","title":"Projects","text":"<p>I maintain a repository on Github with my open source projects that I have been developing over time for various purposes: https://github.com/efurlanm/ . The current main research repository is: https://github.com/efurlanm/ml/. The research also uses the LNCC supercomputer Santos Dumont under the project AMPEMI. </p>"},{"location":"teach-proj/","title":"Autonomous Line-Following Robot","text":"<p>As an integral component of my project-based learning methodology, consistently applied across all disciplines I teach each semester, I proposed and guided the development of an autonomous line-following robot. This comprehensive project involved students in the design, hardware integration, software programming, and control system optimization, culminating in a robotics competition where the robot's ability to autonomously navigate complex tracks was rigorously tested. The valuable insights gained from this development and competitive analysis were further documented in a scientific paper, highlighting the technical challenges, innovative solutions, and the robot's practical application and efficiency.</p> <p>Repository: https://github.com/efurlanm/robot/</p>"},{"location":"teach-proj/#classroom-activities-photo-gallery","title":"Classroom Activities Photo Gallery","text":"<p>This gallery documents an interdisciplinary, hands-on learning initiative where students designed, built, and programmed line-following robots for a competition that I proposed. This activity fostered collaborative teamwork and the application of a structured methodology, integrating concepts and skills from diverse curriculum disciplines. Through this process, students gained practical experience and developed real-world problem-solving skills. The project culminated in a competitive event showcasing their work. As part of the project documentation and an introduction to academic publishing, students also produced a brief introductory article summarizing their approach and outcomes. Some past publications are listed in pub-courses.</p> <p>Access to the photo gallery (in Portuguese).</p>"},{"location":"teaching/","title":"Teaching","text":"<p>List of current duties and courses taught. The links point to repositories where some more information can be found (in Portuguese).</p>"},{"location":"teaching/#current-duties","title":"Current duties","text":"<ul> <li>Algorithms and Structured Programming</li> <li>Computer Networks</li> <li>Digital Systems and Microprocessors</li> <li>Fundamentals of Low Voltage Electrical Installations</li> <li>Parallel and Distributed Architectures</li> <li>Programming Languages</li> <li> <p>Operational Systems</p> </li> <li> <p>Systems Analysis and Modeling</p> </li> </ul>"},{"location":"teaching/#past-courses","title":"Past courses","text":""},{"location":"teaching/#computing","title":"Computing","text":"<ul> <li>Advanced Algorithms and Data Structures</li> <li>Capstone Project</li> <li>Compilers</li> <li>Computational Logic and Mathematics</li> <li>Computer Architecture and Organization</li> <li>Creativity and Innovation</li> <li>Data Modeling</li> <li>Digital Systems</li> <li>Distributed Systems</li> <li>Formal Languages \u200b\u200band Automata</li> <li>Formal Languages, Automata and Computability</li> <li>Fundamentals of Parallel and Distributed Programming</li> <li>Integrated Project</li> <li>Object Oriented Languages</li> <li>Object Oriented Programming</li> <li>Programming Techniques</li> <li>Special Topics in Computer Science</li> </ul>"},{"location":"teaching/#engineering","title":"Engineering","text":"<ul> <li>Building Systems</li> <li>Electrical Power Systems</li> <li>Electrotechnical</li> <li>Industrial Communication Networks</li> <li>Industrial Organization and Automation</li> <li>Machine Design</li> <li>Production Management</li> <li>Project Management for Production</li> <li>Protection of the Electric Power System</li> <li>Strategic Production Planning</li> <li>Theory of Structures</li> <li>Transport Works</li> <li>Reverse Logistic</li> </ul>"},{"location":"teaching/#publications","title":"Publications","text":"<ul> <li>Course publications - publications that were generated as part of the activities of the courses taught.</li> <li>All Publications  (long listing) - collection of all publications, including courses, teaching material, and my research.</li> </ul>"},{"location":"teaching/#student-projects","title":"Student Projects","text":"<ul> <li>Autonomous line-following robot - as a cornerstone of my project-based learning methodology across all courses, this initiative focuses on the development and competitive evaluation of an autonomous robot. This hands-on project integrates hardware, software, and control systems, culminating in a robotics competition and a scientific publication detailing its design and performance.</li> </ul>"},{"location":"blog/","title":"Posts","text":"<p>My personal blog containing short random notes that I collect over time on the most varied subjects.</p>"},{"location":"blog/2024/12/01/hp41/","title":"HP-41","text":"<p>The 1979 HP-41 series programmable calculator, produced until 1990, was famously used in the Space Shuttle missions. It featured an LCD alphanumeric display and was powered by a processor initially called \"Coconut\" (or 1LE3 CPU), later more broadly known as the Nut CPU. The calculator included RAM, ROM, and I/O capabilities, utilizing the interpreted programming language FOCAL (\"Forty One Calculator Language\"). Both the operating system and the interpreter were stored in ROM, programmed using the Coconut processor's assembly language, also called MCODE (or \"M-Code\"). A later upgrade, the NEWT Microprocessor, further enhanced its capabilities.</p> <p>What truly sets this calculator apart are its hardware expansion slots. These allowed users to significantly expand its functionality by adding various components such as memory modules, printer interfaces, card readers, barcode wands, and specialized application modules. This innovative design was a clear precursor to the expansion slots found in modern computers. The HP-41 also famously utilized Reverse Polish Notation (RPN) for its input logic.</p> <p>While it naturally lacked the processing power and versatility of modern portable computing devices, the HP-41's design philosophy\u2014rooted in portability and user customization\u2014profoundly influenced the development of more advanced mobile computing equipment. The HP-41C, for instance, was a popular model in the series, recognized for its \"Continuous Memory\" feature.</p> <ul> <li>HP-41C, at wikipedia.org .</li> <li>HP-41 Library, at hp1.org .</li> <li>A_programmers_handbook_v.2.07, by Poul Kaarup, 2015.</li> <li>CPU Detailed Description, by Hewlett-Packard, 1981.</li> <li>Schematic, Hewlett-Packard, 2000.</li> <li>ROM listing <ul> <li>http://www.hp41.org/LibView.cfm?Command=View&amp;ItemID=1064</li> <li>http://www.hp41.org/LibView.cfm?Command=View&amp;ItemID=304</li> </ul> </li> <li>Monte Dalrymple's \"Inside the NUT CPU\" - provides an in-depth look at the Nut CPU, which is the central processing unit of the HP-41 calculator series. It delves into the architecture, design, and functionality of the CPU.</li> <li>Doug Wilder\u00b4s \"QuinTable.pdf\" - HP-41 microcode table, the low-level instructions that control the operations of the HP-41 calculator series.</li> <li>David's assembler manual -  comprehensive guide that provides detailed instructions on how to use the assembler software for programming the HP-41.</li> <li>Monte Dalrymple's \"NEWT Microprocessor Technical Manual\" - the NEWT (Nut, Expanded, With Turbo) CPU is an upgraded version of the Hewlett-Packard Nut microprocessor, which was employed in a number of HP calculators, including the HP-41 series.</li> <li>Ken Emery's \"HP-41 MCODE For Beginners\" - MCODE is the internal machine code used by the HP-41, one level below the set of \"user code\" instructions that users and programmers are accustomed to dealing with. Some user code instructions like CLX are implemented by the HP-41 in just a few MCODE instructions; other user code instructions like TAN consist of hundreds of MCODE operations.</li> <li>HP-41 IC Specifications<ul> <li>https://literature.hpcalc.org/items/865</li> <li>https://literature.hpcalc.org/items/866</li> </ul> </li> <li>Rich Hawkes' \"Nonpareil RPN HP-41 Calculator Build\" - DIY hardware version of the HP-41.</li> <li>go41c calculator - Android App.</li> <li>Online HP-41C OWNER\u2019S HANDBOOK AND PROGRAMMING GUIDE.</li> </ul>"},{"location":"blog/2024/01/24/inpe-general-regulations/","title":"INPE General Regulations","text":"<p>INPE's General Regulations 2024 (approved on 09/04/2023) in searchable PDF format:</p> <ul> <li>Regimento_Geral_20230904.pdf (in Portuguese)</li> </ul> <p>The original PDF file containing INPE's General Regulations 2024 has an annoying problem that is not searchable and is not possible to select text. What I used to fix it was:</p> <pre><code>$ pdfsandwich -lang por &lt;in.pdf&gt; -o &lt;out.pdf&gt;\n$ gs -sDEVICE=pdfwrite -dCompatibilityLevel=1.7 -q -o &lt;out.pdf&gt; &lt;in.pdf&gt;\n$ ocrmypdf -l=por -s -O=3 --jbig2-lossy --output-type=pdf &lt;in.pdf&gt; &lt;out.pdf&gt;\n$ qpdf --linearize &lt;in.pdf&gt; &lt;out.pdf&gt;\n</code></pre>"},{"location":"blog/2024/12/02/internals/","title":"Internals","text":"<p>Internals refers to the inner workings of compilers or interpreters, detailing how they are structured and operate, documenting their internal structures such as the low-level runtime library, intermediate representations, control graph analysis and optimization, machine descriptions, and more.</p> <ul> <li>GNU Compiler Collection Internals</li> <li>GNU Fortran Compiler Internals</li> <li>GNU C Compiler Internals</li> <li>CPython\u2019s internals</li> </ul>"},{"location":"blog/2024/05/29/loss-lands/","title":"Loss Landscape","text":"<p>Very nice WebGL application to visualize the loss landscape for some common ANN. Currently features the models Resnet-20 (short/no-short), Resnet-56 (short/no-short), Vgg 16 and DenseNet 121.</p> <p>http://www.telesens.co/loss-landscape-viz/viewer.html</p> <p>More info:</p> <ul> <li>http://www.telesens.co/2019/01/16/neural-network-loss-visualization</li> <li>http://arxiv.org/abs/1712.09913</li> <li>http://mathformachines.com/posts/visualizing-the-loss-landscape</li> <li>http://github.com/tomgoldstein/loss-landscape</li> <li>http://github.com/marcellodebernardi/loss-landscapes</li> </ul>"},{"location":"blog/2024/01/25/microcloud/","title":"MicroCloud","text":"<p>MicroCloud is an interesting project that, through lightweight virtualization and few host computers, allows you to quickly generate a cluster of several computing nodes, requiring few resources and allowing you to use common available hardware at home, such as Raspberry Pi and laptops.</p> <p>https://canonical.com/microcloud</p> <p>Its sufficiently small to function on a developer laptop. It can be utilized for safely experimenting with new technologies, simulating or testing complicated infrastructure processes, simulating how your workloads would operate in production, and creating lightweight, restricted disposable testing environments.</p> <p>It is a simple method to start an LXD cluster with high availability. It makes use of snap packages, has the ability to automatically configure LXD and Ceph on a group of servers, and uses mDNS to find other servers on the network automatically. This allows you to run a single command on one machine to build an entire cluster.</p>","tags":["LXC","Conteiner"]},{"location":"blog/2024/05/24/nn-opti/","title":"Neural Network Optimization","text":"<p>Good post by Matthew Stewart's \"Neural Network Optimization\" from June 27, 2019. https://towardsdatascience.com/neural-network-optimization-7ca72d4db3e0</p> <p>Optimization</p> <p>The equation below represents the average gradient of the loss function with respect to the model parameters, computed over all training samples</p> \\[g={\\frac{1}{m}}\\sum_{i}\\nabla_{\\theta}L(f(x^{(i)};\\theta),y^{(i)})\\] <p>where:</p> <ul> <li>\\(g\\) is the gradient of the loss function with respect to the model parameters \\(\\theta\\). The gradient vector is a vector that points in the direction of the steepest increase in a function.</li> <li>\\(m\\) is the total number of training samples in the dataset. It\u2019s the denominator in the expression, indicating that we\u2019re averaging the gradients over all samples.</li> <li>\\(\\sum_{i}\\) indicates that we\u2019re summing over all training samples. The index \\(i\\) ranges from \\(1\\) to \\(m\\).</li> <li>\\(\\nabla_\\theta\\) is the gradient operator with respect to the model parameters \\(\\theta\\). It computes the partial derivatives of the loss function with respect to each parameter.</li> <li>\\(L(f(x^{(i)};\\theta),y^{(i)})\\) represents the loss function evaluated for the \\(i\\)-th training sample. It measures the discrepancy between the predicted output \\(f(x^{(i)};\\theta)\\) and the actual target \\(y^{(i)}\\).</li> </ul>"},{"location":"blog/2024/02/22/para-spec/","title":"Parallel Spectral Numerical Methods","text":"<p>Very nice Wikibook based on Parallel Spectral Numerical Methods by Chen et al. (2012) from University of Michigan. Discusses how to solve ordinary differential equations (ODE) and partial differential equations (PDE) using separation of variables. Next, it introduces numerical time-stepping schemes that can be used to solve ODEs and PDEs. This is followed by an introduction to pseudo spectral methods through an overview of the discrete Fourier Transform (DFT) and the Fast Fourier Transform (FFT) algorithm that is used to quickly calculate the DFT. Finally it will combine all of these to solve a couple of different PDEs first in a serial setting and then in a parallel setting. The programs will use Matlab and Fortran. A Python implementation of some of the Matlab programs is also provided.</p> <p>https://en.wikibooks.org/wiki/Parallel_Spectral_Numerical_Methods</p>"},{"location":"blog/2025/02/28/capes-peri/","title":"Periodicals from CAPES","text":"<p>I did a quick search on the CAPES website:</p> <p>https://www.periodicos.capes.gov.br/index.php/acervo/lista-a-z-periodicos.html</p> <p>Searching for open, peer-reviewed, national, multidisciplinary journals, and I selected some that I found interesting. The first line of each item corresponds to the title, [ISSN] and classification; the second corresponds to the website, and the third is the periodicity:</p> <ul> <li> <p>Revista Ci\u00eancia, Tecnologia &amp; Ambiente [2359-6643] B4 </p> <ul> <li>https://www.revistacta.ufscar.br/index.php/revistacta</li> <li>Federal University of S\u00e3o Carlos (UFSCAR)</li> <li>Rolling Pass</li> </ul> </li> <li> <p>Revista Profiscientia [1806-0285] B3</p> <ul> <li>https://profiscientia.ifmt.edu.br/profiscientia/index.php/profiscientia</li> <li>Federal Institute of Mato Grosso (IFMT)</li> <li>Rolling Pass</li> </ul> </li> <li> <p>Ci\u00eancia &amp; Tecnologia [2178-9436] B3</p> <ul> <li>https://citec.fatecjaboticabal.edu.br/index.php/citec</li> <li>Fatec Jaboticabal</li> <li>Rolling Pass</li> </ul> </li> <li> <p>Somma: Revista Cient\u00edfica do Instituto Federal do Piau\u00ed [2447-701X] B2</p> <ul> <li>https://revistas.ifpi.edu.br/index.php/somma/index</li> <li>Federal Institute of Piau\u00ed (IFPI)</li> <li>Rolling Pass</li> </ul> </li> <li> <p>Abak\u00f3s [2316-9451] A4</p> <ul> <li>https://periodicos.pucminas.br/index.php/abakos</li> <li>PUC Minas</li> <li>Semiannual, 2023-11, 2023-06</li> </ul> </li> <li> <p>Essentia: Revista de Cultura, Ci\u00eancia e Tecnologia [1516-6406] B3</p> <ul> <li>https://essentia.uvanet.br/index.php/ESSENTIA</li> <li>State University of Vale do Acara\u00fa (UVA)</li> <li>Semiannual</li> </ul> </li> <li> <p>Journal of the Brazilian Computer Society [0104-6500] A2</p> <ul> <li>https://sol.sbc.org.br/journals/index.php/jbcs</li> <li>Quarterly</li> </ul> </li> <li> <p>Revista Brasileira de Computa\u00e7\u00e3o Aplicada [2176-6649] B3</p> <ul> <li>https://seer.upf.br/index.php/rbca/index</li> <li>University of Passo Fundo (UPF)</li> <li>Quarterly</li> </ul> </li> <li> <p>Revista de Inform\u00e1tica Te\u00f3rica e Aplicada [0103-4308] B3</p> <ul> <li>https://seer.ufrgs.br/index.php/rita/index</li> <li>Federal University of Rio Grande do Sul (UFRGS)</li> <li>Semiannual</li> </ul> </li> </ul>","tags":["Qualis"]},{"location":"blog/2024/05/13/pinn-inverse-pereira/","title":"Using PINN for Inverse Problems","text":"<p>My personal notes about the seminar Using Physics-informed Neural Networks for Inverse Problems by Jo\u00e3o Pereira - IMPA at National Scientific Computing Laboratory (LNCC) on 2024-05-13.</p> <p>Presentation generated from the video: PINN-Presentation-Pereira.pdf (in Portuguese)</p> <p>The seminar mainly deals with two published articles, and also a third that has not yet been published:</p> <ul> <li>HASAN, A.; M. PEREIRA, J.; FARSIU, S.; TAROKH, V. Identifying Latent Stochastic Differential Equations. IEEE Transactions on Signal Processing, [N.p.], vol. 70, pp. 89\u2013104, 2022. DOI: 10.1109/TSP.2021.3131723. Available at: https://ieeexplore.ieee.org/document/9632430/.</li> <li>HASAN, A.; PEREIRA, J. M.; RAVIER, R.; FARSIU, S.; TAROKH, V. Learning Partial Differential Equations from Data Using Neural Networks. [N.p.], 22 Oct. 2019. Available at: http://arxiv.org/abs/1910.10262.</li> <li> <p>BIZZI, A.; NISSENBAUM, L.; PEREIRA, J. M. Neural Conjugate Flows: Physics-informed architectures with flow structure. arXiv, no. arXiv:2411.08326, 13 Nov. 2024. DOI: 10.48550/arXiv.2411.08326. Available at: http://arxiv.org/abs/2411.08326.</p> </li> <li> <p>Code:</p> <ul> <li>http://github.com/alluly/pde-estimation</li> <li>http://github.com/alluly/ident-latent-sde</li> </ul> </li> </ul>"},{"location":"blog/2024/05/13/pinn-inverse-pereira/#pinn","title":"PINN","text":"<ul> <li>The various PDEs can be seen as a simple linear combination</li> </ul> Equation PDE Wave (1D) \\(u_{tt} - u_{xx} = 0\\) Heat (1D) \\(u_{t} - u_{xx} = 0\\) Helmholtz (2D) \\(u_{xx} + u_{yy} + u= 0\\) Burgers (1D) \\(u_{t} + uu_{x} = 0\\) Korteweg-de Vries \\(u_{t} - 6uu_{x} + u_{xxx}= 0\\) <ul> <li> <p>The problem is to determine the PDE that best represents the data</p> </li> <li> <p>Initially, a set of possible derivative terms is estimated</p> </li> </ul> <p></p> <ul> <li> <p>Let \\(p_1, \u2026, p_k\\) be sample random points in the domain</p> </li> <li> <p>If \\(u\\) is a solution of the PDE</p> </li> </ul> <p>\\(a_1 u + a_2 u_{xx} + a_3 uu_x + a_4 u_{xxx} + a_5 u_t = 0\\)</p> <ul> <li>For all \\(p_1, \u2026, p_k\\)</li> </ul> <p>$a_1 u (p_k) + a_2 u_{xx} (p_k) + a_3 u (p_k) u_x(p_k) + a_4 u_{xxx} (p_k) + a_5 u_t (p_k) = 0 $</p> <ul> <li>In matrix form:</li> </ul> <p>\\(\\underbrace{ \\left[ \\begin{array}{c c c c} u(p_1) &amp; u_{x x}(p_1) &amp; u(p_1)u_x(p_1)&amp; u_{x x x}(p_1) &amp; u_t(p_1) \\\\\\  \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\\\  u(p_k) &amp; u_{x x}(p_k) &amp; u(p_k)u_x(p_k) &amp; u_{x x x}(p_k) &amp; u_t(p_k) \\end{array}  \\right] }_{\\mathcal{M}_u(p)} \\left[ \\begin{array}{c} a_1 \\\\\\ \\vdots \\\\\\ a_5  \\end{array}  \\right]=0\\)</p> <ul> <li>The vector \\(a = (a_1, ..., a_5)\\) is in the null space of \\(\\mathcal{M}_u(p)\\)</li> <li>In matrix form: \\(\\mathcal{M}_u(p) a = 0\\)</li> <li>The null space vector is a singular vector with singular value 0</li> <li>The null space vector (also known as the null vector) refers to the zero vector in the context of linear algebra</li> <li>The null space vector is simply the zero vector itself: 0</li> <li>It is the unique vector that belongs to the null space of any matrix</li> <li>When we say null space vector, we are referring to the specific vector v that satisfies the condition Av = 0 for a given matrix A</li> <li>Let's think about optimization</li> <li>Calculate the smallest singular value using the min-max principle</li> </ul> <p>$ \\underset{ a }{ \\min } \\quad | \\mathcal{M}_u(p) a |_2^2 $</p> <p>subject to $ \\quad | a |_2 = 1 \\quad $ (Euclidean norm)</p> <p>$ | a |_2 = \\sqrt{a_1^2 + \\cdots + a_n^2} $</p> <ul> <li> <p>Bringing together the losses</p> </li> <li> <p>Fitting the neural network \\(\\hat{u}(\\cdot;\\theta)\\)</p> </li> </ul> <p></p> <ul> <li>Learning the PDE</li> </ul> <p></p> <ul> <li>Encourage law sparsity</li> </ul> <p></p> <ul> <li>Training</li> </ul> <p></p> <ul> <li>Minimizing \\(\\mathcal{L}_{PDE} (\\theta,a)\\) in terms of \\(\\theta\\) enforces that the ANN is a solution to the  PDE being learned.</li> </ul>"},{"location":"blog/2024/05/13/pinn-inverse-pereira/#stochastic-pinn","title":"Stochastic PINN","text":"<p>The Stochastic Physics-Informed Neural Network (S-PINN) framework extends the identification of governing laws to systems characterized by inherent randomness or latent dynamics. This methodology addresses the inverse problem of discovering the drift and diffusion coefficients of Stochastic Differential Equations (SDEs) from observed data snapshots or probability densities.</p>"},{"location":"blog/2024/05/13/pinn-inverse-pereira/#mathematical-framework","title":"Mathematical Framework","text":"<p>A stochastic process \\(X_t\\) is modeled via an It\u00f4 SDE (Kiyosi It\u00f4 Stochastic Differential Equation) of the form: $$ dX_t = f(X_t, t)dt + g(X_t, t)dW_t $$ where \\(f(X_t, t)\\) denotes the drift coefficient, \\(g(X_t, t)\\) represents the diffusion coefficient, and \\(W_t\\) is a standard Wiener process. The objective in the inverse problem is to identify the functional forms of \\(f\\) and \\(g\\) using a candidate library of differential operators or neural network approximations.</p>"},{"location":"blog/2024/05/13/pinn-inverse-pereira/#fokker-planck-equation-constraint","title":"Fokker-Planck Equation Constraint","text":"<p>Physical consistency is maintained by enforcing the Fokker-Planck Equation (FPE), which governs the time evolution of the probability density function \\(p(x, t)\\): $$ \\frac{\\partial p(x, t)}{\\partial t} = -\\sum_{i=1}^d \\frac{\\partial}{\\partial x_i} [f_i(x, t) p(x, t)] + \\frac{1}{2} \\sum_{i,j=1}^d \\frac{\\partial^2}{\\partial x_i \\partial x_j} [ (g(x, t) g(x, t)^\\top)_{ij} p(x, t) ] $$ The training process involves minimizing a multi-objective loss function \\(\\mathcal{L} = \\mathcal{L}_{data} + \\lambda_{phys} \\mathcal{L}_{FPE} + \\lambda_{reg} \\mathcal{L}_{reg}\\). The physics loss \\(\\mathcal{L}_{FPE}\\) penalizes the residue of the Fokker-Planck Equation, ensuring the learned drift and diffusion are consistent with the observed density evolution. Sparsity-promoting regularizations, such as the \\(L_1\\) norm, are applied to identify parsimonious governing equations.</p>"},{"location":"blog/2024/05/13/pinn-inverse-pereira/#neural-conjugate-flows","title":"Neural Conjugate Flows","text":"<p>Recent developments introduce Neural Conjugate Flows, which utilize physics-informed architectures with specific flow structures. This approach allows for efficient density estimation and improved uncertainty quantification by enforcing conjugate structures within the neural network, bridging generative modeling with the discovery of physical laws.</p>"},{"location":"blog/2024/05/13/pinn-inverse-pereira/#links-of-interest","title":"Links of interest","text":"<ul> <li>I WANT SCIENCE. Artificial Intelligence and Physics: Solving Inverse Problems with Neural Networks (in Portuguese).</li> <li>Schedule of the event where the lecture was given (in Portuguese).</li> </ul>"},{"location":"blog/2024/12/01/retro-arch/","title":"Retrocomputing Archive","text":"<p>The site is a repository dedicated to the preservation and sharing of software and documentation for classical computer systems, including a wide variety of classical computer systems and their software, such as the CP/M operating system. The site hosts software and documentation of all types for classical computer systems, providing a valuable resource for enthusiasts and researchers interested in retrocomputing. Maintained by classiccmp.org community.</p> <p>http://www.retroarchive.org/</p>"},{"location":"blog/2024/04/07/sd-upgr/","title":"LNCC SDumont supercomputer upgrade","text":"<p>The National Scientific Computing Laboratory (LNCC) and Eviden/Atos signed a new contract worth us$ 19.4 million, which will allow the machine to go from the current 5.1 Petaflop/s to 17 Petaflop/s of capacity. The technology will be based on the BullSequana XH3000 architecture, and with the expansion it will be the most powerful supercomputer in Latin America dedicated to academic studies.</p> <p>https://agenciabrasil.ebc.com.br/geral/noticia/2024-04/supercomputador-mais-potente-do-pais-tera-capacidade-aumentada (in Portuguese)</p> <p>LNCC SDumont website (in Portuguese): https://sdumont.lncc.br</p>"},{"location":"blog/2024/02/17/sd-link/","title":"LNCC SDumont supercomputer","text":"<p>Some related links I found interesting (mostly in Portuguese):</p> <ul> <li> <p>SDumont support manual: https://sdumont.lncc.br/support_manual.php</p> </li> <li> <p>LNCC Youtube channel: https://www.youtube.com/@LNCCbr</p> </li> <li> <p>2015 Simple presentation including some photos of the physical construction of the facilities: https://www.slideshare.net/RobsondaCosta2/supercomputador-sdumont-top500org-146-2015</p> </li> <li> <p>2016 Presentation. First SDumont architecture when it was first deployed: https://sdumont.lncc.br/media/01_General_overview_of_SANTOS_DUMONT_architecture.pdf</p> </li> </ul> <p>More info:</p> <ul> <li>https://eviden.com/insights/press-releases/eviden-expands-lncc-santos-dumont-supercomputer-capacity-fourfold-to-meet-growing-needs-of-academic-community/</li> </ul>"},{"location":"blog/2024/02/03/top-2023/","title":"Brazil supercomputers top500 nov2023","text":"<p>Brazil currently has 9 supercomputers on the TOP500 list. The 500 most potent non-distributed computer systems in existence are ranked and described in detail by the TOP500 project. The last time LNCC's SDumont was included in the list, November 2022, it was in position 462.</p> <p>https://top500.org/</p> <p>The following list can be obtained directly from the top500.org website.</p> Rank System Cores Rmax (PFlop/s) Rpeak (PFlop/s) Power (kW) 45 P\u00e9gaso - Supermicro A+ Server 4124GO-NART+, AMD EPYC 7513 32C 2.6GHz, NVIDIA A100, Infiniband HDR, EVIDEN Petrobr\u00e1s Brazil 233,856 19.07 42.00 1,033 88 Drag\u00e3o - Supermicro SYS-4029GP-TVRT, Xeon Gold 6230R 26C 2.1GHz, NVIDIA Tesla V100, Infiniband EDR, EVIDEN Petrobr\u00e1s Brazil 188,224 8.98 14.01 943 111 Gaia - PowerEdge XE8545, AMD EPYC 74F3 24C 3.2GHz, NVIDIA A100, Infiniband, DELL EMC Petrobr\u00e1s Brazil 84,480 6.97 13.73 574 169 Atlas - Bull 4029GP-TVRT, Xeon Gold 6240 18C 2.6GHz, NVIDIA Tesla V100, Infiniband EDR, EVIDEN Petrobr\u00e1s Brazil 91,936 4.38 8.85 547 197 Gemini - PowerEdge XE8545, AMD EPYC 74F3 24C 3.2GHz, NVIDIA A100, Infiniband, DELL EMC Petrobr\u00e1s Brazil 42,240 3.86 6.86 287 205 IARA - NVIDIA DGX A100, AMD EPYC 7742 64C 2.25GHz, NVIDIA A100 SXM4 40 GB, Infiniband, Nvidia SiDi Brazil 24,800 3.66 4.13 217 NOBZ1 - ThinkSystem C2397, Xeon Platinum 8280 28C 2.7GHz, Broadcom, Lenovo Software Company MBZ Brazil 80,640 3.55 6.97 245 F\u00eanix - Bull 4029GP-TVRT, Xeon Gold 5122 4C 3.6GHz, NVIDIA Tesla V100, Infiniband EDR, EVIDEN Petrobr\u00e1s Brazil 60,480 3.16 5.37 390 475 A16A - ThinkSystem C0366, Xeon Gold 6252 24C 2.1GHz, 100G Ethernet, Lenovo Software Company MBZ Brazil 61,440 2.09 4.13 <p>SDumont on nov 2022 list</p> Rank System Cores Rmax (PFlop/s) Rpeak (PFlop/s) Power (kW) 462 Santos Dumont (SDumont) - Bull Sequana X1000, Xeon Gold 6252 24C 2.1GHz, Mellanox InfiniBand EDR, NVIDIA Tesla V100 SXM2, EVIDEN Laborat\u00f3rio Nacional de Computa\u00e7\u00e3o Cient\u00edfica Brazil 33,856 1.85 2.73 <p>SDumont is a Brazilian public supercomputer dedicated to teaching and research, and is the main machine of SINAPAD. The manufacturer is the French company Atos/Bull and has an installed processing capacity of around 5.1 petaflops peak, divided into 8 partitions: 4 partitions with CPU, 3 partitions with CPU + GPU, and 1 partition with CPU + Xeon Phi. SDumont should be in the TOP 500 with this capacity, but because it is partitioned, it can only run Linpack Benchmark on a single partition, only this being taken into consideration by the TOP500. A new upgrade is planned for 2024, boosting its capacity to 23 petaflops.</p>","tags":["top500"]},{"location":"blog/2024/02/02/wscad/","title":"WSCAD and SBAC-PAD","text":"<p>The Symposium on High Performance Computing Systems (WSCAD), a national event organized by the Brazilian Computing Society (SBC) and the Institute of Electrical and Electronic Engineers (IEEE), aims to highlight the main developments, applications and trends in Computer Science. Computing for distributed systems, high-performance processing and architecture. The IEEE International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD) is usually held annually in conjunction with the WSCAD event in October.</p> <p>http://wscad.sbc.org.br/edicoes/edicoes.html</p> <ul> <li>WSCAD conference proceedings: http://wscad.sbc.org.br/edicoes/edicoes.html</li> <li>WSCAD 2023 edition: https://inf.pucrs.br/wscad2023/</li> <li>WSCAD 2022 edition: http://wscad.sbc.org.br/</li> <li>Brazilian Computer Society (SBC) YouTube channel: https://www.youtube.com/@sbcoficial</li> </ul>"},{"location":"blog/2024/02/16/zenodo/","title":"Zenodo","text":"<p>Zenodo is a general-purpose open repository developed under the European OpenAIRE program and operated by the European Organization for Nuclear Research (CERN) and allows the deposit of research articles, datasets, research software, reports and any other related digital artifacts to research. For each submission, a persistent digital object identifier (DOI) is created, which makes stored items easily citable. It also allows the deposit of data sets of up to 50 GB. One supported source is GitHub repositories. It is hosted on CERN's high-performance computing infrastructure that is operated primarily for the needs of high-energy physics.</p> <p>https://zenodo.org/</p> <p>Lecture describing the use: https://youtu.be/6tum4jq4mNs (in Portuguese)</p>","tags":["Zenodo"]},{"location":"blog/2023/08/24/zotero/","title":"Zotero","text":"<p>I use Zotero in my daily life to do my research. Zotero is a free and open source reference manager for bibliographic data and research materials. It features integration with web browsers, word processors, Google Docs, generation of in-text citations, footnotes and bibliographies, and has a built-in PDF reader with annotation capabilities. It was originally created at the Center for History and New Media at George Mason University.</p> <ul> <li>Website: https://www.zotero.org/</li> <li>Zotero on Wikipedia: https://pt.wikipedia.org/wiki/Zotero</li> <li>How To Use Zotero (A Complete Beginner's Guide): https://youtu.be/JG7Uq_JFDzE</li> </ul>","tags":["Zotero"]},{"location":"blog/2025/11/23/opti-scie-work/","title":"Optimizing Scientific Workloads","text":"<p>Optimizing Scientific Workloads: Architectural Constraints and Algorithmic Strategies.</p> <p>The efficiency of scientific computing is governed by the synergy between hardware architecture and software implementation. This analysis explores the technical transition from consumer-grade legacy processors (Ivy Bridge and Sandy Bridge microarchitectures) to enterprise-grade server architectures (Broadwell), detailing the implications for instruction sets, virtualization, and cache memory management. Furthermore, it examines strategies for optimizing Fortran code to exploit these architectural distinctives through manual loop tiling and compiler-driven transformations using the Graphite framework.</p>"},{"location":"blog/2025/11/23/opti-scie-work/#1-architectural-evolution-and-hardware-constraints","title":"1. Architectural Evolution and Hardware Constraints","text":"<p>A comparative analysis was conducted between legacy desktop/mobile processors and server-grade processors to understand the shift in processing capability. The subjects of analysis are the Intel Core i5-3330 (Desktop), Intel Core i5-3210M (Mobile), and Intel Core i7-2630QM (Mobile) versus the Intel Xeon E5-2680 v4 (Server).</p>"},{"location":"blog/2025/11/23/opti-scie-work/#11-core-architecture-and-physical-resources","title":"1.1 Core Architecture and Physical Resources","text":"<p>Clock frequency is often a deceptive performance metric in parallelized workloads.</p> <ul> <li>Legacy Mobile (i5-3210M): Despite the \"i5\" designation, this processor possesses only 2 physical cores, utilizing Hyper-Threading to simulate 4 threads.</li> <li>Legacy Desktop (i5-3330): Features 4 physical cores. In computational tasks, 4 physical cores significantly outperform 2 physical cores with hyper-threading, regardless of similar clock speeds.</li> <li>Server Enterprise (Xeon E5-2680 v4): Utilizing the Broadwell architecture (14nm), this processor offers 14 physical cores and 28 threads. The architectural improvements in Instructions Per Cycle (IPC) allow it to outperform legacy processors even at lower base clock speeds (2.4 GHz vs. 3.0 GHz) (Hennessy &amp; Patterson, 2017).</li> </ul>"},{"location":"blog/2025/11/23/opti-scie-work/#12-instruction-set-extensions-and-security","title":"1.2 Instruction Set Extensions and Security","text":"<p>The transition to the Broadwell architecture introduces critical instruction sets absent in the Ivy Bridge and Sandy Bridge generations.</p> <ul> <li>AVX vs. AVX2: The i5-3330 and i5-3210M support Advanced Vector Extensions (AVX), which handle 256-bit floating-point operations. However, they lack AVX2. AVX2 expands integer vector operations to 256 bits, a critical feature for modern Linux kernels (e.g., Ubuntu 24.04) and neural network quantization. The E5-2680 processor supports AVX2.</li> <li>Virtualization (VT-d): Virtualization Technology for Directed I/O (VT-d) is essential for passing physical hardware directly to virtual machines (PCI passthrough). While the i5-3330 supports this, the older i7-2630QM (Sandy Bridge) frequently lacks reliable VT-d support, limiting its utility in containerized environments.</li> <li>Security Primitives (RDRAND): Ivy Bridge processors include the <code>RDRAND</code> instruction for hardware-based entropy generation, crucial for cryptographic operations in SSH. The older Sandy Bridge architecture relies on slower software-based entropy.</li> </ul>"},{"location":"blog/2025/11/23/opti-scie-work/#2-memory-hierarchy-and-cache-optimization","title":"2. Memory Hierarchy and Cache Optimization","text":"<p>Performance in scientific computing is often bottlenecked by memory latency. The L3 cache size varies drastically between the analyzed platforms:</p> <ul> <li>i5-3210M: 3 MB</li> <li>i5-3330: 6 MB</li> <li>Xeon E5-2680 v4: 35 MB</li> </ul> <p>To leverage these caches, software must be optimized to minimize data movement between the CPU and main RAM.</p>"},{"location":"blog/2025/11/23/opti-scie-work/#21-the-mathematical-model-for-loop-tiling","title":"2.1 The Mathematical Model for Loop Tiling","text":"<p>Loop tiling (or cache blocking) partitions large matrix iterations into sub-blocks that fit entirely within the CPU's cache. The optimal block size (\\(B\\)) is determined by the size of the L3 cache (\\(C_{L3}\\)) and the data type size. For a matrix multiplication involving three double-precision matrices (8 bytes per element), the constraint is:</p> <p>$ 3 \\times B^2 \\times \\text{sizeof(double)} &lt; C_{L3} $</p> <p>$ 24 \\times B^2 &lt; C_{L3} $</p> <p>$ B &lt; \\sqrt{\\frac{C_{L3}}{24}} $</p> <p>Applying this model yields the following optimal block sizes:</p> <ul> <li>Mobile (3 MB): \\(B \\approx 250\\)</li> <li>Desktop (6 MB): \\(B \\approx 400\\)</li> <li>Server (35 MB): \\(B \\approx 1200\\)</li> </ul>"},{"location":"blog/2025/11/23/opti-scie-work/#22-manual-implementation-in-fortran","title":"2.2 Manual Implementation in Fortran","text":"<p>The following implementation utilizes the C Preprocessor to adapt the block size at compile time, ensuring code portability.</p> <pre><code>program matrix_mult_tiled\n    implicit none\n\n! Preprocessor checks for defined block size\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 128\n#endif\n\n    integer, parameter :: n = 4096\n    integer, parameter :: b = BLOCK_SIZE\n    real(8), dimension(n,n) :: A, B, C\n    integer :: i, j, k, ii, jj, kk\n\n    ! TILING ALGORITHM\n    ! External loops control the blocks (ii, jj, kk)\n    do ii = 1, n, b\n        do jj = 1, n, b\n            do kk = 1, n, b\n                ! Internal loops process the block within cache\n                do i = ii, min(ii+b-1, n)\n                    do k = kk, min(kk+b-1, n)\n                        do j = jj, min(jj+b-1, n)\n                            C(i,j) = C(i,j) + A(i,k) * B(k,j)\n                        end do\n                    end do\n                end do\n            end do\n        end do\n    end do\nend program matrix_mult_tiled\n</code></pre> <p>Compilation Commands:</p> <p>To compile specifically for the desktop architecture (6 MB cache): <pre><code>gfortran -O3 -march=native -cpp -DBLOCK_SIZE=400 matrix_block.f90 -o matrix_desktop\n</code></pre></p>"},{"location":"blog/2025/11/23/opti-scie-work/#3-compiler-driven-optimization-graphite","title":"3. Compiler-Driven Optimization (Graphite)","text":"<p>Modern compilers, such as GCC, include polyhedral optimization frameworks (Graphite) to automate these transformations via specific flags.</p>"},{"location":"blog/2025/11/23/opti-scie-work/#31-loop-interchange-floop-interchange","title":"3.1 Loop Interchange (<code>-floop-interchange</code>)","text":"<p>Fortran adheres to Column-Major Order, meaning contiguous memory addresses are stored column by column. Naive nested loops often access data in row-major order, causing cache thrashing.</p> <ul> <li>Inefficient Access (Row-Major Logic): <pre><code>DO j = 1, N\n   DO i = 1, N\n      A(j, i) = ... ! 'j' (row index) changes slowly\n   END DO\nEND DO\n</code></pre></li> <li>Optimized Access (Column-Major Logic):   The <code>-floop-interchange</code> flag detects inefficient access patterns and effectively rewrites the binary to iterate column-by-column:   <pre><code>DO i = 1, N\n   DO j = 1, N\n       A(j, i) = ... ! 'j' varies fast, respecting memory layout\n   END DO\nEND DO\n</code></pre></li> </ul>"},{"location":"blog/2025/11/23/opti-scie-work/#32-strip-mining-floop-strip-mine","title":"3.2 Strip Mining (<code>-floop-strip-mine</code>)","text":"<p>This optimization acts as the \"Slicer.\" It transforms a single large loop into a nest of two loops: one that iterates over \"strips\" (segments) and one that processes the data within a strip.</p> <ul> <li>Original Loop: <pre><code>DO i = 1, 10000\n   A(i) = B(i) + C(i)\nEND DO\n</code></pre></li> <li>Transformed by Strip Mining: <pre><code>! The compiler creates \"strips\" suitable for vector registers\nDO ii = 1, 10000, STRIP_SIZE\n   DO i = ii, min(ii + STRIP_SIZE - 1, 10000)\n      A(i) = B(i) + C(i)\n   END DO\nEND DO\n</code></pre> While strip mining alone does not drastically improve performance, it is a prerequisite for vectorization (AVX) and, when combined with loop interchange, enables automatic cache blocking (Wolfe, 1989).</li> </ul>"},{"location":"blog/2025/11/23/opti-scie-work/#33-automatic-compilation-strategy","title":"3.3 Automatic Compilation Strategy","text":"<p>To apply these optimizations automatically without modifying the source code, the following command is used. Note that <code>libisl</code> (Integer Set Library) must be installed.</p> <pre><code>gfortran -O3 -march=native -floop-interchange -floop-strip-mine -floop-block matrix_naive.f90 -o matrix_auto\n</code></pre>"},{"location":"blog/2025/11/23/opti-scie-work/#references","title":"References","text":"<p>Hennessy, J. L., &amp; Patterson, D. A. (2017). Computer architecture: A quantitative approach (6th ed.). Morgan Kaufmann.</p> <p>Intel. (2016). Intel\u00ae 64 and IA-32 Architectures Optimization Reference Manual. Intel Corporation.</p> <p>Wolfe, M. (1989). More iteration space tiling. In Proceedings of the 1989 ACM/IEEE conference on Supercomputing (pp. 655-664). ACM. </p>"},{"location":"blog/2025/12/03/hpc-fort-opti/","title":"High-Performance Computing: The Fortran Optimization Manifesto","text":"<p>This post details the engineering journey to optimize the Binary Trees benchmark, aiming to surpass the performance of the fastest C++ implementation. Through rigorous profiling, micro-architectural analysis, and the application of modern Fortran techniques, we achieved a &gt;50% reduction in execution time (0.76s vs 1.60s) on an Intel Ivy Bridge architecture. This case study demonstrates that language choice is secondary to algorithmic understanding, memory architecture mastery, and compiler-assisted optimization.</p>"},{"location":"blog/2025/12/03/hpc-fort-opti/#1-introduction-and-context","title":"1. Introduction and Context","text":"<p>In the realm of High-Performance Computing (HPC), the \"Computer Language Benchmarks Game\" serves as a rigorous testing ground for compiler efficiency and runtime performance. The Binary Trees benchmark is particularly punishing; it stresses the memory allocator and the CPU's branch predictor rather than raw floating-point throughput.</p> <p>The objective was absolute: utilize Modern Fortran (2018+) to beat the state-of-the-art C++ solution, which utilizes <code>std::pmr</code> (Polymorphic Memory Resources) and template metaprogramming.</p>"},{"location":"blog/2025/12/03/hpc-fort-opti/#11-hardware-environment-the-constraints","title":"1.1. Hardware Environment (The Constraints)","text":"<p>Optimization is meaningless without context. Our target architecture imposes specific physical limits:</p> <ul> <li>CPU: Intel\u00ae Core\u2122 i5-3210M (Ivy Bridge Mobile, 22nm).</li> <li>Topology: 2 Physical Cores / 4 Threads.</li> <li>Frequency: 2.50 GHz (Turbo 3.10 GHz).</li> <li>Cache: 3MB L3, 256KB L2, 32KB L1.</li> <li>Memory: DDR3.</li> <li>OS: Ubuntu 22.04 LTS (Linux Kernel 6.8.0).</li> </ul> <p>Implication: The Ivy Bridge architecture relies heavily on its Hardware Prefetcher. Optimizations must ensure linear memory access patterns to exploit this. The relatively small L1 cache demands strict data locality.</p>"},{"location":"blog/2025/12/03/hpc-fort-opti/#2-the-baseline-c-supremacy","title":"2. The Baseline: C++ Supremacy","text":"<p>The reference implementation is C++ g++ #7. Its performance dominance stems from three factors:</p> <ol> <li>Monotonic Memory Resource: It avoids the operating system's heap (<code>malloc/free</code>) by using a stack-like allocator (<code>std::pmr::monotonic_buffer_resource</code>).</li> <li>Compile-Time Evaluation: Heavy use of C++ templates generates specialized assembly for specific tree depths.</li> <li>Structure: It utilizes pointers (<code>Node* left, right</code>) which map directly to the hardware's addressing mode.</li> </ol> <p>Baseline Metrics (C++ on Target Hardware):</p> <ul> <li>Time: 1.605s</li> <li>Instructions: ~26.49 Billion</li> <li>Cache Misses: ~11.7 Million</li> <li>IPC: 1.58</li> </ul>"},{"location":"blog/2025/12/03/hpc-fort-opti/#3-the-optimization-roadmap-a-forensic-approach","title":"3. The Optimization Roadmap: A Forensic Approach","text":"<p>We adopted a multi-stage optimization strategy, iterating based on telemetry from Linux <code>perf</code> tools.</p>"},{"location":"blog/2025/12/03/hpc-fort-opti/#31-memory-architecture-the-apache-runtime-arena","title":"3.1. Memory Architecture: The Apache Runtime Arena","text":"<p>Standard Fortran <code>ALLOCATE</code> and <code>DEALLOCATE</code> incur massive overhead due to system calls and metadata management. To compete with C++'s <code>std::pmr</code>, we implemented a Region-Based Memory Management system (Arena).</p>"},{"location":"blog/2025/12/03/hpc-fort-opti/#the-compliance-strategy","title":"The Compliance Strategy","text":"<p>The benchmark rules prohibit \"rolling your own\" custom allocators but allow standard external libraries. We utilized the Apache Portable Runtime (APR) via <code>ISO_C_BINDING</code>.</p> <ul> <li>Technique: We request massive blocks of raw memory using <code>apr_palloc</code> (a C library function).</li> <li>Fortran Implementation: We map this C-pointer to a Fortran array using <code>c_f_pointer</code>.</li> <li>Allocation Cost: \\(O(1)\\). We simply increment an integer cursor (<code>cur = cur + 1</code>).</li> <li>Deallocation Cost: \\(O(1)\\). We reset the cursor to 0.</li> </ul>"},{"location":"blog/2025/12/03/hpc-fort-opti/#32-data-layout-the-aos-breakthrough","title":"3.2. Data Layout: The \"AoS\" Breakthrough","text":"<p>In HPC, data layout dictates cache efficiency.</p> <ul> <li>Initial Attempt (SoA): Separate arrays for <code>Left_Children</code> and <code>Right_Children</code>. This failed to beat C++ because accessing a node required two disjoint memory lookups.</li> <li>Final Solution (AoS - Array of Structs): We implemented a 2D array <code>integer(4) :: d(2, N)</code>.<ul> <li><code>d(1, i)</code> is the Left Child.</li> <li><code>d(2, i)</code> is the Right Child.</li> <li>Why it wins: Fortran stores arrays in Column-Major order. This ensures that <code>d(1,i)</code> and <code>d(2,i)</code> are physically adjacent in RAM. A single cache line fetch retrieves both children, maximizing bandwidth utilization.</li> </ul> </li> </ul>"},{"location":"blog/2025/12/03/hpc-fort-opti/#33-pointer-compression-32-bit-indices","title":"3.3. Pointer Compression (32-bit Indices)","text":"<p>Modern CPUs are 64-bit, meaning standard pointers consume 8 bytes.</p> <ul> <li>Optimization: We replaced pointers with <code>integer(4)</code> indices.</li> <li>Impact: This reduces the node size by 50%. We effectively double the capacity of the L3 Cache (3MB), significantly reducing cache misses compared to the C++ pointer-based implementation.</li> </ul>"},{"location":"blog/2025/12/03/hpc-fort-opti/#34-algorithmic-transformation-aggressive-manual-unrolling","title":"3.4. Algorithmic Transformation: Aggressive Manual Unrolling","text":"<p>Telemetry showed that the C++ compiler was unwinding recursion better than GFortran. We responded with Aggressive Manual Batch Allocation.</p> <p>Instead of allocating one node at a time, our recursive constructor <code>make_tree</code> allocates entire subtrees (Depth 0, 1, 2, and 3) in a single block.</p> <pre><code>! Batch Allocation for Depth 3 (15 Nodes at once)\nif (depth == 3) then\n   base = pool%cursor\n   pool%cursor = base + 15 ! Single atomic update to cursor\n   ! ... 15 nodes initialized linearly ...\n   pool%nodes(1, base+2) = base+3; pool%nodes(2, base+2) = base+6\n   ! ...\n   return\nend if\n</code></pre> <p>Benefit:</p> <ol> <li>Store-Level Parallelism: The CPU can issue multiple memory writes in parallel because the addresses are known offsets.</li> <li>Elimination of Calls: This covers 93.75% of all nodes in the tree, effectively turning a recursive algorithm into a linear memory fill operation.</li> </ol>"},{"location":"blog/2025/12/03/hpc-fort-opti/#35-parallelism-zero-overhead-scheduling","title":"3.5. Parallelism: Zero-Overhead Scheduling","text":"<p>OpenMP's <code>schedule(dynamic)</code> incurs runtime overhead. Since binary trees are perfectly balanced, the workload is deterministic.</p> <ul> <li>Strategy: We utilized <code>schedule(static)</code>.</li> <li>Locality: We moved the <code>Arena</code> structure to the Thread Stack (inside the parallel region). This guarantees that memory used by Thread A is physically distant from Thread B, eliminating False Sharing (cache line contention) without requiring padding.</li> </ul>"},{"location":"blog/2025/12/03/hpc-fort-opti/#4-forensic-analysis-the-verdict","title":"4. Forensic Analysis: The Verdict","text":"<p>The final comparison reveals why the Fortran implementation is superior. It is not about \"speed\"; it is about efficiency.</p>"},{"location":"blog/2025/12/03/hpc-fort-opti/#41-the-scoreboard","title":"4.1. The Scoreboard","text":"Metric C++ (Baseline) Fortran (Optimized) Delta Interpretation Time (s) 1.605 0.769 -52.1% Fortran is more than 2x faster. Instructions 26.49 Billion 9.75 Billion -63.2% The key victory. We solved the problem with 3x less code execution. CPU Cycles 16.73 Billion 7.11 Billion -57.5% The hardware worked for less than half the time. Cache Misses 11.71 Million 3.92 Million -66.5% Architecture Dominance. 32-bit indices + AoS layout fit 3x more data in cache. Branch Misses 3.33 Million 0.39 Million -88.1% Manual unrolling made the execution path perfectly predictable."},{"location":"blog/2025/12/03/hpc-fort-opti/#42-why-fortran-won","title":"4.2. Why Fortran Won?","text":"<ol> <li>Lower Abstraction Penalty: Modern Fortran arrays (<code>contiguous</code>) map directly to hardware vectors. We bypassed the \"object-oriented tax\" that C++ pays.</li> <li>Instruction Density: By manually unrolling the tree creation (Depth 3), we removed billions of <code>CALL</code> and <code>RET</code> instructions.</li> <li>Memory Bandwidth: The combination of 32-bit indices (vs 64-bit pointers) reduced the memory bandwidth requirement by half.</li> </ol>"},{"location":"blog/2025/12/03/hpc-fort-opti/#5-the-advantages-of-modern-fortran-for-hpc","title":"5. The Advantages of Modern Fortran for HPC","text":"<p>This experiment disproves the notion that Fortran is archaic. It demonstrates specific advantages over C/C++ in HPC contexts:</p> <ol> <li>Strict Aliasing by Default: Fortran assumes arrays do not overlap unless specified. This allows the compiler (<code>gfortran</code>) to apply aggressive vectorization (<code>AVX</code>).</li> <li>Array-Oriented Syntax: Operations like slicing <code>array(1:n)</code> are intrinsic. In our code, the layout <code>d(:,:)</code> allowed the compiler to understand the memory stride perfectly.</li> <li>Clean Module System: The <code>module</code> system provides encapsulation without the header/source duplication of C++.</li> <li>Zero-Overhead Interoperability: The <code>ISO_C_BINDING</code> module allowed us to use the <code>libapr</code> C library seamlessly.</li> </ol>"},{"location":"blog/2025/12/03/hpc-fort-opti/#6-how-to-reproduce-step-by-step-guide","title":"6. How to Reproduce (Step-by-Step Guide)","text":"<p>To verify these results on a Debian/Ubuntu system:</p>"},{"location":"blog/2025/12/03/hpc-fort-opti/#61-dependencies","title":"6.1. Dependencies","text":"<pre><code>sudo apt-get install gfortran libapr1-dev linux-tools-common linux-tools-generic\n</code></pre>"},{"location":"blog/2025/12/03/hpc-fort-opti/#62-compilation-with-pgo-profile-guided-optimization","title":"6.2. Compilation with PGO (Profile Guided Optimization)","text":"<p>Critical Step: We use PGO to inform the branch predictor of the tree traversal patterns.</p> <pre><code># 1. Instrument\ngfortran -std=f2018 -O3 -march=native -flto -fopenmp \\\n    -funroll-loops -floop-nest-optimize \\\n    --param max-inline-insns-single=1200 --param max-inline-insns-auto=1000 \\\n    -fprofile-generate \\\n    binarytrees.f90 -o binarytrees -lapr-1\n\n# 2. Train (Single threaded to avoid race conditions in .gcda files)\nexport OMP_NUM_THREADS=1\n./binarytrees_train 18 &gt; /dev/null\nunset OMP_NUM_THREADS\n\n# 3. Optimize\ngfortran -std=f2018 -O3 -march=native -flto -fopenmp \\\n    -funroll-loops -floop-nest-optimize \\\n    --param max-inline-insns-single=1200 --param max-inline-insns-auto=1000 \\\n    -fprofile-use -fprofile-correction \\\n    binarytrees.f90 -o binarytrees -lapr-1\n</code></pre>"},{"location":"blog/2025/12/03/hpc-fort-opti/#63-verification","title":"6.3. Verification","text":"<pre><code>./binarytrees 21\n</code></pre>"},{"location":"blog/2025/12/03/hpc-fort-opti/#7-the-final-source-code","title":"7. The Final Source Code","text":"<p>https://github.com/efurlanm/fortran/blob/main/btree/binarytrees.f90</p>"},{"location":"blog/2025/09/02/pinn-smar-trai/","title":"Unpacking an Advanced Parametric PINN: A Deep Dive into Smart Training Techniques","text":"<p>Physics-Informed Neural Networks (PINNs) have emerged as a powerful tool for solving differential equations, but how can we make them more robust, efficient, and capable of solving entire families of problems? The answer lies in advanced training strategies that guide the network toward a better solution.</p> <p>This post will deconstruct the key components of an advanced parametric PINN, using a Python script that solves the 2D Burgers' equation as our practical example. We'll explore how techniques like curriculum learning, adaptive weighting, and intelligent learning rate scheduling come together to create a powerful and generalizable model.</p>"},{"location":"blog/2025/09/02/pinn-smar-trai/#the-core-concepts-what-makes-this-pinn-advanced","title":"The Core Concepts: What Makes This PINN \"Advanced\"?","text":"<p>Before diving into the code, let's briefly define the three core strategies that elevate a standard PINN.</p> <ul> <li> <p>Curriculum Learning \ud83e\udde0: This strategy organizes the training from easiest to hardest. Instead of confronting the model with the most complex version of the problem at the start, we begin with a simplified version and gradually increase the complexity. This helps the optimizer avoid bad local minima and accelerates overall convergence. Think of it as learning to add before attempting calculus.</p> </li> <li> <p>Adaptive Weighting \u2696\ufe0f: The loss function in a PINN is a composite of several terms: the PDE residual, boundary conditions, and initial conditions. Adaptive weighting dynamically balances the importance of each of these terms during training, ensuring that the network learns to satisfy all physical constraints of the problem simultaneously, leading to a more accurate solution.</p> </li> <li> <p>ReduceLROnPlateau Callback \ud83d\udcc9: This is an intelligent mechanism for adjusting the learning rate (\\(LR\\)). It monitors the training loss and, if it stops improving for a set number of epochs (hits a \"plateau\"), it automatically reduces the learning rate. This allows the optimizer to take smaller, more precise steps to refine the solution and escape plateaus.</p> </li> </ul>"},{"location":"blog/2025/09/02/pinn-smar-trai/#a-practical-look-at-curriculum-learning-in-python","title":"A Practical Look at Curriculum Learning in Python","text":"<p>The most insightful strategy is Curriculum Learning. The goal is to train a single PINN that can solve the Burgers' equation for a range of kinematic viscosity values (<code>nu</code>), for instance, from <code>0.01</code> to <code>0.1</code>.</p> <p>Instead of randomly sampling <code>nu</code> from the entire range from the very beginning, the script implements a curriculum.</p> <ol> <li>At the start of training: The network is only given problems with <code>nu</code> in a smaller, easier range, like <code>[0.01, 0.06]</code>.</li> <li>As training progresses: This range is gradually expanded.</li> <li>By the end of training: The network is learning from the full range of <code>[0.01, 0.1]</code>.</li> </ol> <p>This approach allows the network to build a solid foundation with simpler physics before generalizing to more complex cases.</p>"},{"location":"blog/2025/09/02/pinn-smar-trai/#how-it-works-in-the-code","title":"How It Works in the Code","text":"<p>This logic is implemented within the <code>fit</code> method's main training loop. At each epoch, new random points (collocation points) are generated to test the model's adherence to the physics.</p> <p>First, spatial and temporal points are sampled randomly within the domain.</p> <pre><code># Inside the fit method:\nfor epoch in range(epochs_adam):\n    # Generates 10,000 random (x, y, t) points each epoch\n    x_pde_batch = tf.constant(np.random.uniform(x_min, x_max, (num_pde_points, 1))...\n    y_pde_batch = tf.constant(np.random.uniform(y_min, y_max, (num_pde_points, 1))...\n    t_pde_batch = tf.constant(np.random.uniform(t_min, t_max, (num_pde_points, 1))...\n</code></pre> <p>Next, and most importantly, the curriculum for <code>nu</code> is applied. The code calculates the training progress and uses it to define the upper limit for <code>nu</code> sampling in the current epoch.</p> <pre><code># Continuing inside the loop in fit:\n    # 1. Calculate training progress (from 0.0 to 1.0)\n    progress = epoch / epochs_adam\n\n    # 2. Define the max 'nu' for this epoch, increasing it linearly\n    current_nu_max = self.nu_min_train + (total_nu_range * progress)\n\n    # 3. Ensure a minimum starting range for stability\n    current_nu_max = max(current_nu_max, self.nu_min_train + nu_start_range)\n\n    # 4. Sample 10,000 'nu' values from the current curriculum range\n    nu_pde_batch = tf.constant(np.random.uniform(self.nu_min_train, current_nu_max, (num_pde_points, 1))...\n</code></pre> <p>A Concrete Example:</p> <p>With the script's parameters (<code>epochs_adam = 5000</code>, <code>nu_min_train = 0.01</code>, <code>nu_max_train = 0.1</code>, <code>nu_start_range = 0.05</code>):</p> <ul> <li>At Epoch 0 (Start): <code>progress</code> is 0.0. The <code>current_nu_max</code> is set to <code>0.06</code>. The network trains on <code>nu</code> values sampled from <code>[0.01, 0.06]</code>.</li> <li>At Epoch 3000 (Mid-training): <code>progress</code> is 0.6. <code>current_nu_max</code> calculates to <code>0.064</code>. The difficulty has increased, and the network now trains on <code>nu</code> values from <code>[0.01, 0.064]</code>.</li> <li>At Epoch 5000 (End): <code>progress</code> is 1.0. <code>current_nu_max</code> is now <code>0.1</code>. The network is finally training on the complete range of <code>[0.01, 0.1]</code>.</li> </ul>"},{"location":"blog/2025/09/02/pinn-smar-trai/#demystifying-key-hyperparameters","title":"Demystifying Key Hyperparameters","text":"<p>The script's setup raises a couple of important questions about its configuration.</p>"},{"location":"blog/2025/09/02/pinn-smar-trai/#collocation-points-is-10000-a-magic-number","title":"Collocation Points: Is 10,000 a Magic Number?","text":"<p>Not necessarily, but in this specific script, yes, the value is set to 10,000. This number is a hyperparameter, meaning it's a configurable setting of the training process. It is defined in the experiment configuration section:</p> <pre><code># --- Experiment Configuration (Stage 1) ---\nnum_pde_points_stage1 = 10000 # &lt;-- Value defined here\n</code></pre> <p>This variable is then used during training to generate that many points at each epoch. A user could easily modify this value to experiment with more or fewer collocation points to see how it impacts training performance and accuracy.</p>"},{"location":"blog/2025/09/02/pinn-smar-trai/#setting-the-right-range-for-nu","title":"Setting the Right Range for <code>nu</code>","text":"<p>Is the training range <code>nu_min_train = 0.01</code> to <code>nu_max_train = 0.1</code> appropriate for a true <code>nu</code> value of <code>0.05</code>?</p> <p>Yes, this range is perfectly suitable. The primary reason is that the true value (<code>0.05</code>) is comfortably contained within the training range (<code>[0.01, 0.1]</code>). This is critical for two reasons:</p> <ol> <li>Goal of Parametric Training (Stage 1): The first training stage aims to create a general model that understands the physics for any <code>nu</code> within the specified range. By training on a range that includes <code>0.05</code>, the network learns the correct physical behavior in that specific neighborhood.</li> <li>Preparation for the Inverse Problem (Stage 2): In the second stage, the goal is to discover the specific <code>nu</code> value from observed data. Because the model was trained in Stage 1 to understand the system's behavior across the entire <code>[0.01, 0.1]</code> range, it is well-prepared to accurately identify that the new data corresponds to a viscosity of <code>0.05</code>.</li> </ol>"},{"location":"blog/2025/09/02/pinn-smar-trai/#conclusion","title":"Conclusion","text":"<p>By implementing intelligent strategies like Curriculum Learning, this parametric PINN becomes more than just a solver for a single equation\u2014it becomes a generalizable tool capable of understanding a whole family of physical problems. The techniques discussed here are not just theoretical; they are practical, implementable methods that lead to more robust, stable, and accurate Physics-Informed Neural Networks.</p>"},{"location":"blog/2025/09/01/pinn-debug/","title":"Why Is My AI Failing at Physics? A Guide to Debugging Physics-Informed Neural Networks","text":"<p>Physics-Informed Neural Networks, or PINNs, represent a fascinating intersection of artificial intelligence and the natural sciences. Imagine you want to model a complex physical system, like the flow of water in a river or the formation of a traffic jam. You might have a few real-world measurements, but not nearly enough to train a traditional AI model. This is where PINNs shine. They are neural networks trained not just on data, but also on the mathematical equations that govern the system (Raissi et al., 2019). By baking the laws of physics directly into the training process, PINNs can often find accurate solutions even with very sparse data.</p> <p>One classic test for these models is the Burgers' equation, a relatively simple formula that describes how waves can steepen and form shocks, much like a wave breaking on a shore (Wight &amp; Zhao, 2020). The challenge gets even harder with the inverse problem: what if we have a few measurements of the wave, but we don't know a key physical property, like the water's viscosity? We want the PINN to not only model the wave but also to discover the missing viscosity parameter for us.</p> <p>This is where many practitioners hit a wall. The PINN fails to train, the loss stagnates, and the results are physically nonsensical. This isn't just a random bug; it's often a predictable series of failures. This post will walk you through why your PINN might be failing and provide a clear, actionable toolkit to fix it.</p>"},{"location":"blog/2025/09/01/pinn-debug/#how-a-pinn-learns-physics","title":"How a PINN \"Learns\" Physics","text":"<p>At its heart, a PINN learns by trying to minimize a multi-part objective, or \"loss function.\" Think of it as a final grade composed of scores from different subjects. The network must do well in all of them to pass.</p> <ul> <li> <p>Data Fidelity (\\(\\mathcal{L}_{data}\\)): This part of the score measures how well the network's prediction, \\(u(x, t)\\), matches the actual, sparse measurements we have. This is the traditional \"supervised learning\" component.</p> </li> <li> <p>Physics Residual (\\(\\mathcal{L}_{PDE}\\)): This is the core of a PINN. It checks how well the network's output satisfies the governing physical law\u2014in our case, the Burgers' equation. The network uses a technique called automatic differentiation to calculate the derivatives from the equation within the network itself, effectively \"testing\" its own solution against the laws of physics at thousands of random points in space and time (Lu et al., 2021). The 1D viscous Burgers' equation is written as:</p> </li> </ul> \\[\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x} - \\nu \\frac{\\partial^2 u}{\\partial x^2} = 0\\] <ul> <li>Boundary and Initial Conditions (\\(\\mathcal{L}_{BC}, \\mathcal{L}_{IC}\\)): These terms ensure the solution respects the problem's constraints, such as the state of the system at the beginning ( \\(t=0\\)) and at its spatial edges.</li> </ul> <p>The total loss is a sum of these components. The optimizer's job is to adjust the network's internal parameters (its weights and biases) and the unknown physical parameter (\\(\\nu\\), the viscosity) to find the lowest possible total loss.</p> \\[\\mathcal{L}_{total} = \\mathcal{L}_{data} + \\mathcal{L}_{PDE} + \\mathcal{L}_{IC} + \\mathcal{L}_{BC}\\]"},{"location":"blog/2025/09/01/pinn-debug/#the-cascade-of-failure-why-good-models-go-bad","title":"The Cascade of Failure: Why Good Models Go Bad","text":"<p>When a PINN fails on a problem like the Burgers' equation, it's rarely due to a single cause. Instead, it's a chain reaction of interconnected issues.</p>"},{"location":"blog/2025/09/01/pinn-debug/#the-root-cause-spectral-bias","title":"The Root Cause: Spectral Bias","text":"<p>Neural networks have a well-documented \"spectral bias.\" They are inherently good at learning smooth, low-frequency patterns first and struggle immensely with sharp, high-frequency features (Rahaman et al., 2019). The solution to the Burgers' equation often starts as a smooth wave but quickly develops a very sharp \"shock front\"\u2014a near-discontinuity. This creates a fundamental conflict: the physics of the problem produces exactly the kind of feature that the neural network is naturally bad at learning.</p>"},{"location":"blog/2025/09/01/pinn-debug/#the-consequence-unbalanced-and-pathological-gradients","title":"The Consequence: Unbalanced and Pathological Gradients","text":"<p>Because the network cannot easily approximate the sharp shock front, the physics loss (\\(\\mathcal{L}_{PDE}\\)) in that small region of spacetime becomes enormous. This, in turn, creates a massive, unbalanced gradient\u2014the signal that tells the optimizer how to update the network's parameters. The optimizer becomes fixated on this single, huge source of error, effectively ignoring the boundary conditions, the initial conditions, and the rest of the physical domain. The training process becomes \"stiff,\" where different parts of the loss function are evolving at vastly different rates, leading to instability and stagnation (Wang et al., 2021).</p>"},{"location":"blog/2025/09/01/pinn-debug/#the-result-overfitting-and-poor-generalization","title":"The Result: Overfitting and Poor Generalization","text":"<p>Faced with this difficult optimization landscape, the network often finds an \"escape route.\" If it can't satisfy the difficult physics of the shock, it might discover that it's easier to reduce the total loss by simply memorizing the few data points it was given. This leads to a classic case of overfitting. The model's output may pass exactly through the data points, but it violates the physical laws everywhere else. The resulting solution is physically meaningless, and the discovered value for the unknown parameter, \\(\\nu\\), is completely wrong (Krishnapriyan et al., 2021).</p>"},{"location":"blog/2025/09/01/pinn-debug/#a-practical-toolkit-for-fixing-a-failing-pinn","title":"A Practical Toolkit for Fixing a Failing PINN","text":"<p>Understanding this failure cascade allows us to intervene strategically. The following techniques are designed to break the chain reaction and guide the network toward a physically correct solution.</p>"},{"location":"blog/2025/09/01/pinn-debug/#1-use-a-hybrid-optimization-strategy","title":"1. Use a Hybrid Optimization Strategy","text":"<p>This is one of the most impactful changes you can make. Instead of relying on a single optimizer, use a two-phase approach.</p> <ul> <li>Phase 1: Adam Optimizer. Start the training with the Adam optimizer for several thousand iterations. Adam is excellent at navigating the rough, global loss landscape to quickly find a promising region for a good solution.</li> <li>Phase 2: L-BFGS Optimizer. After Adam has done the initial exploration, switch to a quasi-Newton optimizer like L-BFGS. L-BFGS is much more precise and can rapidly converge to the bottom of the minimum that Adam identified (Raissi et al., 2019). Many reported PINN failures are simply due to omitting this crucial second step.</li> </ul>"},{"location":"blog/2025/09/01/pinn-debug/#2-focus-the-networks-attention-where-it-matters","title":"2. Focus the Network's Attention Where It Matters","text":"<p>A key issue is that the network struggles with specific \"stubborn\" spots, like the shock front. We can force the network to pay more attention to these difficult areas.</p> <ul> <li>Adaptive Resampling (RAR): Instead of training on a fixed set of random points, periodically pause training, evaluate where the physics loss (\\(\\mathcal{L}_{PDE}\\)) is highest, and add new training points to those high-error regions. This technique, known as Residual-based Adaptive Refinement (RAR), forces the network to focus its capacity on the parts of the problem it finds most challenging (Lu et al., 2021).</li> <li>Self-Adaptive Weights: A more advanced and powerful approach is to let the network learn how to balance the loss function on its own. In Self-Adaptive PINNs (SA-PINNs), each individual training point in the loss function is assigned its own trainable weight. The network learns to automatically increase the weights for points where the error is high, creating a dynamic \"attention mechanism\" that forces it to focus on difficult regions (McClenny &amp; Braga-Neto, 2020). This directly counteracts the problem of unbalanced gradients.</li> </ul>"},{"location":"blog/2025/09/01/pinn-debug/#3-simplify-the-problem-with-hard-constraints","title":"3. Simplify the Problem with Hard Constraints","text":"<p>Often, we ask the network to learn the boundary and initial conditions by penalizing them in the loss function (so-called \"soft constraints\"). A more effective method is to build these conditions directly into the network's architecture, enforcing them by construction (\"hard constraints\"). For example, you can use a transformation of the network's output that mathematically guarantees it will satisfy the boundary conditions. This removes the \\(\\mathcal{L}_{BC}\\) and \\(\\mathcal{L}_{IC}\\) terms from the loss function, simplifying the optimization problem and reducing the potential for competing gradients (Krishnapriyan et al., 2021).</p>"},{"location":"blog/2025/09/01/pinn-debug/#your-setup-for-success","title":"Your Setup for Success","text":"<p>To put these ideas into practice, you don't need a supercomputer.</p> <ul> <li>Hardware: A single modern consumer or professional GPU (e.g., an NVIDIA RTX series or Titan X) is typically sufficient for problems like the 1D or 2D Burgers' equation (Raissi et al., 2019).</li> <li>Software &amp; Libraries: The standard environment is Python. You can build PINNs using core deep learning libraries like PyTorch or TensorFlow. For a more streamlined experience, consider specialized libraries like DeepXDE, which is built on top of these backends and provides a high-level API that closely resembles the mathematical formulation of the problem (Lu et al., 2021).</li> <li>Network Architecture: A good starting point for the Burgers' equation is a standard fully-connected neural network with 4 to 8 hidden layers and 20 to 50 neurons per layer. For the activation function, hyperbolic tangent (tanh) is often preferred over the more common ReLU, as its smoothness and non-zero derivatives are beneficial for calculating the physics-based loss terms (Wang et al., 2021).</li> </ul>"},{"location":"blog/2025/09/01/pinn-debug/#conclusion","title":"Conclusion","text":"<p>The failure of a PINN is rarely a mystery. It is often a predictable outcome of the fundamental mismatch between a network's natural tendencies and the complex, sharp features present in many physical systems. But by understanding this cascade of failure\u2014from spectral bias to gradient pathologies to overfitting\u2014we can employ a targeted set of powerful techniques to fix it. By using hybrid optimizers, focusing the network's attention on difficult regions, and simplifying the problem with hard constraints, you can transform a failing model into one that successfully solves the underlying physics and discovers the hidden parameters you seek.</p>"},{"location":"blog/2025/09/01/pinn-debug/#references","title":"References","text":"<p>Krishnapriyan, A. S., Gholami, A., Zhe, S., Kirby, R. M., &amp; Mahoney, M. W. (2021). Characterizing possible failure modes in physics-informed neural networks. arXiv. https://arxiv.org/abs/2109.01050</p> <p>Lu, L., Meng, X., Mao, Z., &amp; Karniadakis, G. E. (2021). DeepXDE: A deep learning library for solving differential equations. SIAM Review, 63(1), 208\u2013228.</p> <p>McClenny, L., &amp; Braga-Neto, U. (2020). Self-adaptive physics-informed neural networks using a soft attention mechanism. arXiv. https://arxiv.org/abs/2009.04544</p> <p>Rahaman, N., Baratin, A., Arpit, D., Draxler, F., Lin, M., Hampacher, F., Courville, A., &amp; Bengio, Y. (2019, May). On the spectral bias of neural networks. In International Conference on Machine Learning (pp. 5301\u20135310). PMLR.</p> <p>Raissi, M., Perdikaris, P., &amp; Karniadakis, G. E. (2019). Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. Journal of Computational Physics, 378, 686\u2013707.</p> <p>Wang, S., Teng, Y., &amp; Perdikaris, P. (2021). Understanding and mitigating gradient flow pathologies in physics-informed neural networks. SIAM Journal on Scientific Computing, 43(5), A3055\u2013A3081.</p> <p>Wight, C., &amp; Zhao, J. (2020). Solving the Burgers' equation with physics-informed neural networks. arXiv. https://arxiv.org/abs/2007.08914</p>"},{"location":"blog/2025/08/31/lm-trai/","title":"Achieving Scalable Performance on Commodity Hardware for Large Model Training","text":"<p>Training large-scale artificial intelligence models has become a defining challenge of the modern computational era, often perceived as a domain exclusive to those with access to state-of-the-art, unencumbered supercomputing infrastructure. However, recent advancements have demonstrated that exceptional performance can be achieved even with resource constraints and heterogeneous or restricted hardware. This is accomplished through a sophisticated synthesis of software optimization, algorithmic innovation, and a deep understanding of the underlying system architecture. This post delves into the technical strategies that enable high-throughput training, focusing on innovations in parallelism, communication, and low-precision arithmetic.</p>"},{"location":"blog/2025/08/31/lm-trai/#system-architecture-and-parallelism-strategy","title":"System Architecture and Parallelism Strategy","text":"<p>The foundation of large-scale training is a distributed system, typically comprising hundreds of server nodes, each equipped with multiple GPU accelerators. In one notable instance, a cluster of 256 nodes, each housing eight NVIDIA H800 GPUs (for a total of 2,048 units), was utilized. A key architectural detail is the internal connectivity within each node, where GPUs are linked via NVSwitches, enabling high-speed intra-node communication. The nodes themselves are interconnected using a high-speed fabric, such as InfiniBand, which is critical for efficient gradient and data exchange across the cluster.</p> <p>To effectively harness such a system, a hybrid parallelism strategy is often employed. The training workload is distributed using a combination of data parallelism and pipeline parallelism. Data parallelism involves replicating the model across multiple GPUs and feeding each replica a different subset of the training data. Pipeline parallelism, conversely, partitions the model's layers across a series of GPUs, with each GPU responsible for a specific stage of the computation. This hybrid approach is particularly effective in heterogeneous environments, where different hardware capabilities can be balanced by assigning them different roles in the pipeline (Park et al., 2020). By carefully designing the pipeline stages and data distribution, it is possible to maintain high utilization across all accelerators, even when tensor parallelism\u2014which partitions individual operations within a layer\u2014is avoided due to memory constraints.</p>"},{"location":"blog/2025/08/31/lm-trai/#overcoming-communication-bottlenecks","title":"Overcoming Communication Bottlenecks","text":"<p>A primary obstacle in scaling distributed training is the communication overhead associated with synchronizing model parameters and exchanging activations between computational stages. As the number of nodes increases, the time spent on communication can quickly dominate the total training time, diminishing the returns of adding more hardware.</p>"},{"location":"blog/2025/08/31/lm-trai/#the-dualpipe-algorithm","title":"The DualPipe Algorithm","text":"<p>To mitigate this, innovative algorithms that overlap communication and computation are essential. The DualPipe algorithm is one such technique designed for efficient pipeline parallelism. It intelligently schedules the forward and backward passes to minimize \"pipeline bubbles\"\u2014idle periods when GPUs are waiting for data from a preceding stage. A key aspect of this method is the co-opting of a small fraction of the GPU's streaming multiprocessors (SMs) to act as dedicated communication accelerators and schedulers. This offloads the scheduling and data transfer tasks from the main computational cores, allowing for a more seamless overlap of operations. Such communication optimization techniques are a cornerstone of efficient distributed learning, as they directly address the scalability limitations imposed by data exchange (Zhang et al., 2020).</p>"},{"location":"blog/2025/08/31/lm-trai/#high-speed-interconnects","title":"High-Speed Interconnects","text":"<p>The physical network fabric is equally crucial. High-bandwidth, low-latency interconnects like InfiniBand or specialized protocols such as NVIDIA's NVLink are not merely beneficial but essential. The performance of distributed training is highly sensitive to interconnect latency and bandwidth, as these factors directly dictate the speed of collective communication operations like <code>All-Reduce</code>, which are fundamental for synchronizing gradients in data parallelism. Research consistently shows that insufficient interconnect performance creates severe bottlenecks that lead to underutilization of expensive GPU resources and prolonged training times.</p>"},{"location":"blog/2025/08/31/lm-trai/#memory-and-precision-optimization","title":"Memory and Precision Optimization","text":"<p>With model sizes growing into the trillions of parameters, memory capacity becomes a critical constraint. A multi-faceted approach to memory optimization is required, encompassing both the precision of numerical representations and the strategic management of training artifacts.</p>"},{"location":"blog/2025/08/31/lm-trai/#low-precision-training","title":"Low-Precision Training","text":"<p>A significant reduction in memory footprint can be achieved by utilizing lower-precision numerical formats. While model weights and optimizer states are typically stored in higher precision (e.g., FP16 or BFloat16), the bulk of the matrix multiplication operations, which form the computational core of transformer models, can be performed in 8-bit floating-point (FP8) format. This not only halves the memory required for activations but also leverages specialized hardware units like NVIDIA's Tensor Cores for accelerated computation.</p> <p>Transitioning to low-precision formats is not trivial; it requires careful management to avoid catastrophic loss of fidelity. This involves techniques for \"microscaling\" the mantissas and exponents of data to preserve the necessary dynamic range. A common practice is to use formats like E4M3 (4-bit exponent, 3-bit mantissa) for tensor calculations while promoting intermediate results to higher precision within the vector units of the CUDA cores to maintain numerical stability during accumulation. The optimizer can maintain master copies of the weights in FP32, applying the low-precision updates to this high-fidelity version, thereby combining the memory savings of FP8 with the stability of FP32.</p>"},{"location":"blog/2025/08/31/lm-trai/#memory-offloading-and-recomputation","title":"Memory Offloading and Recomputation","text":"<p>Further memory savings can be realized through software techniques. One effective strategy is to recompute certain intermediate values during the backward pass rather than storing them in GPU memory after the forward pass. Operations like RMSNorm and specific linear projections are candidates for this \"activation checkpointing\" or recomputation, trading a modest increase in computational cost for a substantial reduction in memory usage. Additionally, less critical data, such as exponential moving average (EMA) parameters used by some optimizers, can be offloaded from the GPU's limited HBM to the more abundant CPU host memory, to be retrieved only when needed.</p>"},{"location":"blog/2025/08/31/lm-trai/#fault-tolerance-and-system-resilience","title":"Fault Tolerance and System Resilience","text":"<p>Finally, when training models on thousands of processors for weeks or months, hardware failures are not an exception but an expectation. Consequently, a robust fault tolerance strategy is indispensable. The conventional approach relies on periodic checkpointing, where the entire state of the training process (model weights, optimizer states, etc.) is saved to persistent storage. If a node fails, the entire job is stopped and restarted from the last valid checkpoint.</p> <p>However, recent research is exploring more dynamic and less disruptive methods. For instance, systems like \"Fault Tolerant Llama\" demonstrate the feasibility of continuing training with a reduced set of workers while failed nodes are being restored, using quorum-based mechanisms to ensure consistency (PyTorch Team, 2025). This avoids the significant downtime associated with the \"stop-the-world\" approach of traditional checkpointing, which is a promising direction for maximizing the efficiency and reliability of large-scale training endeavors.</p>"},{"location":"blog/2025/08/31/lm-trai/#conclusion","title":"Conclusion","text":"<p>The ability to train state-of-the-art models on less-than-ideal hardware is not a matter of brute force but of sophisticated engineering. Through a combination of hybrid parallelism, advanced communication-computation overlap algorithms, aggressive memory and precision optimization, and resilient system design, it is possible to construct highly performant and efficient training infrastructures. These strategies democratize access to large-scale model training and push the boundaries of what is computationally feasible.</p>"},{"location":"blog/2025/08/31/lm-trai/#bibliography","title":"Bibliography","text":"<p>Morgan, T. P. (2025, January 27). How did DeepSeek train its AI model on a lot less \u2013 and crippled \u2013 hardware? The Next Platform. https://www.nextplatform.com/2025/01/27/how-did-deepseek-train-its-ai-model-on-a-lot-less-and-crippled-hardware/</p> <p>Park, J. J., Nguyen, T., Lee, S., Choi, J., Noh, S. H., &amp; Choi, Y. (2020). HetPipe: Enabling Large DNN Training on (Whimpy) Heterogeneous GPU Clusters through Integration of Pipelined Model Parallelism and Data Parallelism. In 2020 USENIX Annual Technical Conference (ATC 20) (pp. 563-576). USENIX Association.</p> <p>PyTorch Team. (2025). Fault Tolerant Llama: training with 2000 synthetic failures every ~15 seconds and no checkpoints on Crusoe L40S. PyTorch Blog. Retrieved from https://pytorch.org/blog/fault-tolerant-llama-training-with-2000-synthetic-failures-every-15-seconds-and-no-checkpoints-on-crusoe-l40s/</p> <p>Zhang, H., Zheng, Z., Xu, S., Dai, W., Chen, H., Wang, J., ... &amp; Cui, B. (2020). Poseidon: An efficient communication architecture for distributed deep learning on {GPU} clusters. In 2020 USENIX Annual Technical Conference (ATC 20) (pp. 577-590). USENIX Association. </p>"},{"location":"blog/2025/08/30/pinn-burgers/","title":"Overcoming Generalization Challenges in 2D Burgers' Equation with Physics-Informed Neural Networks","text":"<p>Physics-Informed Neural Networks (PINNs) have emerged as a powerful paradigm in \"scientific machine learning,\" enabling the integration of physical laws, expressed as Partial Differential Equations (PDEs), into neural network training (Wang et al., 2021, p. 1; Lu et al., 2021, p. 208). While PINNs offer a promising avenue for solving complex, non-linear systems like the 2D Burgers' equation, ensuring robust generalization remains a critical challenge, particularly for solutions exhibiting multi-scale features, anisotropic behavior, or in data-poor environments. The 2D Burgers' equation is a fundamental non-linear PDE often used as a benchmark for such challenges (Raissi et al., 2019, p. 686). This post explores several cutting-edge approaches aimed at enhancing PINN generalization capabilities, directly addressing the underlying limitations that hinder their performance.</p>"},{"location":"blog/2025/08/30/pinn-burgers/#the-core-problem-gradient-pathologies-and-numerical-stiffness","title":"The Core Problem: Gradient Pathologies and Numerical Stiffness","text":"<p>A significant obstacle to PINN generalization stems from \"gradient pathologies,\" characterized by \"unbalanced back-propagated gradients during model training\" (Wang et al., 2021, p. 1). This imbalance frequently leads to \"numerical stiffness\" in the gradient flow dynamics (Wang et al., 2021, p. 1), where gradients from different components of the loss function (e.g., PDE residual versus boundary conditions) can vary by orders of magnitude (Wang et al., 2021, p. 4). This disparity can cause the network to prioritize minimizing the PDE residual within the domain while neglecting crucial boundary or initial conditions, resulting in \"erroneous predictions\" (Wang et al., 2021, p. 4). For the 2D Burgers' equation, which can involve complex flow patterns and potential shock formation, such stiffness is particularly problematic.</p> <p>Furthermore, the importance of \"sampling collocation points on the performance of PINNs has largely been overlooked\" (Daw et al., 2022, p. 1). Failures can arise when the \"correct solution must propagate from the initial and/or boundary points to the interior points\" (Daw et al., 2022, p. 3). If this propagation is hindered, PINNs can converge to \"trivial solutions\" (Daw et al., 2022, p. 1), especially in regions with \"highly imbalanced PDE residual fields\" (Daw et al., 2022, p. 1).</p>"},{"location":"blog/2025/08/30/pinn-burgers/#promising-strategies-for-enhanced-generalization","title":"Promising Strategies for Enhanced Generalization","text":"<p>Recent research has yielded several innovative techniques that directly combat these limitations, leading to substantial improvements in PINN accuracy and generalization.</p>"},{"location":"blog/2025/08/30/pinn-burgers/#adaptive-causal-sampling-and-evolutionary-sampling","title":"Adaptive Causal Sampling and Evolutionary Sampling","text":"<p>The selection and sampling of collocation points are \"quite crucial in training PINNs\" (Guo et al., 2022, p. 1). A key insight is that \"sampling should obey temporal causality\" to avoid \"sampling confusion and trivial solution of PINNs\" (Guo et al., 2022, p. 1, 5). The Adaptive Causal Sampling Method (ACSM) introduces temporal causality into adaptive sampling, significantly improving PINN performance with \"few collocation points\" and \"almost no extra computation cost,\" achieving up to \"two orders of magnitude\" improvement in prediction accuracy (Guo et al., 2022, p. 1, 5, 33).</p> <p>Building on this, the Evolutionary Sampling (Evo) method and its Causal Evo extension directly address \"propagation failures\" by incrementally accumulating collocation points in regions of high PDE residuals (Daw et al., 2022, p. 1, 4). Causal Evo, specifically designed for time-dependent PDEs, also incorporates a \"causal formulation of the PDE loss\" (Daw et al., 2022, p. 6), enabling faster convergence to accurate solutions (Daw et al., 2022, p. 8). These methods demonstrate a \"two orders of magnitude improvement in sampling efficiency\" for scenarios with very few collocation points, making them highly beneficial for high-dimensional problems like the 2D Burgers' equation where sampling efficiency is critical (Daw et al., 2022, p. 8).</p>"},{"location":"blog/2025/08/30/pinn-burgers/#adaptive-learning-rate-annealing","title":"Adaptive Learning Rate Annealing","text":"<p>To counteract the \"unbalanced gradients,\" an adaptive learning rate annealing algorithm dynamically adjusts the weights (\\(\\lambda_i\\)) of different loss terms during training (Wang et al., 2021, p. 1, 10). This algorithm \"utilizes gradient statistics\" to \"balance the interplay between the different terms\" in the composite loss function (Wang et al., 2021, p. 1, 10), ensuring that all physical constraints are adequately considered (Wang et al., 2021, p. 11). For the Helmholtz equation, this method improved prediction error by \"more than one order of magnitude\" (Wang et al., 2021, p. 11). This technique has been shown to \"consistently improve the predictive accuracy of physics-informed neural networks by a factor of 50-100x\" across various computational physics problems (Wang et al., 2021, p. 1, 13, 22).</p>"},{"location":"blog/2025/08/30/pinn-burgers/#novel-neural-network-architectures","title":"Novel Neural Network Architectures","text":"<p>Architectural innovations also play a crucial role. A novel neural network architecture has been proposed that is inherently \"more resilient to such gradient pathologies and presents less stiffness in the gradient flow dynamics\" (Wang et al., 2021, p. 2). This design incorporates \"multiplicative interactions between different input dimensions\" and \"enhances the hidden states with residual connections,\" drawing inspiration from attention mechanisms (Wang et al., 2021, p. 12). Such architectures can lead to a \"decrease in the magnitude of the leading Hessian eigenvalue\" by approximately three times, indicating reduced gradient flow stiffness (Wang et al., 2021, p. 13). This \"better capacity to represent complicated functions\" is highly advantageous for capturing the detailed dynamics of the 2D Burgers' equation (Wang et al., 2021, p. 14, 15).</p>"},{"location":"blog/2025/08/30/pinn-burgers/#first-order-physics-informed-neural-networks-fo-pinns","title":"First-Order Physics-Informed Neural Networks (FO-PINNs)","text":"<p>A significant challenge for standard PINNs, especially for parameterized systems, is the \"accuracy decreases significantly\" and the \"soft implementation of boundary conditions\" (Gladstone et al., 2023, p. 1). First-Order Physics-Informed Neural Networks (FO-PINNs) address this by reformulating higher-order PDEs into first-order systems (Gladstone et al., 2023, p. 1, 5). For a second-order PDE like:</p> \\[ a \\frac{\\partial^2 u}{\\partial x^2} + b \\frac{\\partial^2 u}{\\partial x \\partial y} + c \\frac{\\partial^2 u}{\\partial y^2} + d \\frac{\\partial u}{\\partial x} + e \\frac{\\partial u}{\\partial y} + fu = g(x, y) \\] <p>FO-PINNs define first-order derivatives \\(u_x = \\frac{\\partial u}{\\partial x}\\) and \\(u_y = \\frac{\\partial u}{\\partial y}\\) as new output variables, transforming the PDE loss function into a first-order one and introducing compatibility loss terms:</p> \\[ J_{PDE} = \\left(a \\frac{\\partial \\hat{u}_x}{\\partial x} + b \\frac{\\partial \\hat{u}_y}{\\partial y} + c \\frac{\\partial \\hat{u}_x}{\\partial y} + d\\hat{u}_x + e\\hat{u}_y + f\\hat{u} - g\\right)^2 \\] \\[ J_{COMP} = \\left(\\hat{u}_x - \\frac{\\partial \\hat{u}}{\\partial x}\\right)^2 + \\left(\\hat{u}_y - \\frac{\\partial \\hat{u}}{\\partial y}\\right)^2 \\] \\[ J = J_{PDE} + J_{COMP} \\] <p>This approach offers \"significantly higher accuracy in solving parameterized systems\" and enables the \"exact imposition of boundary conditions\" through approximate distance functions, overcoming the \"exploding Laplacian issue\" associated with higher-order derivatives (Gladstone et al., 2023, p. 1, 2, 5). For the 2D Burgers' equation, where second-order diffusion terms are often present, this reformulation could lead to improved accuracy and boundary enforcement.</p>"},{"location":"blog/2025/08/30/pinn-burgers/#residual-based-adaptive-refinement-rar","title":"Residual-Based Adaptive Refinement (RAR)","text":"<p>For PDEs with \"steep gradients,\" such as the Burgers' equation, simply using randomly distributed residual points may not be efficient (Lu et al., 2021, p. 217). The Residual-Based Adaptive Refinement (RAR) method dynamically adds more collocation points \"in the locations where the PDE residual... is large\" during training (Lu et al., 2021, p. 217). This adaptive strategy significantly improves \"training efficiency\" (Lu et al., 2021, p. 217). For the 1D Burgers' equation, PINNs with RAR \"can capture the discontinuity much better\" (Lu et al., 2021, p. 222). The effectiveness of RAR has also been \"demonstrated\" for the 2D Burgers' equation (Lu et al., 2021, p. 222, 223), highlighting its utility in accurately resolving sharp fronts or complex features.</p>"},{"location":"blog/2025/08/30/pinn-burgers/#multi-fidelity-hierarchical-training-and-data-complementarity","title":"Multi-Fidelity Hierarchical Training and Data Complementarity","text":"<p>For \"data-poor environments\" and \"parametric PINNs,\" multi-fidelity hierarchical training proves beneficial (Hassanaly et al., 2024, p. 7). This method uses solutions from simpler or lower-fidelity models to guide the training of more complex PINNs (Hassanaly et al., 2024, p. 7). This strategy can help mitigate the \"curse of dimensionality\" when PINNs are applied to parametric variations (Hassanaly et al., 2024, p. 9, 16).</p> <p>Furthermore, while PINNs are data-efficient, \"if data is available, it should be used\" (Hassanaly et al., 2024, p. 10). The \"physics loss is best used as a complement to data rather than as a complete replacement\" (Hassanaly et al., 2024, p. 10). In scenarios with \"low-data availability,\" combining physics and data losses leads to the \"highest accuracy throughout the parameter space\" (Hassanaly et al., 2024, p. 2, 10, 16). For the 2D Burgers' equation, even sparse data from traditional simulations or experimental observations could greatly assist in achieving more accurate and generalizable solutions.</p>"},{"location":"blog/2025/08/30/pinn-burgers/#conclusion","title":"Conclusion","text":"<p>The generalization of PINNs for solving challenging non-linear PDEs, such as the 2D Burgers' equation, is continuously improving through targeted methodological advancements. By systematically addressing issues like gradient pathologies, numerical stiffness, and inefficient sampling, a comprehensive framework for more robust PINN training is emerging. The combination of adaptive and causal sampling methods (ACSM, Evo, Causal Evo), adaptive learning rate annealing, novel and resilient neural network architectures, first-order reformulations (FO-PINNs) for improved accuracy and boundary condition imposition, residual-based adaptive refinement (RAR), and the strategic integration of multi-fidelity hierarchical training and observational data, offers a powerful toolkit. These approaches are crucial for unlocking the full potential of PINNs in accurately and efficiently solving complex problems in computational fluid dynamics and beyond, paving the way for reliable \"scientific machine learning\" applications.</p>"},{"location":"blog/2025/08/30/pinn-burgers/#references","title":"References","text":"<p>Daw, A., Bu, J., Wang, S., Perdikaris, P., &amp; Karpatne, A. (2022). Rethinking the importance of sampling in physics-informed neural networks. arXiv preprint arXiv:2207.02338.</p> <p>Gladstone, R. J., Nabian, M. A., Sukumar, N., Srivastava, A., &amp; Meidani, H. (2023). FO-PINN: A First-Order formulation for Physics-Informed Neural Networks. arXiv preprint arXiv:2303.15681.</p> <p>Guo, J., Wang, H., &amp; Hou, C. (2022). A Novel Adaptive Causal Sampling Method for Physics-Informed Neural Networks. Global Science Preprint.</p> <p>Hassanaly, M., Weddle, P. J., King, R. N., De, S., Doostan, A., Randall, C. R., Dufek, E. J., Colclasure, A. M., &amp; Smith, K. (2024). PINN surrogate of Li-ion battery models for parameter inference. Part II: Regularization and application of the pseudo-2D model. NREL, University of Colorado Boulder, Northern Arizona University, Idaho National Laboratory (INL).</p> <p>Lu, L., Meng, X., Mao, Z., &amp; Karniadakis, G. E. (2021). DeepXDE: A deep learning library for solving differential equations. SIAM Review, 63(1), 208\u2013228.</p> <p>Raissi, M., Perdikaris, P., &amp; Karniadakis, G. E. (2019). Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. Journal of Computational Physics, 378, 686\u2013707.</p> <p>Wang, S., Teng, Y., &amp; Perdikaris, P. (2021). Understanding and mitigating gradient pathologies in physics-informed neural networks. SIAM Journal on Scientific Computing, 43(5), A3055\u2013A3081.</p>"},{"location":"blog/2025/01/15/marimo/","title":"Marimo","text":"<p>Interesting alternative to Jupyter Notebook, but with other goals and features. The idea is to embed everything inside a single .py file, instead of an .ipynb file. The .py file is used both for the graphical interface (interactive web app) and for command line execution. It tries to eliminate some of Jupyter's reproducibility issues. It has features such as integration with package and project managers, such as uv. It's worth checking out.</p> <p>https://marimo.io/</p>"},{"location":"blog/2025/11/26/mbp-nix/","title":"The Guide to Stabilizing Linux on a MacBook Pro (Mid-2012)","text":"<p>Installing Linux (specifically Kubuntu 22.04) on a MacBook Pro 9,2 (Mid-2012 / A1278) breathes new life into this classic hardware. However, out of the box, users often face a frustrating array of issues: the system freezing upon waking from sleep, random reboots when plugging in power, and crashes after leaving the laptop closed overnight.</p> <p>After extensive debugging and testing, we have arrived at a \"Gold Standard\" configuration that solves these problems. This guide covers the installation of the proprietary Wi-Fi driver, kernel parameter tuning for the SSD and CPU, disabling problematic hardware features, and fixing USB wake-up conflicts.</p> <p>\"Hardware Context\"   This guide is optimized for the MacBook Pro 9,2 (Ivy Bridge i5) equipped with a generic SSD (e.g., XrayDisk). If you are using a standard HDD or a different SSD brand, the storage parameters are still safe to use and highly recommended for stability.</p>"},{"location":"blog/2025/11/26/mbp-nix/#step-1-wi-fi-drivers","title":"Step 1: Wi-Fi Drivers","text":"<p>The open-source <code>b43</code> driver often causes instability with the Broadcom BCM4331 chip found in this laptop, specifically regarding power states. For maximum stability and performance, we must switch to the proprietary <code>wl</code> driver.</p> <p>Open your terminal and run the following commands to ensure the open-source driver is removed and the proprietary one is installed:</p> <pre><code># 1. Remove the open-source driver and firmware installer\nsudo apt purge firmware-b43-installer b43-fwcutter\n\n# 2. Install the proprietary Broadcom driver\nsudo apt update\nsudo apt install bcmwl-kernel-source\n</code></pre> <p>Reboot your computer after this step to load the new driver.</p>"},{"location":"blog/2025/11/26/mbp-nix/#step-2-the-magic-grub-configuration","title":"Step 2: The \"Magic\" GRUB Configuration","text":"<p>This is the most critical step. We need to modify the kernel boot parameters to handle the MacBook's specific hardware quirks, particularly regarding power management, the Thunderbolt controller, and SSD behavior after long sleep.</p> <ol> <li>Edit the GRUB configuration file:</li> </ol> <pre><code>sudo nano /etc/default/grub\n</code></pre> <ol> <li>Locate the line starting with <code>GRUB_CMDLINE_LINUX_DEFAULT</code>. Replace the entire line with the following configuration:</li> </ol> <pre><code>GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash acpi_osi=Darwin acpi_backlight=video i915.enable_psr=0 i915.reset=1 init_on_alloc=0 mitigations=off module_blacklist=thunderbolt,firewire_ohci,firewire_core,firewire_sbp2 acpi_sleep=nonvs pci=noaer pcie_aspm=off intel_idle.max_cstate=1 scsi_mod.use_blk_mq=1 ahci.mobile_lpm_policy=1 libata.force=noncq\"\n</code></pre> <ol> <li> <p>Save the file (<code>Ctrl+O</code>, <code>Enter</code>) and exit (<code>Ctrl+X</code>).</p> </li> <li> <p>Crucial: Apply the changes by updating GRUB:</p> </li> </ol> <pre><code>sudo update-grub\n</code></pre>"},{"location":"blog/2025/11/26/mbp-nix/#understanding-the-parameters","title":"\ud83e\uddd0 Understanding the Parameters","text":"<p>Why so many options? Here is the breakdown of this \"Gold Standard\" config:</p> Parameter Function <code>acpi_osi=Darwin</code> Exposes macOS-compatible ACPI interfaces, improving hardware recognition. <code>acpi_backlight=video</code> Ensures screen brightness keys work natively with the Intel GPU. <code>i915.enable_psr=0</code> Disables \"Panel Self Refresh\" to prevent screen flickering and GPU hangs. <code>module_blacklist=...</code> Prevents Thunderbolt/FireWire drivers from loading. These ports cause memory allocation errors and crashes upon wake. <code>acpi_sleep=nonvs</code> Stops Linux from modifying the NVS memory area, preventing conflicts with Apple's BIOS during sleep. <code>pci=noaer</code> Disables Advanced Error Reporting to stop the kernel from panicking over harmless bus errors. <code>intel_idle.max_cstate=1</code> The anti-freeze fix. Forces the CPU to stay in a light sleep (C1) state, preventing it from desynchronizing with hardware. <code>ahci.mobile_lpm_policy=1</code> Prevents the SATA controller from cutting SSD power too aggressively during long sleeps. <code>libata.force=noncq</code> The \"Long Sleep\" fix. Disables Native Command Queuing. Essential for budget SSDs that freeze after waking from deep sleep."},{"location":"blog/2025/11/26/mbp-nix/#step-3-reinforcing-the-blacklist","title":"Step 3: Reinforcing the Blacklist","text":"<p>While we added the blacklist to GRUB, it is best practice to ensure these modules are also blocked at the system level, ensuring they never load during the initial RAM disk boot process.</p> <ol> <li>Create a blacklist configuration file:</li> </ol> <pre><code>sudo nano /etc/modprobe.d/blacklist-macbook.conf\n</code></pre> <ol> <li>Paste the following content:</li> </ol> <pre><code>blacklist thunderbolt\nblacklist firewire_ohci\nblacklist firewire_core\nblacklist firewire_sbp2\n</code></pre> <ol> <li>Save and exit. Then, update the initial RAM disk (initramfs):</li> </ol> <pre><code>sudo update-initramfs -u\n</code></pre>"},{"location":"blog/2025/11/26/mbp-nix/#step-4-disabling-hibernation","title":"Step 4: Disabling Hibernation","text":"<p>Linux hibernation (suspend-to-disk) is notoriously unstable on Macs. Furthermore, Ubuntu attempts a \"Hybrid Sleep\" after a few hours, which crashes this machine because the SSD fails to wake up from the hibernation attempt. We will force the system to use only RAM for sleeping (Suspend-to-RAM).</p> <ol> <li>Create a configuration directory and file:</li> </ol> <pre><code>sudo mkdir -p /etc/systemd/sleep.conf.d\nsudo nano /etc/systemd/sleep.conf.d/no-hibernate.conf\n</code></pre> <ol> <li>Paste the following content:</li> </ol> <pre><code>[Sleep]\nAllowHibernation=no\nAllowHybridSleep=no\nAllowSuspendThenHibernate=no\nSuspendState=mem\n</code></pre> <ol> <li>Save and exit. Reload systemd configuration:</li> </ol> <pre><code>sudo systemctl daemon-reload\n</code></pre>"},{"location":"blog/2025/11/26/mbp-nix/#step-5-fixing-wi-fi-password-loops","title":"Step 5: Fixing Wi-Fi Password Loops","text":"<p>Even with the correct driver, the BCM4331 chip often fails the WPA2 security handshake when Power Saving is enabled, causing the system to repeatedly ask for the Wi-Fi password.</p> <ol> <li>Create a NetworkManager configuration file:</li> </ol> <pre><code>sudo nano /etc/NetworkManager/conf.d/99-wifi-powersave-off.conf\n</code></pre> <ol> <li>Paste the following content to permanently disable power saving:</li> </ol> <pre><code>[connection]\nwifi.powersave = 2\n</code></pre> <ol> <li>Save and exit. (This takes effect on reboot).</li> </ol>"},{"location":"blog/2025/11/26/mbp-nix/#step-6-preventing-usb-sleep-crashes","title":"Step 6: Preventing USB Sleep Crashes","text":"<p>The 2012 MacBook has a hardware bug where USB devices (like ethernet adapters or mice) connected during sleep can confuse the power controller (SMC), causing the system to hang with a pulsing light and unresponsive power button.</p> <p>We must tell the system not to wake up via USB to avoid this conflict.</p> <ol> <li>Create a systemd service to disable USB wakeup:</li> </ol> <pre><code>sudo nano /etc/systemd/system/disable-usb-wakeup.service\n</code></pre> <ol> <li>Paste the following content:</li> </ol> <pre><code>[Unit]\nDescription=Disable USB Wakeup to prevent sleep crashes\n\n[Service]\nType=oneshot\nExecStart=/bin/sh -c \"echo EHC1 &gt; /proc/acpi/wakeup; echo EHC2 &gt; /proc/acpi/wakeup; echo XHC1 &gt; /proc/acpi/wakeup\"\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <ol> <li>Save, exit, and enable the service:</li> </ol> <pre><code>sudo systemctl enable --now disable-usb-wakeup.service\n</code></pre>"},{"location":"blog/2025/11/26/mbp-nix/#step-7-ssd-maintenance-and-sensors","title":"Step 7: SSD Maintenance and Sensors","text":"<p>To keep your SSD fast and monitor temperatures safely without crashing the Apple SMC controller.</p>"},{"location":"blog/2025/11/26/mbp-nix/#enable-trim","title":"Enable TRIM","text":"<p>TRIM helps the SSD manage deleted data blocks.</p> <pre><code>sudo systemctl enable --now fstrim.timer\n</code></pre>"},{"location":"blog/2025/11/26/mbp-nix/#safe-sensor-monitoring","title":"Safe Sensor Monitoring","text":"<p>Do not run <code>sensors-detect</code> on a MacBook. Probing the proprietary Apple SMC bus can freeze the hardware.</p> <p>Instead, simply install the sensor package and use it directly, as the kernel already includes the correct driver (<code>applesmc</code>):</p> <pre><code>sudo apt install lm-sensors\n</code></pre> <p>You can now check temperatures safely by running the command <code>sensors</code> in the terminal.</p>"},{"location":"blog/2025/11/26/mbp-nix/#conclusion","title":"Conclusion","text":"<p>After applying these settings and rebooting, the MacBook Pro 2012 is transformed. You can close the lid with confidence, leave it overnight, and open it the next day to a responsive system with stable Wi-Fi and no crashes.</p> <p>Summary of Fixes:</p> <ol> <li>Wi-Fi: Proprietary <code>wl</code> driver + Power Save disabled.</li> <li>Boot/PCI: GRUB parameters to ignore Thunderbolt and fix memory maps.</li> <li>Sleep: C-States limited to C1 + SATA NCQ disabled for SSD stability.</li> <li>Hardware: USB wakeup disabled to prevent SMC lockups.</li> </ol> <p>Enjoy your rock-solid Linux MacBook!</p>"},{"location":"blog/2025/01/18/jupy-repr/","title":"Notebooks","text":"<p>Post talking about some problems with Jupyter Notebook, especially the reproducibility problem:</p> <p>https://docs.marimo.io/faq/#faq-problems</p> <p>Post discussing consistency issues encountered when analyzing 10 million Jupyter notebooks from GitHub. Key issues include lack of reproducibility, difficulties in code organization, and effective collaboration between developers:</p> <p>https://blog.jetbrains.com/datalore/2020/12/17/we-downloaded-10-000-000-jupyter-notebooks-from-github-this-is-what-we-learned/#consistency-of-notebooks</p> <p>Article that explores the challenges software developers face when using electronic notebooks like Jupyter. Common pain points include code organization, debugging and collaboration issues, and difficulty maintaining clear and repeatable workflows:</p> <p>Chattopadhyay, S., Henley, A., Mahato, M., Smith, M. A., &amp; Myers, B. A. (2020). What\u2019s Wrong with Computational Notebooks? Pain Points, Needs, and Design Opportunities. Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, 1-12. https://doi.org/10.1145/3313831.3376729</p>"},{"location":"blog/2025/08/30/pinn-chal/","title":"Overcoming Challenges in Physics-Informed Neural Networks (PINNs): Gradient Optimization for Inverse Problems","text":"<p>Physics-Informed Neural Networks (PINNs) represent a promising approach for solving complex Partial Differential Equations (PDEs) and inverse problems, such as determining hidden parameters of a physical system \u2013 for instance, viscosity (<code>nu</code>) in a 2D Burgers equation. However, the application of PINNs presents inherent challenges. A recent study by Wang et al. (2020) delves into these limitations and proposes innovative solutions that can significantly enhance PINN performance.</p>"},{"location":"blog/2025/08/30/pinn-chal/#the-fundamental-problem-unbalanced-gradients-and-stiff-dynamics","title":"The Fundamental Problem: Unbalanced Gradients and Stiff Dynamics","text":"<p>PINNs operate by embedding PDE constraints directly into the neural network's loss function. This composite loss function typically includes terms that penalize the PDE residual (<code>Lr</code>), ensuring that physical laws are satisfied, and terms that fit observed data, initial, or boundary conditions (<code>Li</code>) (Wang et al., 2020, p. 3, Equation 4). During training, the neural network adjusts its parameters to minimize this combined loss (Wang et al., 2020, p. 3).</p> <p>Wang et al. (2020) identified a fundamental mode of failure in PINNs: stiffness in the gradient flow dynamics, which leads to unbalanced back-propagated gradients during model training (Wang et al., 2020, p. 2, 4-5). This means that the gradients from different parts of the loss function can have vastly different magnitudes. For example, the gradients from the PDE residual term (<code>Lr</code>) can be significantly larger than those from the data-fit terms (<code>Li</code>) (Wang et al., 2020, p. 4).</p> <p>How does this affect <code>nu</code> estimation in the 2D Burgers equation? When attempting to find the viscosity parameter <code>nu</code> (an inverse problem), your PINN's loss function will include a term for the 2D Burgers equation residual (which depends on <code>nu</code>) and terms for fitting any available observational data. If the residual term's gradients dominate, the neural network may become very efficient at satisfying the PDE but neglect the constraints from observational data. This would result in an unsatisfactory fit to real-world measurements and, consequently, an inaccurate estimation of <code>nu</code>. The authors demonstrate that this stiffness is exacerbated when the target solution is more complex or oscillatory (Wang et al., 2020, p. 7). They illustrate this with the Helmholtz equation, where the standard PINN model fails to fit boundary conditions because gradients of the boundary loss (<code>\u2207\u03b8Lub(\u03b8)</code>) are \"sharply concentrated around zero and overall attain significantly smaller values\" than the gradients of the PDE residual loss (<code>Lr(\u03b8)</code>) (Wang et al., 2020, p. 4, Figure 2). If <code>\u2207\u03b8Lub(\u03b8)</code> gradients are very small, the PINN will experience difficulties in fitting the boundary conditions (Wang et al., 2020, p. 4).</p>"},{"location":"blog/2025/08/30/pinn-chal/#solution-1-learning-rate-annealing-algorithm-for-balanced-learning","title":"Solution 1: Learning Rate Annealing Algorithm for Balanced Learning","text":"<p>To counteract this gradient imbalance, the work proposes an adaptive learning rate annealing algorithm (Wang et al., 2020, p. 8). This adaptive algorithm dynamically adjusts the weights (\u03bbi) of the different terms within the composite loss function during training. It uses gradient statistics to compute instantaneous values for these weights, essentially re-scaling the learning rate for each loss term (Wang et al., 2020, p. 9-10, Algorithm 1).</p> <p>How this helps in <code>nu</code> inference for the 2D Burgers equation: This is a crucial insight for inverse problems. By dynamically adjusting the weights, the algorithm ensures that neither the PDE residual term (highly sensitive to <code>nu</code>) nor the data-fit terms are neglected (Wang et al., 2020, p. 9). This adaptive balancing allows the network to simultaneously learn to satisfy the underlying physics and accurately fit observed data, leading to more robust and precise inference of the viscosity parameter <code>nu</code>. The authors demonstrated that this method, by itself, can improve predictive accuracy by more than an order of magnitude for the Helmholtz problem (Wang et al., 2020, p. 11, Figure 6). The algorithm calculates \u03bb\u0302i as the ratio between the maximum gradient magnitude of <code>\u2207\u03b8Lr(\u03b8n)</code> and the mean of the gradient magnitudes of <code>\u2207\u03b8Li(\u03b8n)</code>, and then updates \u03bbi using a moving average (Wang et al., 2020, p. 10, Equations 40-41).</p>"},{"location":"blog/2025/08/30/pinn-chal/#solution-2-a-more-resilient-neural-network-architecture","title":"Solution 2: A More Resilient Neural Network Architecture","text":"<p>Beyond the training algorithm, the architecture of the neural network itself plays a vital role (Wang et al., 2020, p. 12). The authors introduce a novel neural network architecture designed to be more resilient to gradient pathologies and exhibit less stiffness in the gradient flow dynamics compared to conventional fully-connected networks (Wang et al., 2020, p. 12, 22). This architecture incorporates:</p> <ol> <li>Explicit multiplicative interactions between different input dimensions (Wang et al., 2020, p. 12, Equation 43).</li> <li>Enhanced hidden states with residual connections (Wang et al., 2020, p. 12, Equations 44-46).</li> </ol> <p>This design leads to a decrease in the largest eigenvalue of the Hessian matrix (\u03c3max(\u22072\u03b8L(\u03b8))), an indicator of gradient flow stiffness, suggesting more stable training (Wang et al., 2020, p. 13). The proposed architecture, termed Model M3, demonstrated an approximate 3x reduction in the magnitude of the leading Hessian eigenvalue compared to the conventional dense architecture (Model M1) (Wang et al., 2020, p. 13, Figure 11).</p> <p>How this helps in <code>nu</code> inference for the 2D Burgers equation: Using this enhanced architecture can make your PINN for the Burgers 2D equation more stable and efficient to train, even when dealing with complex flow patterns or parameter regimes that might otherwise cause training instability. A more stable network is better equipped to explore the parameter space effectively, leading to a more reliable and accurate estimation of <code>nu</code>.</p>"},{"location":"blog/2025/08/30/pinn-chal/#the-combined-power-orders-of-magnitude-improvements","title":"The Combined Power: Orders of Magnitude Improvements","text":"<p>The most compelling finding is that the combination of the learning rate annealing algorithm and the improved neural network architecture (Model M4) consistently delivers the most accurate results (Wang et al., 2020, p. 14, 16). This combined approach improved the predictive accuracy of PINNs by a remarkable factor of 50 to 100 times across a range of problems in computational physics (Wang et al., 2020, p. 2, 22).</p> <p>For your inverse problem of estimating <code>nu</code> in the 2D Burgers equation, this means that by adopting these proposed methodologies (Model M4), you can expect significantly more precise and robust inferences of the viscosity parameter compared to standard PINN formulations (Wang et al., 2020, p. 16, Table 3). For example, in the Klein-Gordon problem, Model M4 achieved a relative L2 error of 2.81e-03, while Model M1 had 1.79e-01, representing nearly two orders of magnitude improvement (Wang et al., 2020, p. 16, Table 3).</p>"},{"location":"blog/2025/08/30/pinn-chal/#conclusion","title":"Conclusion","text":"<p>The work of Wang et al. (2020) offers crucial insights into the difficulties of PINNs and presents practical and effective solutions. When addressing the inverse problem of identifying the viscosity <code>nu</code> for the 2D Burgers equation using PINNs, it is fundamental to consider:</p> <ul> <li>Gradient pathologies: Unbalanced gradients and stiff dynamics are common challenges (Wang et al., 2020, p. 2, 4-5).</li> <li>Adaptive loss weighting: Utilize a learning rate annealing algorithm (such as Algorithm 1) to dynamically balance the contributions of the PDE residual and data-fit terms (Wang et al., 2020, p. 9-10).</li> <li>Improved neural architecture: Employ architectures designed to reduce gradient flow stiffness for more stable training (Wang et al., 2020, p. 13).</li> </ul> <p>By incorporating these advancements, it is possible to unlock the full potential of PINNs, transforming a challenging inverse problem into a more manageable and precise endeavor.</p>"},{"location":"blog/2025/08/30/pinn-chal/#references","title":"References","text":"<p>Wang, S., Teng, Y., &amp; Perdikaris, P. (2020, January 15). Understanding and mitigating gradient pathologies in physics-informed neural networks. arXiv. Retrieved from https://github.com/PredictiveIntelligenceLab/GradientPathologiesPINNs</p>"},{"location":"blog/2025/09/01/pinn-acce/","title":"Bridging the Software Gap: Accelerating Physics-Informed Neural Networks","text":"<p>In the realm where artificial intelligence meets scientific discovery, Physics-Informed Neural Networks (PINNs) stand out as a revolutionary approach. These networks don't just learn from data; they are inherently guided by the fundamental laws of physics, allowing them to solve complex equations and uncover hidden parameters in physical systems (Raissi et al., 2019). Imagine a digital brain that understands both observations and the underlying rules of nature. This capability is particularly valuable when experimental data is scarce or noisy, as the physics acts as a powerful constraint on the learning process.</p> <p>Our recent investigation focused on a PINN designed to determine a critical physical property: the kinematic viscosity (\\(\\nu\\)) within a 2D Burgers' equation. This equation is a cornerstone in fluid dynamics, describing the intricate flow of fluids and holding relevance across various fields of science and engineering.</p> <p>The 2D Burgers' equation is represented by a system of two coupled partial differential equations:</p> \\[ \\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x} + v \\frac{\\partial u}{\\partial y} - \\nu \\left( \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} \\right) = 0 \\] \\[ \\frac{\\partial v}{\\partial t} + u \\frac{\\partial v}{\\partial x} + v \\frac{\\partial v}{\\partial y} - \\nu \\left( \\frac{\\partial^2 v}{\\partial x^2} + \\frac{\\partial^2 v}{\\partial y^2} \\right) = 0 \\] <p>Here, \\(u\\) and \\(v\\) denote the fluid's velocity components along the x and y axes, respectively, while \\(\\nu\\) is the kinematic viscosity, the parameter our network aims to discover.</p>"},{"location":"blog/2025/09/01/pinn-acce/#the-evolving-landscape-of-scientific-software","title":"The Evolving Landscape of Scientific Software","text":"<p>The world of scientific computing is constantly advancing, with software libraries undergoing frequent updates. This evolution often presents a challenge: ensuring that established scientific models continue to perform consistently when migrated to newer software versions. We undertook a detailed comparison between an older implementation of our PINN and a more contemporary one, built using a newer version of its foundational deep learning framework. Our primary goal was to confirm that the scientific insights derived from our models remain robust across these different software environments.</p> <p>Transitioning a sophisticated scientific model between major software versions is rarely straightforward. Even if the core mathematical logic remains unchanged, subtle differences in how the software handles numerical computations, optimizes algorithms, or manages internal processes can lead to variations in both the results obtained and the computational time required. This necessitates rigorous verification to maintain the integrity of scientific findings.</p>"},{"location":"blog/2025/09/01/pinn-acce/#the-technical-environment","title":"The Technical Environment","text":"<p>For those interested in the specifics of our setup, all experiments were conducted within a Python programming environment, meticulously managed using Conda. The essential software libraries employed included:</p> <ul> <li>TensorFlow: The deep learning framework, with one implementation utilizing version 1.x (specifically <code>tensorflow.compat.v1</code>) and the other leveraging the more recent version 2.x (integrated with Keras).</li> <li>NumPy: An indispensable library for high-performance numerical operations and efficient data manipulation.</li> <li>SciPy: Employed for advanced scientific computing routines, particularly for its robust L-BFGS-B optimization algorithm.</li> </ul> <p>The computations were performed on a powerful workstation. The central processing unit (CPU) was an Intel Xeon E5-2680 v4. Although the system was equipped with a dedicated graphics processing unit (GPU), an NVIDIA GeForce RTX 3050 with 6 GB of VRAM, all calculations for these experiments were exclusively processed by the CPU in the initial phase. Subsequently, experiments were re-run to explicitly utilize the GPU. The system was provisioned with a substantial 128 GB of system memory (RAM), ensuring ample capacity for handling large datasets and complex model operations.</p>"},{"location":"blog/2025/09/01/pinn-acce/#neural-network-architecture","title":"Neural Network Architecture","text":"<p>The neural network, the \"brain\" of our PINN, is structured to learn the intricate dynamics of the fluid flow. It accepts three input parameters: the spatial coordinates (\\(x, y\\)) and time (\\(t\\)). Its output consists of two crucial values: the predicted velocity component in the x-direction (\\(u\\)) and the velocity component in the y-direction (\\(v\\)).</p> <p>The architecture of this network is defined as follows:</p> <ul> <li>An input layer with 3 neurons, corresponding directly to the \\(x, y, t\\) inputs.</li> <li>Four hidden layers, each densely connected and containing 60 neurons. These layers are responsible for extracting and transforming the complex features from the input data.</li> <li>An output layer with 2 neurons, providing the final predicted \\(u\\) and \\(v\\) velocities.</li> </ul> <p>The hyperbolic tangent (Tanh) activation function was applied to the neurons in all hidden layers. This non-linear function is crucial for enabling the network to model the complex, non-linear relationships inherent in fluid dynamics. To ensure stable and efficient learning, the initial values for the network's weights were set using the Glorot normal (Xavier) initializer, a widely adopted technique that helps prevent issues like vanishing or exploding gradients during training.</p>"},{"location":"blog/2025/09/01/pinn-acce/#our-comparison-approach","title":"Our Comparison Approach","text":"<p>To establish a fair and meaningful comparison between the two implementations, we meticulously standardized their experimental setups. This involved ensuring:</p> <ul> <li>Identical Starting Conditions: Both models began their training with the exact same initial guess for the kinematic viscosity (\\(\\nu\\)).</li> <li>Consistent Training Data: The same set of data points, representing the observed fluid behavior, was fed into both models.</li> <li>Balanced Physics Integration: The relative importance given to the \"physics\" component of the learning process (quantified by the PDE loss) versus the \"data\" component (quantified by the data loss) was precisely matched across both implementations.</li> <li>Uniform Training Strategy: Both models followed an identical two-stage optimization process. They began with the Adam optimizer for robust initial learning, followed by a switch to the more specialized L-BFGS-B optimizer for fine-tuning the model parameters.</li> </ul> <p>Following these rigorous alignments, we executed both implementations and thoroughly analyzed their outputs. Our focus was on key metrics such as the discovered \\(\\nu\\) value, the accuracy of their predictions (assessed through various \"loss\" metrics), and the computational time expended during different phases of training.</p>"},{"location":"blog/2025/09/01/pinn-acce/#what-we-found-performance-and-precision-across-implementations","title":"What We Found: Performance and Precision Across Implementations","text":"<p>Our comprehensive comparison yielded several significant insights into both the numerical behavior and the computational efficiency of the two PINN implementations.</p>"},{"location":"blog/2025/09/01/pinn-acce/#numerical-consistency-and-discovered-kinematic-viscosity-nu","title":"Numerical Consistency and Discovered Kinematic Viscosity (\\(\\nu\\))","text":"<p>Both implementations successfully converged to a value for the kinematic viscosity. While these discovered values were remarkably close (e.g., 0.020000 for the newer implementation versus 0.023290 for the older one), they were not numerically identical. This slight divergence is a well-known characteristic when migrating complex scientific models between major software versions, even when all high-level parameters are precisely aligned. Such differences often arise from subtle variations in floating-point arithmetic, the internal workings of optimization algorithms, or how random numbers are generated and utilized within the different framework versions.</p>"},{"location":"blog/2025/09/01/pinn-acce/#prediction-accuracy","title":"Prediction Accuracy","text":"<p>The overall accuracy of the predictions, as reflected by the final \"total loss\" values, remained comparable between the two implementations. Both models consistently demonstrated a strong ability to learn from the provided data and adhere to the governing physical laws. Furthermore, the individual components of the loss function\u2014the data loss and the physics loss\u2014exhibited similar trends and magnitudes, confirming that both implementations were effectively minimizing errors in their predictions and their fidelity to the Burgers' equation.</p>"},{"location":"blog/2025/09/01/pinn-acce/#the-power-of-acceleration-computational-time","title":"The Power of Acceleration: Computational Time","text":"<p>Perhaps the most compelling finding emerged from the analysis of computational time. When the experiments were shifted from the CPU to the GPU, both PINN implementations experienced a dramatic reduction in training durations.</p> <ul> <li> <p>For the newer implementation, the initial \"data-only\" training phase, which took approximately 642 seconds on the CPU, was completed in just about 7 seconds on the GPU\u2014a speedup factor of over 90 times. The subsequent \"full Adam\" training also saw a significant acceleration, from around 103 seconds on the CPU to roughly 6 seconds on the GPU. The final \"L-BFGS-B\" optimization, while less dramatically accelerated, still showed an improvement, completing in about 60 seconds on the GPU compared to 65 seconds on the CPU.</p> </li> <li> <p>The older implementation also benefited immensely from GPU acceleration. Its \"data-only\" training time plummeted from approximately 21 seconds on the CPU to just over 1 second on the GPU. Similarly, the \"full Adam\" training was reduced from about 53 seconds to less than 3 seconds. Most notably, the \"L-BFGS-B\" phase, which took around 23 seconds on the CPU, finished in less than 1 second on the GPU\u2014a remarkable speedup of over 25 times.</p> </li> </ul> <p>These substantial reductions in computational time underscore the immense value of leveraging specialized hardware like GPUs for deep learning tasks. The parallel processing capabilities of the GPU significantly enhance the efficiency of the optimization algorithms, allowing for much faster model training and iteration.</p>"},{"location":"blog/2025/09/01/pinn-acce/#conclusion-functional-success-with-enhanced-efficiency","title":"Conclusion: Functional Success with Enhanced Efficiency","text":"<p>In conclusion, our comparative study unequivocally demonstrates that the migration of the Physics-Informed Neural Network to the newer software environment was functionally successful. The model consistently operates as intended, effectively learns from data, and accurately discovers the physical parameter. While achieving exact numerical identity between the two TensorFlow versions proved challenging\u2014a common observation in such transitions\u2014the results remained consistently close and scientifically sound. Crucially, the integration of GPU acceleration dramatically improved the computational efficiency of both implementations, transforming training times from minutes or hours to mere seconds. This dual success highlights the importance of thorough software verification and the transformative impact of hardware acceleration in advancing scientific discovery through machine learning.</p>"},{"location":"blog/2025/09/01/pinn-acce/#references","title":"References","text":"<p>Raissi, M., Perdikaris, P., &amp; Karniadakis, G. E. (2019). Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. Journal of Computational Physics, 378, 686-707.</p>"},{"location":"blog/2025/08/31/pinn-para/","title":"Enhancing Parametric PINN Training: A Synergistic Approach with Weighted Curricula and Learning Rate Scheduling","text":"<p>Physics-Informed Neural Networks (PINNs) have emerged as a powerful paradigm for solving differential equations by embedding physical laws directly into the loss function of a neural network. A particularly compelling application is in solving parametric inverse problems, where the goal is to infer physical parameters (e.g., viscosity, conductivity) from observational data. A common and effective methodology involves a two-stage process: first, training a general parametric model over a range of the parameter, and second, using this pre-trained model as a prior to rapidly identify the specific parameter value that best explains a new set of observations.</p> <p>The success of this second stage is critically dependent on the robustness and accuracy of the initial, general-purpose model. However, training a single PINN to generalize across a wide parameter range is a significant challenge. Different parameter values can drastically alter the complexity and stability of the solution, leading to training instabilities and gradient imbalances. This post explores a sophisticated, two-pronged strategy to fortify this crucial first stage of training: the Weighted Curriculum and the ReduceLROnPlateau learning rate scheduler.</p>"},{"location":"blog/2025/08/31/pinn-para/#the-challenge-of-parametric-complexity-in-pinns","title":"The Challenge of Parametric Complexity in PINNs","text":"<p>Training a PINN on a parametric partial differential equation (PDE) requires the network to learn a family of solutions. The difficulty of this task is often not uniform across the parameter space. For instance, in fluid dynamics simulations governed by the Burgers' or Navier-Stokes equations, the viscosity parameter \\(\\nu\\) is a key determinant of solution complexity. High-viscosity scenarios are diffusion-dominated, resulting in smooth solutions that are relatively easy for a network to approximate. Conversely, low-viscosity scenarios are convection-dominated, leading to sharp gradients and turbulent features that are notoriously difficult to learn.</p> <p>This heterogeneity in problem difficulty gives rise to a critical issue during training: gradient pathology. As highlighted by Wang, Teng, &amp; Perdikaris (2021), the different components of the PINN loss function (e.g., data fidelity, boundary conditions, and PDE residuals) can have gradients of vastly different magnitudes. This imbalance can cause the optimization process to be dominated by \"easy\" regions of the problem space, failing to adequately learn the more complex and challenging regimes, thereby producing a poorly generalized model.</p>"},{"location":"blog/2025/08/31/pinn-para/#the-weighted-curriculum-strategy","title":"The Weighted Curriculum Strategy","text":"<p>To address these challenges, a \"Weighted Curriculum\" approach can be implemented. This strategy is not a single technique but a combination of two established machine learning principles\u2014Curriculum Learning and Adaptive Loss Weighting\u2014applied to the specific context of parametric PINNs.</p>"},{"location":"blog/2025/08/31/pinn-para/#curriculum-learning-for-parameter-space-exploration","title":"Curriculum Learning for Parameter Space Exploration","text":"<p>The concept of Curriculum Learning, formally introduced by Bengio et al. (2009), posits that a model learns more effectively if it is first trained on easier examples before being gradually exposed to more complex ones. In the context of parametric PINNs, this translates to structuring the training process around the difficulty induced by the physical parameter. Instead of sampling the parameter \\(\\nu\\) uniformly from its entire range \\([\\nu_{min}, \\nu_{max}]\\) from the outset, the training begins on an easier subset (e.g., \\([\\nu_{mid}, \\nu_{max}]\\)). As training progresses, the sampling range is gradually expanded to include more challenging, lower values of \\(\\nu\\).</p> <p>This approach helps to stabilize the initial phases of training, allowing the network to learn a coarse approximation of the solution manifold before confronting the more complex dynamics. This sequential introduction of difficulty helps the optimizer avoid poor local minima, a motivation supported by findings on failure modes in PINNs (Krishnapriyan et al., 2021). Recent research has further validated this by applying curriculum strategies not only to PDE parameters but also to progressively increase the complexity of geometric domains or the duration of time-dependent simulations (Mao et al., 2023).</p>"},{"location":"blog/2025/08/31/pinn-para/#adaptive-loss-weighting-for-gradient-balancing","title":"Adaptive Loss Weighting for Gradient Balancing","text":"<p>To directly combat the problem of gradient imbalance, the second component of the strategy is to apply adaptive weights to the loss function. The core idea is to assign greater importance to the collocation points corresponding to parameter values that are known to be more difficult. By weighting the PDE loss, we can force the optimizer to pay more attention to these challenging regions.</p> <p>A practical implementation is to define a weight, \\(w\\), for each point in the PDE residual loss calculation as a function of its associated parameter value, \\(\\nu\\). For problems where difficulty increases as \\(\\nu\\) decreases, an inverted exponential function serves as an effective weighting scheme:</p> \\[w(\\nu) = \\exp\\left(-\\gamma \\frac{\\nu - \\nu_{min}}{\\nu_{max} - \\nu_{min}}\\right)\\] <p>Here, \\(\\gamma\\) is a \"sharpness factor\" that controls how rapidly the weight increases for low \\(\\nu\\) values. This explicit weighting scheme is a form of adaptive loss balancing, a highly active area of PINN research aimed at creating more robust optimization landscapes (McClenny &amp; Braga-Neto, 2020).</p>"},{"location":"blog/2025/08/31/pinn-para/#dynamic-learning-rate-adjustment-with-reducelronplateau","title":"Dynamic Learning Rate Adjustment with ReduceLROnPlateau","text":"<p>Complementary to the Weighted Curriculum, which controls what the model learns, is the use of a learning rate scheduler to control how the model learns. ReduceLROnPlateau is a heuristic-based scheduler that dynamically adjusts the optimizer's learning rate. It operates by monitoring a specific metric, typically the validation loss, and reducing the learning rate by a predefined factor if the metric fails to improve for a set number of epochs (referred to as \"patience\").</p> <p>This technique is rooted in the long-standing practice of learning rate annealing, which recognizes that optimizers benefit from larger steps early in training and require smaller, more precise steps to fine-tune as they approach a minimum (LeCun et al., 1998). By reducing the learning rate when training stagnates, ReduceLROnPlateau helps the optimizer to descend into narrower minima and avoid oscillating around a solution.</p>"},{"location":"blog/2025/08/31/pinn-para/#synergy-and-promising-outlook","title":"Synergy and Promising Outlook","text":"<p>The true power of these techniques is realized when they are used in concert. The Weighted Curriculum provides a structured and stable pathway for the model to learn a complex, multi-regime problem. Meanwhile, ReduceLROnPlateau acts as an intelligent control system for the optimizer, ensuring that the learning pace is appropriate for the current stage of the curriculum. For instance, when the curriculum introduces a new, more challenging set of parameter values, the loss may plateau; ReduceLROnPlateau can then decrease the learning rate to allow for more careful exploration of this new, more complex solution space.</p> <p>This combination represents a robust and principled approach to training parametric PINNs. The field continues to evolve, with promising research focused on developing fully automated loss-balancing schemes that require no manual tuning, such as those based on gradient normalization or the neural tangent kernel, which have demonstrated significant improvements in model accuracy and stability (Wang et al., 2021). The structured approach of a Weighted Curriculum, enhanced by adaptive learning rates, provides a strong foundation upon which these future advancements can be built.</p>"},{"location":"blog/2025/08/31/pinn-para/#conclusion","title":"Conclusion","text":"<p>For parametric PINNs to be effective tools in solving inverse problems, the initial training of a generalized model must be both stable and accurate. The combined strategy of a Weighted Curriculum\u2014which organizes the learning process from easy to hard and focuses the loss function on challenging regions\u2014and an adaptive learning rate scheduler like ReduceLROnPlateau provides a powerful framework for achieving this. By carefully managing both the data and the optimization dynamics, researchers can develop more reliable and highly generalized PINN solvers, unlocking their full potential for scientific discovery and engineering applications.</p>"},{"location":"blog/2025/08/31/pinn-para/#bibliography","title":"Bibliography","text":"<p>Bengio, Y., Louradour, J., Collobert, R., &amp; Weston, J. (2009). Curriculum learning. In Proceedings of the 26th annual international conference on machine learning (ICML) (pp. 41-48).</p> <p>Krishnapriyan, A. S., Gholami, A., Zhe, S., Kirby, R. M., &amp; Mahoney, M. W. (2021). Characterizing possible failure modes in physics-informed neural networks. In Advances in Neural Information Processing Systems (NeurIPS), 34, 26548-26560.</p> <p>LeCun, Y., Bottou, L., Orr, G. B., &amp; M\u00fcller, K. R. (1998). Efficient BackProp. In Neural Networks: Tricks of the Trade (pp. 9-50). Springer.</p> <p>Mao, Z., Jagtap, A. D., &amp; Karniadakis, G. E. (2023). Physics-informed curriculum learning for data-efficient discovery of nonlinear PDEs. arXiv preprint arXiv:2303.12489.</p> <p>McClenny, L., &amp; Braga-Neto, U. (2020). Self-adaptive loss balanced PINNs: A user-friendly approach for solving complex PDEs. arXiv preprint arXiv:2007.04542.</p> <p>Wang, S., Teng, Y., &amp; Perdikaris, P. (2021). Understanding and mitigating gradient flow pathologies in physics-informed neural networks. SIAM Journal on Scientific Computing, 43(5), A3055-A3081.</p>"},{"location":"blog/2026/01/26/mkdocs-workflow/","title":"Tutorial: A Reproducible MkDocs Workflow with Centralized Templates","text":"<p>Creating documentation or course notes shouldn't involve copy-pasting configuration files and CSS assets for every new project.</p> <p>In this post, I will share my complete workflow. It uses MkDocs, a custom Bash script (<code>zk</code>), and a centralized template directory. This allows me to write in Zettlr or Kate (pure text mode) and instantly preview the result without cluttering my project folders.</p>"},{"location":"blog/2026/01/26/mkdocs-workflow/#prerequisites","title":"Prerequisites","text":"<p>To reproduce this setup, you will need:</p> <ul> <li>MkDocs installed (preferably in a Conda environment or venv).</li> <li>MkDocs Material theme.</li> <li>A Linux environment (Bash).</li> </ul>"},{"location":"blog/2026/01/26/mkdocs-workflow/#step-1-directory-structure","title":"Step 1: Directory Structure","text":"<p>First, organize your file system to separate the Template (global assets) from your Projects (content).</p> <p>Create a base directory (e.g., <code>template</code>).</p>"},{"location":"blog/2026/01/26/mkdocs-workflow/#the-template-directory","title":"The Template Directory","text":"<p>This folder holds the files that are common to all projects: CSS, JavaScript (like KaTeX for math), and fonts .</p> <pre><code>/path/to/your/template\n\u251c\u2500\u2500 assets\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 extra.css\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 katex/        # Offline math rendering \n\u2502\u00a0\u00a0 \u2514\u2500\u2500 katex.js\n\u251c\u2500\u2500 index.md          # Default homepage if none exists \n\u2514\u2500\u2500 mkdocs.yml        # Base configuration \n</code></pre>"},{"location":"blog/2026/01/26/mkdocs-workflow/#the-base-configuration-mkdocsyml","title":"The Base Configuration (<code>mkdocs.yml</code>)","text":"<p>Save this as <code>/path/to/your/template/mkdocs.yml</code>. It defines the theme, offline settings, and plugins .</p> <pre><code>site_name: Notes\nuse_directory_urls: false\ntheme:\n  name: material\n\nplugins:\n  search: {}\n  offline: {}\n  autorefs: {}\n\nextra_css:\n  - assets/extra.css\n  - assets/katex/katex.min.css\n\nextra_javascript:\n  - assets/katex.js\n  - assets/katex/katex.min.js\n  - assets/katex/contrib/auto-render.min.js\n\nmarkdown_extensions:\n  admonition: {}\n  pymdownx.details: {}\n  pymdownx.arithmatex:\n    generic: true\n  pymdownx.superfences:\n    custom_fences:\n      - name: mermaid\n        class: mermaid\n        format: !!python/name:pymdownx.superfences.fence_code_format\n</code></pre>"},{"location":"blog/2026/01/26/mkdocs-workflow/#step-2-the-project-directory","title":"Step 2: The Project Directory","text":"<p>Now, create a project folder (e.g., <code>event</code>). Notice how clean it is\u2014it only contains content and a small config file .</p> <pre><code>/path/to/your/event/\n\u251c\u2500\u2500 index.md\n\u251c\u2500\u2500 my-article.md\n\u2514\u2500\u2500 mkdocs-inherit.yml  # The \"Delta\" config\n</code></pre>"},{"location":"blog/2026/01/26/mkdocs-workflow/#the-inheritance-config-mkdocs-inherityml","title":"The Inheritance Config (<code>mkdocs-inherit.yml</code>)","text":"<p>Instead of a full config, this file simply inherits from the base and overrides specific fields (like the site name or color) .</p> <pre><code>INHERIT: mkdocs.yml\nsite_name: Tech Week 2026.1\ntheme:\n    palette:\n        primary: teal\n        accent:  teal\nnav:\n  - Home: index.md\n  - About: my-article.md\n</code></pre>"},{"location":"blog/2026/01/26/mkdocs-workflow/#step-3-the-zk-script-the-engine","title":"Step 3: The <code>zk</code> Script (The Engine)","text":"<p>This script automates the build process. It creates a temporary directory, links your project files to the template assets, and runs the server .</p> <p>Save this file as <code>zk</code> in your path (e.g., <code>/usr/local/bin/zk</code>) and make it executable (<code>chmod +x zk</code>).</p> <p>Note: You must edit the <code>BASE</code> variable to match your template path .</p> <pre><code>#!/bin/bash\n# Enable extended globbing (pattern matching) to handle numeric arguments later.\nshopt -s extglob\n\n#\n# USER CONFIGURATION\n#\n\n# Default port for the local server\nPORT=8000\n\n# Default mode is \"serve\" (preview). Set to true to generate static HTML files.\nBUILD=false\n\n# IMPORTANT: Absolute path to your centralized template folder.\n# This folder must contain the 'mkdocs.yml' and the 'assets' folder.\nBASE_TEMPLATE=\"/path/to/your/template\" \n\n# Optional: Activate your Python/Conda environment containing MkDocs.\n# Uncomment the line below if you run this outside of an active environment.\n# source ~/anaconda3/bin/activate mkdocs\n\n#\n# ARGUMENT PARSING\n#\n# This section checks if the user provided arguments like \"b\" or a port number.\n\ncase $1 in\n    \"b\")\n        # Usage: ./zk b\n        # Enables build mode (generates the 'site' folder).\n        BUILD=true\n    ;;\n    +([0-9])) \n        # Usage: ./zk 8085\n        # If the argument is just a number, treat it as the Port.\n        PORT=$1\n    ;;\nesac\n\n#\n# VARIABLES &amp; PREPARATION\n#\n\n# Flags to track which temporary links we created (to delete them later)\nUSING_TEMPLATE=false\nLINKED_ASSETS=false\nLINKED_INDEX=false\nCFG=\"\"\n\n# Save the current directory (Project Folder)\nSRC=$PWD\n\n# Define a temporary location for the build process.\n# We use /tmp to ensure we don't clutter your home directory.\n# ${PWD##*/} extracts just the current folder name (e.g., \"event\").\nTMP=\"/tmp/mkdocs-build-${PWD##*/}\" \n\n#\n# LOGIC: VIRTUAL ENVIRONMENT SETUP\n#\n\n# Check: Does this folder already have a full mkdocs.yml?\n# If NOT, we assume it's a \"Content-Only\" project and needs the Template.\nif [ ! -f \"mkdocs.yml\" ]; then\n    USING_TEMPLATE=true\n\n    # Create a clean temporary directory and move into it\n    mkdir -p $TMP\n    cd $TMP\n\n    # Link the Project Content\n    # We create a link named 'docs' pointing to your actual project files.\n    # MkDocs expects content to be in a folder named 'docs'.\n    ln -sf $SRC docs\n\n    # Link the Template Cache (Optional)\n    # This helps speed up builds if you have plugins that cache data.\n    ln -sf $BASE_TEMPLATE/.cache .\n\n    # Link the Base Config\n    ln -sf $BASE_TEMPLATE/mkdocs.yml .\n\n    # Inject Assets (CSS/JS)\n    # If your project doesn't have an 'assets' folder, we borrow the template's.\n    # We link it inside your source folder so the preview works correctly.\n    if [ ! -d \"$SRC/assets\" ]; then\n        LINKED_ASSETS=true\n        ln -s $BASE_TEMPLATE/assets $SRC/\n    fi\n\n    # Inject Default Homepage\n    # If you haven't written an index.md yet, use the generic one from the template.\n    if [ ! -f \"$SRC/index.md\" ]; then\n        LINKED_INDEX=true\n        ln -s $BASE_TEMPLATE/index.md $SRC/\n    fi\n\n    # Handle Configuration Inheritance\n    # If the project has a 'mkdocs-inherit.yml' (Delta config), we use it.\n    if [ -f \"$SRC/mkdocs-inherit.yml\" ]; then\n        # Tell MkDocs to use this specific file\n        CFG=\"-f mkdocs-inherit.yml\"       \n        # Link the inherit file to the temp dir\n        ln -sf $SRC/mkdocs-inherit.yml .\n    fi\nfi\n\n#\n# EXECUTION\n#\n\nif $BUILD; then\n    # Generates the static site (usually into a 'site' folder)\n    echo \"Building static site...\"\n    mkdocs build $CFG\nelse\n    # Starts the live preview server.\n    # --dirty: Only rebuilds modified files (faster).\n    # --clean: Cleans up stale artifacts before starting.\n    # -a: Binds to 0.0.0.0 to allow access from other devices on the network.\n    echo \"Starting local server on port $PORT...\"\n    mkdocs serve --livereload --dirty --clean -a 0.0.0.0:$PORT $CFG\nfi\n\n#\n# CLEANUP\n#\n# This runs after you stop the server (Ctrl+C).\n\nif $USING_TEMPLATE; then\n    # Go back to the original folder\n    cd $SRC\n\n    # Delete the temporary build environment\n    rm -rf $TMP\nfi\n\n# Remove the temporary 'assets' link from your project folder\nif $LINKED_ASSETS; then\n    rm \"$SRC/assets\"\nfi\n\n# Remove the temporary 'index.md' link from your project folder\nif $LINKED_INDEX; then\n    rm \"$SRC/index.md\"\nfi\n\n# End of script\n</code></pre>"},{"location":"blog/2026/01/26/mkdocs-workflow/#step-4-daily-usage","title":"Step 4: Daily Usage","text":"<p>With the setup complete, here is the workflow:</p> <ol> <li>Open your project folder.</li> <li>Edit content using your preferred tool:<ul> <li>Zettlr: Great for a \"notebook\" feel with Markdown highlighting.</li> <li>Kate: Excellent for a lightweight, pure text editing experience.</li> </ul> </li> <li>Run the script: Open a terminal in the folder and type: <pre><code>zk\n</code></pre> Or specifying a port: <pre><code>zk 8085\n</code></pre></li> <li>It's possible to edit the Markdown file; MkDocs' live reload will refresh the page in your browser.</li> </ol> <p>The script will handle the linking, launch the server, and clean up the temporary links when you press <code>Ctrl+C</code>. This keeps your source directory perfectly clean, containing only your text files.</p>"},{"location":"books/books/","title":"Books","text":"<p>Selected books, ebooks, wikibooks, papers, publications, and related topics that I collect over time. Includes some documents that I have edited.</p> <ul> <li>Setzer, V. W. (1988). Sistema simples para documenta\u00e7\u00e3o semi-autom\u00e1tica de programas. https://repositorio.usp.br/item/000781431 (in Portuguese) (this article is publicly available) [PDF] [HTML]. Notes: the PDF document was created using ScanTailor, OCRmyPDF, and Master PDF Editor 4. The HTML document was made by manually editing the text file generated by OCR.</li> <li>Setzer, V. W., &amp; Melo, I. S. H. de. (1989). A Constru\u00e7\u00e3o de Um Compilador. https://www.ime.usp.br/~vwsetzer (in Portuguese) [PDF] [Notes]</li> <li>Pinto, T. T. S. (2014). GGLL: a parser generator for LL(1) graphical grammars. University of Sao Paulo. DOI 10.11606/D.45.2014.tde-23012015-075452. http://www.teses.usp.br/teses/disponiveis/45/45134/tde-23012015-075452/</li> <li>Threaded Interpretive Languages: Their Design and Implementation, by RG Loeliger - explores the principles and architecture of threaded interpretive languages, with a specific focus on Forth-like languages. </li> <li>Threaded code designs for Forth interpreters, by PJ Hong - techniques for implementing threaded code in Forth interpreters.</li> <li>Library with several books on compilers, computers, and programming.</li> </ul>"},{"location":"books/books/#wikibooks","title":"Wikibooks","text":"<ul> <li>Compiler - from the book Introduction to Software Engineering. Overview of compilers, explaining how they transform source code written in a high-level programming language into machine code or another lower-level language.</li> <li>Compiler Construction - provides a detailed guide on the theory and practice of compiler construction, including lexical analysis, parsing, semantic analysis, optimization, and code generation.</li> </ul>"},{"location":"books/books/#revision-numbers","title":"Revision numbers","text":"<p>The documents I edit have revision numbers in the filename, to facilitate identification and handling. The numbering rules are based on [Scriptorium (2018)].</p> <ul> <li>The revision number is always changed when any change is made to the document, including its name.</li> <li>The initial revision number when creating the document for the first time will be <code>r1.0</code> .</li> <li>The following numbers will be renamed by increasing one decimal place (r1.1, r1.2, r1.3, ...).</li> <li>When r1.9 is reached, the next number will be r2.0.</li> <li>In case of a radical change (addition of illustrations, notes and similar situations), it is allowed to jump directly to the next integer number (e.g.: from r1.4 to r2.0).</li> <li>In cases where the content of the document does not change, but is only compacted, or some other external change, the number will have an \"a\" added to the end: r1.0a, r1.1a, ...</li> </ul>"},{"location":"books/books/#latex","title":"LaTeX","text":"<ul> <li>Example of how to generate PDF/A-3u using LaTeX and LuaTeX. [.tex] [.pdf]<ul> <li>Passes validation test: https://xodo.com/validate-pdfa and https://demo.verapdf.org/</li> </ul> </li> <li>Example of how to generate PDF 2.0 using LaTeX and LuaTeX. [.tex] [.pdf]<ul> <li>Passes validation test: https://www.pdf-online.com/osa/validate.aspx</li> </ul> </li> </ul>"},{"location":"books/autodoc/autodoc/","title":"Um Sistema Simples para Documenta\u00e7\u00e3o Semi Autom\u00e1tica de Programas","text":"<p>Este documento est\u00e1 publicamente dispon\u00edvel em https://repositorio.usp.br/item/000781431, e foi manualmente convertido para Markdown GFM a partir de texto gerado por OCRmyPDF.</p> <p>Autor: V. W. Setzer Data: 1988 Relat\u00f3rio T\u00e9cnico RI-MAC-880 DEPARTAMENTO DE CI\u00caNCIA DA COMPUTA\u00c7\u00c3O UNIVERSIDADE DE S\u00c3O PAULO INSTITUTO DE MATEM\u00c1TICA E ESTAT\u00cdSTICA S\u00c3O PAULO - BRASIL</p>"},{"location":"books/autodoc/autodoc/#1-introducao","title":"1. INTRODU\u00c7\u00c3O","text":"<p>A documenta\u00e7\u00e3o de programas \u00e9 um dos aspectos cruciais do desenvolvimento de sistemas computacionais em qualquer ambiente. Desde o desenvolvimento de \"software\" b\u00e1sico, at\u00e9 o de \"software aplicativo\" para processamentos administrativos, a atividade de programa\u00e7\u00e3o usando alguma linguagem de programa\u00e7\u00e3o requer um esfor\u00e7o espec\u00edfico na documenta\u00e7\u00e3o de sistemas e programas. Esse fato independe da linguagem: essa necessidade existe desde a programa\u00e7\u00e3o em linguagem de montagem (\"assembler\") at\u00e9 o uso de linguagens denominadas de \"4\u00aa gera\u00e7\u00e3o\".</p> <p>Temos verificado continuamente que as documenta\u00e7\u00f5es de sistemas e programas em geral simplesmente inexistem ou s\u00e3o inadequadas e desatualizadas. As principais consequ\u00eancias desses fatos s\u00e3o:</p> <ol> <li>A manuten\u00e7\u00e3o de programas \u00e9 muito cara e demorada.</li> <li>A fase de testes de programas demanda um tempo exagerado e sobrecarrega os analistas e programadores.</li> <li>N\u00e3o h\u00e1 seguran\u00e7a e confian\u00e7a de que os programas est\u00e3o corretos.</li> <li>O autor de um programa torna-se o \"pai\" do mesmo, pois ningu\u00e9m mais consegue compreend\u00ea-lo e mant\u00ea-lo.</li> <li>N\u00e3o h\u00e1 meios para se verificar a documenta\u00e7\u00e3o, isto \u00e9, se ela realmente reflete a estrutura do programa.</li> <li>A ger\u00eancia n\u00e3o consegue saber se um programa est\u00e1 bem documentado.</li> <li>O projeto, a programa\u00e7\u00e3o e a documenta\u00e7\u00e3o devem ser feitos pelas mesmas pessoas.</li> </ol> <p>Neste artigo apresentamos um sistema extremamente simples de documenta\u00e7\u00e3o de programas atrav\u00e9s de coment\u00e1rios feitos na sintaxe (de coment\u00e1rios) da pr\u00f3pria linguagem de programa\u00e7\u00e3o do programa. Um programa tamb\u00e9m simples (apresentado aqui com o exemplo da documenta\u00e7\u00e3o em sua vers\u00e3o em Pascal para o VAX) \u00e9 empregado para gerar automaticamente tr\u00eas n\u00edveis de documenta\u00e7\u00e3o. Delineamos tamb\u00e9m um programa para gerar automaticamente a documenta\u00e7\u00e3o das altera\u00e7\u00f5es efetuadas em um programa, feitas em um editor de textos qualquer. Veremos como esse sistema tamb\u00e9m pode for\u00e7ar metodologias \"top-down\" de programa\u00e7\u00e3o (refinamentos sucessivos), como permite introduzir e controlar padr\u00f5es de documenta\u00e7\u00e3o e como diminui as consequ\u00eancias apresentadas acima.</p>"},{"location":"books/autodoc/autodoc/#2-niveis-de-documentacao","title":"2. N\u00cdVEIS DE DOCUMENTA\u00c7\u00c3O","text":"<p>Em nosso sistema empregamos tr\u00eas n\u00edveis de documenta\u00e7\u00e3o; ele pode ser facilmente estendido para conter mais n\u00edveis, se for conveniente. Os n\u00edveis cont\u00eam o seguinte:</p> <ul> <li>Nivel 1: Informa\u00e7\u00f5es gerais sobre os programas e procedimentos.</li> <li>Nivel 2: Toda a documenta\u00e7\u00e3o de n\u00edvel 1, mais estruturas conceituais de dados e de programas e rotinas.</li> <li>Nivel 3: Todas as documenta\u00e7\u00f5es de n\u00edveis 1 e 2, mais o programa propriamente dito, com documenta\u00e7\u00e3o de seus detalhes.</li> </ul> <p>Note-se o encaixamento dos conte\u00fados de cada n\u00edvel em rela\u00e7\u00e3o aos n\u00edveis anteriores.</p>"},{"location":"books/autodoc/autodoc/#3-especificacoes-dos-niveis","title":"3. ESPECIFICA\u00c7\u00d5ES DOS N\u00cdVEIS","text":"<p>A documenta\u00e7\u00e3o de n\u00edvel 1 \u00e9 inserida no programa sob forma de coment\u00e1rios ocupando linhas completas (isto \u00e9, n\u00e3o deve haver nada, nessas linhas, al\u00e9m desses coment\u00e1rios), que denominaremos de coment\u00e1rios de n\u00edvel 1. Eles s\u00e3o identificados colocando-se o digito '1' ap\u00f3s o s\u00edmbolo de in\u00edcio de coment\u00e1rio da linguagem, que deve ser inserido na posi\u00e7\u00e3o mais \u00e0 esquerda da linha (coluna 1), como por exemplo '(1', '{1' ou '1' (dependendo da linguagem). O simbolo de fim de coment\u00e1rio deve ser colocado nas \u00faltimas posi\u00e7\u00f5es da linha.</p> <p>A documenta\u00e7\u00e3o de n\u00edvel 2, como vimos, cont\u00e9m a de n\u00edvel 1, produzida pelos coment\u00e1rios de n\u00edvel 1, e mais os coment\u00e1rios de n\u00edvel 2. Estes s\u00e3o linhas de coment\u00e1rios de formato id\u00eantico ao dos coment\u00e1rios de n\u00edvel 1, excetuando-se o d\u00edgito '2' colocado no lugar do '1'.</p> <p>A documenta\u00e7\u00e3o de n\u00edvel 3 cont\u00e9m as duas anteriores, e mais todos os comandos do programa e coment\u00e1rios de n\u00edvel 3. Estes s\u00e3o inseridos no programa em qualquer posi\u00e7\u00e3o das linhas, usando-se simplesmente os s\u00edmbolos de coment\u00e1rios da linguagem empregada. Evidentemente, n\u00e3o devem confundir-se com os coment\u00e1rios de n\u00edvel 1 e 2; portanto, n\u00e3o devem conter os d\u00edgitos '1' ou '2' imediatamente ap\u00f3s o s\u00edmbolo de in\u00edcio de coment\u00e1rio.</p>"},{"location":"books/autodoc/autodoc/#4-listador-da-documentacao","title":"4. LISTADOR DA DOCUMENTA\u00c7\u00c3O","text":"<p>O \"listador\" da documenta\u00e7\u00e3o \u00e9 um programa que solicita do usu\u00e1rio a informa\u00e7\u00e3o do n\u00edvel de documenta\u00e7\u00e3o desejado, e em seguida varre sequencialmente o arquivo com o programa, produzindo uma listagem contendo o seguinte:</p> <p>a) Cabe\u00e7alho em cada p\u00e1gina, contendo o nome do programa, o n\u00edvel de documenta\u00e7\u00e3o, a data e a hora da listagem e o n\u00famero da p\u00e1gina.</p> <p>b) Se o n\u00edvel desejado \u00e9 3, a listagem conter\u00e1 todas as linhas do programa, incluindo todos os coment\u00e1rios, precedida cada uma por um n\u00famero de linha. Esse n\u00famero \u00e9 o n\u00famero de ordem de cada linha do programa, incluindo todos os coment\u00e1rios dos v\u00e1rios n\u00edveis.</p> <p>c) Se o n\u00edvel desejado for 1 ou 2, a listagem conter\u00e1 as linhas de coment\u00e1rio extra\u00eddas do programa, conforme o n\u00edvel desejado, precedidas do n\u00famero de linha correspondente \u00e0 listagem do n\u00edvel 3.</p> <p>Por meio dos n\u00fameros de linhas pode-se estabelecer rapidamente uma correspond\u00eancia visual entre as linhas das listagens dos v\u00e1rios n\u00edveis de documenta\u00e7\u00e3o.</p>"},{"location":"books/autodoc/autodoc/#5-exemplo-detalhes-das-documentacoes","title":"5. EXEMPLO - DETALHES DAS DOCUMENTA\u00c7\u00d5ES","text":"<p>No ap\u00eandice apresentamos como exemplo as listagens dos tr\u00eas n\u00edveis de documenta\u00e7\u00e3o para o programa COMENT.PAS. Esse programa \u00e9 justamente um listador para programas escritos em Pascal, COBOL ou ZIM. Ele foi escrito em Pascal para o VAX. A partir desse exemplo especificaremos aquilo que, at\u00e9 o presente momento, consideramos como interessante constar da documenta\u00e7\u00e3o de cada n\u00edvel.</p>"},{"location":"books/autodoc/autodoc/#51-nivel-1","title":"5.1. N\u00edvel 1","text":"<p>Note-se que ao programa principal e a cada procedimento corresponde um trecho da documenta\u00e7\u00e3o deste n\u00edvel. Esta deve ser totalmente conceitual, isto \u00e9, deve ser voltada para o problema (ou \"mundo real\", se for o caso). Assim, num sistema de conferi\u00e7\u00e3o de notas fiscais colocar\u00edamos \"verifica\u00e7\u00e3o do ICM\" e n\u00e3o \"verifica\u00e7\u00e3o do campo NFICM do registro R2\". Al\u00e9m disso, deve ser totalmente auto-contida, isto \u00e9, deve ser independente das documenta\u00e7\u00f5es de n\u00edveis 2 e 3, a menos dos n\u00fameros de linhas. Denominamos nessa documenta\u00e7\u00e3o de \"entradas\" e \"sa\u00eddas\" os dados transportados de e para unidades externas, respectivamente. Denominamos de \"importa\u00e7\u00f5es\" e \"exporta\u00e7\u00f5es\" os dados que s\u00e3o globais a ou s\u00e3o par\u00e2metros de procedimentos; no primeiro caso acrescentamos a palavra \"globais\".</p> <p>Note-se, ainda, a enumera\u00e7\u00e3o dos nomes dos procedimentos chamados (\"rotinas chamadas\") e quais procedimentos chamam uma certa rotina (\"chamado por\").</p>"},{"location":"books/autodoc/autodoc/#52-nivel-2","title":"5.2. N\u00edvel 2","text":"<p>Observe-se que a documenta\u00e7\u00e3o deste n\u00edvel cont\u00e9m a de n\u00edvel 1; distinguimos os coment\u00e1rios de n\u00edveis 1 e 2 por meio da impress\u00e3o do digito que constava do in\u00edcio do coment\u00e1rio correspondente.</p> <p>Como no n\u00edvel 1, os coment\u00e1rios de n\u00edvel 2 devem ser totalmente conceituais. Al\u00e9m disso, devem ser totalmente independentes da documenta\u00e7\u00e3o de n\u00edvel 3, a menos dos n\u00fameros de linhas.</p> <p>No exemplo, n\u00e3o colocamos as estruturas dos dados, pois elas s\u00e3o demasiado elementares; se existissem, deveriam ser independentes da estrutura \"f\u00edsica\". Por exemplo, deveriam comentar o mais conceitualmente poss\u00edvel o conte\u00fado dos arquivos como conjuntos ou tabelas (vis\u00e3o relacional) em rela\u00e7\u00e3o com o problema ou \u201cmundo real\u201d.</p> <p>A estrutura dos programas \u00e9 dada em um \"Portugu\u00eas estruturado\". Chamamos a aten\u00e7\u00e3o para o fato de que procuramos evitar em nosso \"Portugu\u00eas estruturado\" o uso de palavras reservadas das linguagens de programa\u00e7\u00e3o usuais pois cremos que a descri\u00e7\u00e3o de algoritmos deve libertar-se das amarras estruturais e lingu\u00edsticas impostas por essas linguagens. Assim, n\u00e3o precedemos as condi\u00e7\u00f5es com \"se...\" para evitar propositalmente a conota\u00e7\u00e3o com o \"if\". De fato, essas condi\u00e7\u00f5es est\u00e3o formuladas como perguntas com interroga\u00e7\u00e3o, e podem gerar tanto estruturas como \"if\u201d quanto \"case\". Infelizmente, n\u00e3o encontramos uma alternativa melhor do que \"caso contr\u00e1rio\" para o \"sen\u00e3o\". \u00c9 importante nesse n\u00edvel tratar os dados como conjuntos e elementos de conjuntos. Por exemplo, uma certa malha de repeti\u00e7\u00e3o (\"loop\") poderia ser especificada como \"processa cada linha da nota fiscal\".</p> <p>Aten\u00e7\u00e3o especial deve ser dada para o alinhamento vertical: \u00e9 ele que d\u00e1 a estrutura de composi\u00e7\u00e3o das a\u00e7\u00f5es. A regra empregada \u00e9 a seguinte: se uma linha m come\u00e7a na coluna i, a pr\u00f3xima linha n a ser executada sequencialmente depois de m, independentemente da composi\u00e7\u00e3o desta, deve ser a pr\u00f3xima linha que tamb\u00e9m come\u00e7a na coluna i; entre m e n n\u00e3o deve ocorrer nenhuma linha com algum caractere em colunas de \u00edndice menor ou igual a i.</p> <p>Note-se a correspond\u00eancia da numera\u00e7\u00e3o das documenta\u00e7\u00f5es de n\u00edvel 1 e de n\u00edvel 2.</p>"},{"location":"books/autodoc/autodoc/#53-nivel-3","title":"5.3. N\u00edvel 3","text":"<p>Note-se que a documenta\u00e7\u00e3o deste n\u00edvel cont\u00e9m todo o programa, com os coment\u00e1rios de n\u00edveis 1, 2 e 3, exatamente como ocorrem no arquivo.</p> <p>Observe-se que todas as vari\u00e1veis do programa foram documentadas atrav\u00e9s de coment\u00e1rios de n\u00edvel 3. Esse \u00e9 o n\u00edvel correto para isso, pois vari\u00e1veis n\u00e3o t\u00eam nada a ver com a descri\u00e7\u00e3o conceitual dos n\u00edveis superiores. Al\u00e9m disso, foram colocados alguns coment\u00e1rios de n\u00edvel 3 para comandos do programa.</p> <p>Procuramos seguir a mesma regra de alinhamento vertical exposta para os coment\u00e1rios de n\u00edvel 2. Infelizmente, o resultado n\u00e3o foi exatamente o desejado, mas \u00e9 suficiente para ilustrar essa nossa \u00fanica regra; a exist\u00eancia de uma s\u00f3 regra de alinhamento, ao contr\u00e1rio de maneiras usuais de alinhar comandos de programas, que cont\u00eam regras especificas para certos comandos, tem a inten\u00e7\u00e3o de uniformizar e simplificar essa disposi\u00e7\u00e3o, independentemente da linguagem.</p> <p>Finalmente, note-se como os comandos do programa aparecem inseridos nos coment\u00e1rios de n\u00edvel 2; cada um destes est\u00e1 documentando conceitualmente a a\u00e7\u00e3o executada pelos comandos que o seguem e que precedem o pr\u00f3ximo coment\u00e1rio daquele n\u00edvel.</p>"},{"location":"books/autodoc/autodoc/#6-documentacao-das-alteracoes","title":"6. DOCUMENTA\u00c7\u00c3O DAS ALTERA\u00c7\u00d5ES","text":"<p>Se se deseja documentar o hist\u00f3rico de todas as altera\u00e7\u00f5es efetuadas em um programa, a simples listagem das v\u00e1rias vers\u00f5es do mesmo n\u00e3o \u00e9 pr\u00e1tica, pois \u00e9 relativamente dif\u00edcil deduzir quais foram as modifica\u00e7\u00f5es introduzidas empregando-se uma compara\u00e7\u00e3o visual entre as listagens de duas vers\u00f5es consecutivas. Muitos programadores empregam um programa especial de compara\u00e7\u00e3o de arquivos, que salienta as diferen\u00e7as. Essa solu\u00e7\u00e3o n\u00e3o \u00e9 satisfat\u00f3ria em casos de muitas altera\u00e7\u00f5es. Vejamos a solu\u00e7\u00e3o que nosso sistema oferece para esse problema.</p> <p>Afim de documentar as altera\u00e7\u00f5es projetamos um programa de listagem de altera\u00e7\u00f5es LA, que funciona da seguinte maneira:</p> <p>a) O usu\u00e1rio ativa LA e comunica a este que deseja iniciar altera\u00e7\u00f5es; fornece ainda o nome do arquivo, por exemplo A, onde est\u00e1 seu programa P e o nome do editor de textos E que deseja utilizar para editar as altera\u00e7\u00f5es.</p> <p>b) LA abre um novo arquivo A1 e copia P em A1, numerando suas linhas.</p> <p>c) LA passa o controle ao editor E dando A1 como origem do texto.</p> <p>d) O usu\u00e1rio altera Al empregando E, sem alterar nenhuma numera\u00e7\u00e3o de linhas; ele pode alterar o conte\u00fado de linhas de P, inserir neste novas linhas (sem colocar a numera\u00e7\u00e3o destas) ou eliminar linhas (eliminando tamb\u00e9m sua numera\u00e7\u00e3o). O usu\u00e1rio deve tamb\u00e9m inserir linhas de coment\u00e1rio especiais no in\u00edcio de A1, usando um c\u00f3digo de coment\u00e1rio especial como '/#' a partir da coluna 1; essas linhas servem para documentar-se a raz\u00e3o de se ter feito as altera\u00e7\u00f5es. O programa alterado, que denominaremos de P1, \u00e9 ent\u00e3o gravado em A1.</p> <p>e) O usu\u00e1rio ativa LA novamente e comunica a este que deseja emitir as listagens de altera\u00e7\u00f5es, fornecendo os nomes de A e de A1.</p> <p>f) LA varre A numerando internamente as linhas de P. Em paralelo, l\u00ea A1 comparando as suas linhas com as de mesmo n\u00famero de A. Se houver alguma diferen\u00e7a de conte\u00fado entre duas linhas de mesmo n\u00famero, ambas s\u00e3o gravadas em um arquivo de sa\u00edda S, a de A precedida da mensagem \"original\" e a de A1 de \"alterada\". Se houver alguma linha de A com um n\u00famero de linha que n\u00e3o ocorre em A1, ela \u00e9 gravada em S precedida de \"eliminada\". Se ocorrer uma sequ\u00eancia de linhas de A1 sem numera\u00e7\u00e3o, estas s\u00e3o gravadas em S precedidas da mensagem \"linhas inseridas\", da linha de A correspondente \u00e0 linha numerada de A1 imediatamente anterior \u00e0 sequ\u00eancia, e seguidas pela linha de A imediatamente seguinte. Todas as linhas de A1 com c\u00f3digo de coment\u00e1rio especial ('/#') s\u00e3o tamb\u00e9m inseridas em S. </p> <p>q) A medida que LA varre A1 no passo anterior, vai regravando A1 retirando as numera\u00e7\u00f5es de linhas e eliminando as linhas com c\u00f3digo de coment\u00e1rio especial ('/#').</p> <p>h) Ao terminar a varredura de A e de A1, LA executa uma rotina de listagem semelhante ao listador, que l\u00ea S e produz a impress\u00e3o das altera\u00e7\u00f5es em todos os n\u00edveis de documenta\u00e7\u00e3o; cada n\u00edvel \u00e9 precedido dos coment\u00e1rios especiais ('/#').</p> <p>Como resultado desses procedimentos permanece o programa P em A, P1 \u00e9 criado em A1 e obt\u00e9m-se a listagem das altera\u00e7\u00f5es efetuadas na passagem de P para P1, divididas nos v\u00e1rios n\u00edveis de documenta\u00e7\u00e3o, com as numera\u00e7\u00f5es das linhas de P para refer\u00eancia com o programa original e precedida dos coment\u00e1rios especiais que descrevem os motivos das altera\u00e7\u00f5es. O arquivo S pode ser novamente empregado para obter-se novas c\u00f3pias das altera\u00e7\u00f5es, bastando para isso ativar LA e informar que se deseja executar esse passo.</p> <p>Note-se que esse sistema de documentar as altera\u00e7\u00f5es serve tanto para registrar-se as altera\u00e7\u00f5es de manuten\u00e7\u00e3o, como tamb\u00e9m para documentar os passos de desenvolvimento de um programa em um m\u00e9todo por refinamentos sucessivos.</p> <p>Existem v\u00e1rios sistemas de documenta\u00e7\u00e3o de altera\u00e7\u00f5es, denominados de \"version control systems\"; uma descri\u00e7\u00e3o de v\u00e1rios desses sistemas pode ser encontrada em [1]. Em particular, o sistema DIFF origin\u00e1rio do UNIX e transposto para o TURBO-C \u00e9 muito empregado no IBM-PC. Cremos que nossa proposta \u00e9 superior a esses produtos pois est\u00e1 voltada especificamente para o sistema de documenta\u00e7\u00e3o aqui descrito, al\u00e9m de adaptar-se a qualquer editor de textos. Note-se que a numera\u00e7\u00e3o das linhas feitas pelo nosso sistema resolve todos os problemas de compara\u00e7\u00e3o entre as linhas sem prejudicar o usu\u00e1rio, pelo contr\u00e1rio, est\u00e1 dentro do esquema da documenta\u00e7\u00e3o produzida pelo listador.</p>"},{"location":"books/autodoc/autodoc/#6-resultados","title":"6. RESULTADOS","text":"<p>Com o m\u00e9todo aqui exposto pode-se obter os seguintes resultados:</p> <ol> <li>Documenta\u00e7\u00e3o de um programa, do seu desenvolvimento e de sua manuten\u00e7\u00e3o em v\u00e1rios n\u00edveis de abstra\u00e7\u00e3o.</li> <li>Programa\u00e7\u00e3o \"top-down\". Deve-se desenvolver um programa come\u00e7ando-se pelos coment\u00e1rios de n\u00edvel 1, a seguir inserir os de n\u00edvel 2, e finalmente o programa propriamente dito e os coment\u00e1rios de n\u00edvel 3.</li> <li>Gera\u00e7\u00e3o autom\u00e1tica de documenta\u00e7\u00e3o.</li> <li>Acelera\u00e7\u00e3o do desenvolvimento. A documenta\u00e7\u00e3o em v\u00e1rios n\u00edveis auxilia a programa\u00e7\u00e3o e diminui o tempo dedicado aos testes.</li> <li>Acelera\u00e7\u00e3o da manuten\u00e7\u00e3o. Para se fazer manuten\u00e7\u00e3o de um programa, pode-se localizar o ponto de altera\u00e7\u00e3o (ou de erro) \"navegando-se\" pelos n\u00edveis decrescentes de abstra\u00e7\u00e3o da documenta\u00e7\u00e3o. Os n\u00fameros de linhas podem ser empregados para uma r\u00e1pida movimenta\u00e7\u00e3o de um n\u00edvel para outro.</li> <li>Atualiza\u00e7\u00e3o permanente da documenta\u00e7\u00e3o. Qualquer altera\u00e7\u00e3o do programa deve redundar em altera\u00e7\u00e3o nos coment\u00e1rios de n\u00edveis 3, 2 e mesmo 1 se necess\u00e1rio. Os listadores de altera\u00e7\u00f5es e de documenta\u00e7\u00e3o produzir\u00e3o a documenta\u00e7\u00e3o das altera\u00e7\u00f5es efetuadas e da nova vers\u00e3o da documenta\u00e7\u00e3o do programa.</li> <li>Programa\u00e7\u00e3o encadeada. V\u00e1rias pessoas podem. participar do desenvolvimento de um programa, particionando-se a equipe conforme os tr\u00eas n\u00edveis de abstra\u00e7\u00e3o. Isso garante a qualidade das documenta\u00e7\u00f5es de n\u00edveis 1 e 2.</li> <li>Controle da programa\u00e7\u00e3o \"top down\". A listagem das altera\u00e7\u00f5es correspondendo ao desenvolvimento \"top down\", contendo as v\u00e1rias vers\u00f5es do refinamento sucessivo, possibilita \u00e0 ger\u00eancia verificar se a metodologia est\u00e1 sendo corretamente seguida.</li> <li>Controle da documenta\u00e7\u00e3o. A ger\u00eancia pode controlar a documenta\u00e7\u00e3o dos programas, j\u00e1 que \u00e9 relativamente f\u00e1cil seguir as documenta\u00e7\u00f5es de n\u00edveis 1 e 2. A partir destas, n\u00e3o deve ser dif\u00edcil seguir o programa distribu\u00eddo entre elas, e seus coment\u00e1rios de detalhe. A documenta\u00e7\u00e3o das altera\u00e7\u00f5es permite controlar a manuten\u00e7\u00e3o das documenta\u00e7\u00f5es dos n\u00edveis mais altos.</li> <li>Aumento da portabilidade. Altera\u00e7\u00f5es de programas devidas a mudan\u00e7as de ambiente de processamento podem ser feitas com muito maior rapidez, pois devem afetar muito pouco os n\u00edveis 1 e 2 de documenta\u00e7\u00e3o. Em particular, coment\u00e1rios de n\u00edvel 3 podem ser inseridos para salientar as depend\u00eancias de trechos do programa em rela\u00e7\u00e3o ao ambiente.</li> <li>Documenta\u00e7\u00e3o independente dos detalhes de programa\u00e7\u00e3o. A documenta\u00e7\u00e3o de n\u00edvel 1 pode ser empregada por pessoas que desejam conhecer a funcionalidade dos programas e das rotinas sem se importar com detalhes de programa\u00e7\u00e3o.</li> </ol>"},{"location":"books/autodoc/autodoc/#7-conclusoes","title":"7. CONCLUS\u00d5ES","text":"<p>Apresentamos aqui um m\u00e9todo extremamente simples de produzir e manter a documenta\u00e7\u00e3o de programas. Estamos c\u00f4nscios de que esta n\u00e3o \u00e9 uma \u00e1rea promissora, pois a programa\u00e7\u00e3o est\u00e1 desaparecendo devido a introdu\u00e7\u00e3o de geradores universais de aplica\u00e7\u00f5es para processamento de dados administrativos, que em alguns casos como o sistema LDT geram automaticamente programas e documenta\u00e7\u00e3o, sendo esta de alt\u00edssimo n\u00edvel [2]. No entanto, sobram ainda todos os desenvolvimentos de \"software\" b\u00e1sico, quando n\u00e3o s\u00e3o usadas t\u00e9cnicas formais como VDM (ver, como exemplo dessa t\u00e9cnica, [3]), e a grande maioria dos sistemas desenvolvidos em linguagens de programa\u00e7\u00e3o algor\u00edtmicas e de \"4\u00aa gera\u00e7\u00e3o\". Outros esfor\u00e7os tem sido produzidos no sentido de se introduzir coment\u00e1rios significativos nos programas, como o sistema WEB de Knuth [4]. No entanto, trata-se de sistema muito mais complexo, abrangendo inclusive a parte de asser\u00e7\u00f5es para prova de corretude (para uma extensa refer\u00eancia a respeito, ver [5]). Essas asser\u00e7\u00f5es podem evidentemente ser introduzidas em nosso m\u00e9todo como coment\u00e1rios de n\u00edvel 2. O mesmo se passa com coment\u00e1rios de tipo formal como os propostos por Krieg-Brueckner e Luckham [6]. Nesse dois casos, cremos que as asser\u00e7\u00f5es ficam ligadas demais ao c\u00f3digo, de modo que poderiam constituir um n\u00edvel adicional, entre os nossos n\u00edveis 2 e 3. Com isso as asser\u00e7\u00f5es teriam seus pr\u00f3prios coment\u00e1rios; estes serviriam para esclarecer em um n\u00edvel informal o conte\u00fado matem\u00e1tico daquelas, o que daria a documenta\u00e7\u00e3o do desenvolvimento delas e do programa. A documenta\u00e7\u00e3o desse desenvolvimento n\u00e3o \u00e9 a inten\u00e7\u00e3o exposta em [6]. Al\u00e9m disso, nosso sistema tem a vantagem adicional de documentar as vers\u00f5es.</p> <p>\u00c9 interessante observar que as considera\u00e7\u00f5es de Beckman [7] contr\u00e1rias ao uso de coment\u00e1rios em programas n\u00e3o se aplicam as propostas aqui apresentadas, pois os coment\u00e1rios que propomos est\u00e3o intimamente ligados \u00e0 funcionalidade dos programas e de seus trechos, ao desenvolvimento dos mesmos e ao uso do n\u00edvel 1 independentemente dos outros n\u00edveis.</p> <p>Testamos e desenvolvemos estas ideias com alunos de nossa disciplina de Compila\u00e7\u00e3o, em que eles elaboram individualmente um programa de milhares de linhas. Apesar do protesto inicial dos alunos, estes logo perceberam as enormes vantagens do sistema de documenta\u00e7\u00e3o. Em 1987, apenas 22% da turma concluiu o projeto durante o semestre; em 1988, na turma em que testamos o m\u00e9todo, 65% dos alunos o concluiu, provavelmente devido, em boa parte, \u00e0 documenta\u00e7\u00e3o.</p> <p>V\u00e1rias melhorias podem ser introduzidas no sistema. Por exemplo, pode-se eliminar o aparecimento dos n\u00fameros dos n\u00edveis 1 e 2 nas listagens desses n\u00edveis, bastando para isso enquadrar totalmente os coment\u00e1rios de n\u00edvel 1 do programa principal e de cada procedimento em um ret\u00e2ngulo de asteriscos. Como vimos, a possibilidade de se documentar as altera\u00e7\u00f5es de uma vers\u00e3o para outra pode servir de base para documentar todo processo de desenvolvimento do programa por refinamentos sucessivos; al\u00e9m disso os coment\u00e1rios de n\u00edvel 2 poderiam ser subdivididos em v\u00e1rios subn\u00edveis, para produzir uma documenta\u00e7\u00e3o completa desse desenvolvimento.</p> <p>O colega Arnaldo Mandel prop\u00f4s um sistema de 5 n\u00edveis. O n\u00edvel 1 cont\u00e9m a documenta\u00e7\u00e3o para o usu\u00e1rio \"externo\", do sistema como um todo, como se ele s\u00f3 tivesse o programa-objeto; o n\u00edvel 2 cont\u00e9m informa\u00e7\u00f5es para a compila\u00e7\u00e3o; o n\u00edvel 3 \u00e9 uma documenta\u00e7\u00e3o para reutiliza\u00e7\u00e3o das rotinas, com vari\u00e1veis globais, par\u00e2metros, modo de chamar os procedimentos, etc.; o n\u00edvel 4 \u00e9 correspondente ao nosso n\u00edvel 2; o n\u00edvel 5 cont\u00e9m o hist\u00f3rico de altera\u00e7\u00f5es correspondente aos nossos coment\u00e1rios especiais (ele n\u00e3o prop\u00f5e que se documente as altera\u00e7\u00f5es propriamente ditas).</p> <p>Roberto C. Mayer implementou o listador em C, possibilitando que a especifica\u00e7\u00e3o de n\u00edvel (1 ou 2) valha para uma sequ\u00eancia de linhas, e n\u00e3o somente para cada linha: o encerramento do coment\u00e1rio fecha a sequ\u00eancia. Al\u00e9m disso, sua codifica\u00e7\u00e3o de coment\u00e1rio de um desses n\u00edveis pode ser colocada em qualquer posi\u00e7\u00e3o de uma linha, ao contr\u00e1rio da nossa proposta, que exige essa coloca\u00e7\u00e3o no in\u00edcio da linha, simplificando a constru\u00e7\u00e3o do listador. Seu sistema exige, obviamente, um analisador l\u00e9xico para detetar os n\u00edveis e o encerramento dos coment\u00e1rios correspondentes.</p> <p>Mirza Neuman prop\u00f4s o armazenamento apenas da \u00faltima vers\u00e3o da documenta\u00e7\u00e3o e dos arquivos com as altera\u00e7\u00f5es de uma vers\u00e3o para outra, gerando-se uma vers\u00e3o anterior a partir desses dados. Parece-nos que \u00e9 poss\u00edvel construir-se esse programa gerador, pois todos os dados necess\u00e1rios est\u00e3o dispon\u00edveis.</p>"},{"location":"books/autodoc/autodoc/#8-agradecimentos","title":"8. AGRADECIMENTOS","text":"<p>O sistema aqui apresentado foi desenvolvido a partir de ideias lan\u00e7adas por Marcos Ximenes para o sistema ZIM. Especial agradecimento \u00e9 devido a Afonso C.R. Mastrelli, que programou o exemplo dado no ap\u00eandice, com enorme paci\u00eancia de introduzir paulatinamente as nossas seguidas sugest\u00f5es. Wagner T. Martins programou uma excelente vers\u00e3o do listador em NATURAL para o sistema ADABAS.</p>"},{"location":"books/autodoc/autodoc/#9-referencias","title":"9. REFER\u00caNCIAS","text":"<p>[1] Rex, J. - Keeping Track: Five Version Control Systems - Computer Language 5, 6 (June 1988), pp. 111-122.</p> <p>[2] Setzer, V.W. e Marussi, E. - LDT: Um Gerador Universal de Aplica\u00e7\u00f5es para Processamento de Dados - RT-MAC-8806, Departamento de Ci\u00eancia da Computa\u00e7\u00e3o do IME-USP (Junho de 1988).</p> <p>[3] Bjorner, D. - Programming Languages: Formal Development of Interpreters and Compilers - in Proc. Intl. Comp. Symp. ICS'77, North Holland Publ., pp. 1-21.</p> <p>[4] Knuth, D. - Literate Programming - Computer Journal 27, 2 (1984), pp. 97-111.</p> <p>[5] Gries, D. - The Science of Programming - Springer Verlag, N. York (1981).</p> <p>[6] Krieg-Brueckner, B. e Luckham, D.C. - Anna: Towards a Language for Annotating Ada Programs - ACM SIGPLAN Notices 15, 11 (Nov. 1980), pp. 128-138.</p> <p>[7] Beckman, A. - Comments Considered Harmful - ACM SIGPLAN Notices 12, 4 (April 1977), pp. 94-97.</p>"},{"location":"books/autodoc/autodoc/#anexo","title":"ANEXO","text":"<pre><code>PROGRAMA: COMENT.PAS           DOC.NIVEL  1    DATA:  8-AUG-1988 15:57      PAG:   1\n\n    1 1=============================================================================\n    2 1 TITULO: COMENTARIO\n    3 1 AUTOR : AFONSO CELSO ROCHA MASTRELLI\n    4 1 DATA  : 29/06/88\n    5 1 VERSAO: 1.2\n    6 1 FINALIDADE : GERAR RELATORIO CONTENDO A DCCUMENTACAO DE DETERMINADO PRO-\n    7 1              GRAMA;\n    8 1 ENTRADAS : ARQUIVO QUE CONTEM O COLICGO FONTE (EM PASCAL, COBOL OU ZIM)\n    9 1            COMENTADO POR NIVEIS; CODIGO DO NIVEL DE COMENTARIO DESEJADO;\n   10 1 SAIDAS   : RELATORIO COM A DOCUMENTACAO EXTRAIDA DO ARQUIVO FONTE;\n   11 1 ROTINAS CHAMADAS: LIB$DO_COMMAND (EXTERNA), MOSTRA_TELA, CABECALHO,\n   12 1                   RELAT, RELATPAS E SYS$ASCTIM (EXTERNA);\n   13 1=============================================================================\n   51 1=============================================================================\n   52 1 ROTINA: MOSTRA-TELA;\n   53 1 FINALIDADE: MOSTRA MENU AO USUARIO, PERGUNTANDO E RECEBENDO O NIVEL DE\n   54 1             DOCUMENTACAO QUE ELE QUER E O NOME DO ARQUIVO A SER LIDO,\n   55 1             PASSANDO ESSAS INFORMAC\u00d5ES AO PROGRAMA PRINCIPAL;\n   56 1 ENTRADAS: NIVEL DE DOCUMENTACAO E NOME DO ARQUIVO A SER LIDO;\n   57 1 EXPORTACDES GLOBAIS: NIVEL DE DOCUMENTACAO E NOME DO ARQUIVO A SER LIDO;\n   58 1 CHAMADO POR: COMENTARIO;\n   59 1=============================================================================\n  111 1=============================================================================\n  112 1 ROTINA: CABECALHO;\n  113 1 FINALIDADE: IMPRIMIR CABECALHO NO INICIO DE CADA PAGINA DO RELATORIO;\n  114 1 IMPORTACOES GLOBAIS: NOME DO ARQUIVO LIDO, NIVEL DE DOCUMENTACAO,\n  115 1                      DATA E HORA ATUAIS;\n  116 1 SAIDA: LINHA DE CABECALHO IMPRESSA NO ALTO DE CADA PAG. DA LISTACEM;\n  117 1 CHAMADO POR: COMENTARIO;\n  118 1=============================================================================\n  142 1=============================================================================\n  143 1 ROTINA: RELAT;\n  144 1 FINALIDADE: FAZ LEITURA DO ARQUIVO DE ENTRADA (EM COBOL OU ZIM) E MONTA O\n  145 1             DE SAIDA;\n  146 1 IMPORTACOES: CARACTERE QUE IDENTIFICA A LINHA DE COMENTARIO NA LINGUAGEM\n  147 1              UTILIZADA (COBOL OU ZIM);\n  143 1 SAIDA  : COMENTARIOS DO PROGRAMA DE ENTRADA NO NIVEL DESEJADO;\n  149 1 CHAMADO POR: COMENTARIO;\n  150 1=============================================================================\n  206 1=============================================================================\n  207 1 ROTINA: RELATPAS;\n  208 1 FINALIDADE: FAZ LEITURA DO ARQUIVO DE ENTRADA (EM PASCAL) E MONTA O DE\n  209 1             SAIDA;\n  210 1 SAIDA: COMENTARIOS DO PROGRAMA DE ENTRADA NO NIVEL DESEJADO;\n  211 1 CHAMADO POR: COMENTARIOS;\n  212 1=============================================================================\n\n\nPROGRAMA: COMENT.PAS           DOC.NIVEL  2    DATA:  8-AUG-1988 15:59      PAG:   1\n\n    1 1=============================================================================\n    2 1 TITULO: COMENTARIO\n    3 1 AUTOR : AFONSO CELSO ROCHA MASTRELLI\n    4 1 DATA  : 29/06/88\n    5 1 VERSAO: 1.2\n    6 1 FINALIDADE : GERAR RELATORIO CONTENDO A DOCUMENTACAO DE DETERMINADO PRO-\n    7 1              GRAMA;\n    8 1 ENTRADAS : ARQUIVO QUE CONTEM O CODIGO FONTE (EM PASCAL, COBOL OU ZIM)\n    9 1            COMENTADO POR NIVEIS;  CODIGO DO NIVEL DE CCMENTARIO DESEJADO;\n   10 1 SAIDAS   : RELATORIO COM A DCOCUMENTACAO EXTRAIDA DO ARQUIVO FONTE;\n   11 1 ROTINAS CHAMADAS: LIB$DO_COMMAND (EXTERNA), MOSTRA-TELA, CABECALHO,\n   12 1                   RELAT, RELATPAS E SYS$ASCTIM (EXTERNA);\n   13 1=============================================================================\n   51 1=============================================================================\n   52 1 ROTINA: MOSTRA-TELA;\n   53 1 FINALIDADE: MOSTRA MENU AO USUARIOS PERGUNTANDO E RECEBENDO O NIVEL DE\n   54 1             DOCUMENTACAO QUE ELE QUER E O NOVE DO ARQUIVO A SER LIDO,\n   55 1             PASSANDO ESSAS INFORMACOES AU PROGRAMA PRINCIPAL;\n   56 1 ENTRADAS: NIVEL DE DOCUMENTACAD E NOME DO ARQUIVO A SER LIDO;\n   57 1 EXPORTACOES GLOBAIS: NIVEL DE DOCUMENTACAO E NOME DO ARQUIVO A SER LIDO;\n   58 1 CHAMADO POR: COMENTARIO;\n   59 1=============================================================================\n   61 1=============================================================================\n   62 2 INICIO DE MOSTRA-TELA;\n   63 2 LIMPA A TELA\n   65 2 MOSTRA MENU DE OPCOES AO USUARIO\n   84 2 LE OPCAO DO USUARIO\n   86 2 OPCAO LIDA E' DE CONTINUAR A EXECUCAO ?\n   91 2       LE NOME DO ARQUIVO DE ENTRADA\n   95 2       LE NOME DA LINGUAGEM UTILIZADA NO PROGRAPA\n   97 2       LINGUACEM NAO E' COBOL NEM ZIM?\n  101 2         ASSUME-SE PASCAL COMO LINGUAGEM UTILIZADA\n  106 2 FIM-DE-MOSTRA-TELA\n  111 1=============================================================================\n  112 1 ROTINA: CABECALHO;\n  113 1 FINALIDADE: IMPRIMIR CABECALHO NO INICIO DE CADA PAGINA DO RELATORIO;\n  114 1 IMPORTACOES GLOBAIS: NOME DO ARQUIVO LIDO, NIVEL DE DOCUMENTACAO,\n  115 1                      DATA E HORA ATUAIS;\n  116 1 SAIDA: LINHA DE CABECALHO IMPRESSA NO ALTO DE CADA PAG. DA LISTACEM;\n  117 1 CHAMADO POR: COMENTARIO;\n  118 1=============================================================================\n  121 2 INICIO DE CABECALHO;\n  122 2 PAGINA ESTA' CHEIA ?\n  125 2       ATUALIZA O NUMERO DA PAGINA.\n  127 2       RELATORIO JA' FOI INICIALIZADO ?\n  129 2           SALTA PAGINA\n  131 2       ESCREVE LINHA DE CABECALHO;\n  138 2 FIM DE CABECALHO;\n  142 1=============================================================================\n  143 1 ROTINA: RELAT;\n  144 1 FINALIDADE: FAZ LEITURA DU ARQUIVO DE ENTRADA (EM COBOL OU ZIM) E MONTA O\n  145 1             DE SAIDA;\n  146 1 IMPORTACOES: CARACTERE QUE IDENTIFICA A LINHA DE COMENTARIO NA LINGUAGEM\n  147 1              UTILIZADA (COBOL OU ZIM);\n\n\n\fPROGRAMA: COMENT.PAS           DOC.NIVEL  2    DATA:  9-AUG-1988 15:59      PAG:   2\n\n  148 1 SAIDA  : COVENTARIOS DO PROGRAMA DE ENTRADA NO NIVEL DESEJADO;\n  149 1 CHAMADO POR: COMENTARIO;\n  150 1============================================================================\n  155 2 INICIO DE RELAT;\n  159 2 PARA CADA LINHA DO ARQUIVO DE ENTRADA :\n  162 2     LE LINHA SEQUENCIALMENTE\n  164 2     NUMERA A LINHA LIDA\n  166 2     DOCUMENTACAO E' DE NIVEL 3 ?\n  169 2           ESCREVE LINHA NO RELATORIO\n  174 2       CASO CONTRARIO\n  177 2           LINHA NAO E' NULA ?\n  180 2                 LINHA E' DE COMENTARIO NIVEL 1 ?\n  185 2                       ESCREVE LINHA NO RELATORIO\n  188 2                   CASO CONTRARIO\n  190 2                     E' DE COMENTARIO NIVEL 2 E USUARIO QUER NIVEL 2 ?\n  195 2                           ESCREVE LINHA NO RELATORIO\n  202 2 FIM DE RELAT\n  206 1============================================================================\n  207 1 ROTINA: RELATPAS;\n  208 1 INALIDADE: FAZ LEITURA DO ARQUIVO DE ENTRADA (EM PASCAL) E MONTA O DE\n  209 1            SAIDA;\n  210 1 SAIDA: COMENTARIOS DO PROGRAMA DE ENTRADA NO NIVEL DESEJADO;\n  211 1 CHAMADO POR: COMENTARIO;\n  212 1============================================================================\n  214 2 INICIO DE RELATPAS\n  216 2 PARA CADA LINHA DO ARQUIVO DE ENTRADA :\n  219 2     LE LINHA SEQUENCIALMENTE\n  222 2     DOCUMENTACAD E' DE NIVEL 3 ?\n  225 2           ESCREVE LINHA NO RELATORIO\n  230 2       CASO CONTRARIO\n  233 2           LINHA NAO E' NULA ?\n  236 2                 LINHA E' DE COMENTARIO NIVEL 1 ?\n  241 2                       ESCREVE LINHA NO RELATORIO\n  244 2                   CASO CONTRARIO\n  247 2                       E' DE COMENTARIO NIVEL 2 E USUARIO QUER NIVEL 2 ?\n  252 2                             ESCREVE LINHA NO RELAT\u00d3RIO\n  260 2 FIM DE RELATPAS\n  264 2----------------------------------------------------------------------------\n  265 2                  P R O G R A M A    P R I N C I P A L\n  266 2----------------------------------------------------------------------------\n  267 2 INICIO DE COMENTARIO\n  272 2 EXIBE TELA DE ENTRADA\n  274 2 OPCAO DO USUARIO E' CONTINUAR ?\n  277 2       ABRE ARQUIVOS DE ENTRADA E SAIDA\n  289 2 OPCAO DO USUARIO E' NIVEL 1 OU 2 ?\n  294 2             ENTRADA ESTA' EM PASCAL ?\n  296 2                  PROCESSA ARQUIVO EM PASCAL\n  298 2               CASO CONTRARIO\n  300 2                 PROCESSA ARQUIVO EM COBOL OU ZIM\n  310 2 ALGUM ARQUIVO FOI ABERTO ?\n  313 2       FECHA ARQUIVOS UTILIZADOS\n  317 2 FIM DE COMENTARIO\n\n\n\fPROGRAMA: COMENT.PAS           DOC.NIVEL  3    DATA:  8-AUG-1988 16:00      PAG:   1\n\n    1 (*1===========================================================================*)\n    2 (*1 TITULO: COMENTARIO                                                        *)\n    3 (*1 AUTOR : AFONSO CELSO ROCHA MASTRELLI                                      *)\n    4 (*1 DATA  : 29/06/88                                                          *)\n    5 (*1 VERSAD: 1.2                                                               *)\n    6 (*1 FINALIDADE : GERAR RELATORIO CONTENDO A DOCUMENTACAO DE DE TERMINADO PRO- *)\n    7 (*1              GRAMA;                                                       *)\n    8 (*1 ENTRADAS : ARQUIVO QUE CONTEM O CODICO FONTE (EM PASCAL, COBOL OU ZIM)    *)\n    9 (*1            COMENTADO POR NIVEIS;  CODIGO DO NIVEL DE COMENTARIO DESEJADO; *)\n   10 (*1 SAIDAS   : RELATORIO COM A DOCUMENTACAO EXTRAIDA DO ARQUIVO FONTE;        *)\n   11 (*1 ROTINAS CHAMADAS: LIB$DO_COMMAND (EXTERNA), MOSTRA_TELA, CABECALHO,       *)\n   12 (*1                   RELAT, RELATPAS E SYS$ASCTIM (EXTERNA);                 *)\n   13 (*1===========================================================================*)\n   14 PROGRAM COMENTARIO (INPUT,OUTPUT);\n   15\n   16 CONST\n   17     CLS = CHR(27) + '[H' + CHR(27) + '[J'; (* LIMPA A TELA DO VT100/200/220 *)\n   18 TYPE\n   19     LINHA      = VARYING[120] OF CHAR; (* PARA LINHA DE IMPRESSAO;            *)\n   20     CARACTERE  = CHAR;                 (* PARA PARAMETRO DE RELAT;            *)\n   21     $WORD      = [WORD] 0..65535;      (* PARA PARAMETRO DE SYS$ASCTIM;       *)\n   22     $DATE_TIME = [QUAD] RECORD END;    (* PARA PARAMETRO DE SYS$ASCTIM;       *)\n   23\n   24 VAR\n   25     COMANDO : VARYING[200] OF CHAR; (* COMANDO DCL A SER EXECUTADO;           *)\n   26     LINPROG : LINHA;                (* GUARDA LINHA DO PROGRAMA LIDO;         *)\n   27     OPCAO   : INTEGER;              (* NRO DA CPCAO DO USUARIC NO MENUS       *)\n   28     NOMEARQ : VARYING[30] OF CHAR;  (* NOME DO ARQUIVO QUE CONTEM O PROCRAMA; *)\n   29     SAIDA   : TEXT;                 (* CONTEM O RELATORIO DE SAIDA;           *)\n   30     ENTRADA : TEXT;                 (* PROGRAMA COMENTADO A SECR LIDO;        *)\n   31     LING    : CARACTERE;            (* LINGUAGEM DO PROGRAMA A SER LIDO;      *)\n   32     NUMLIN  : INTEGER;              (* NUMERACAO DAS LINHAS CO FONTE LIDO;    *)\n   33     LINPAG  : INTECER;              (* NUMERO DE LINHAS POR PAGINA;           *)\n   34     NPAG    : INTEGER;              (* NUMERO DA PAGINA DO RELAT\u00d3RIO;         *)\n   35     DATA_HORA: VARYING[17] OF CHAR; (* DATA E HORA RECEBIDA DO SISTEMA;       *)\n   36     RETORNO : INTEGER;              (* SOMENTE AUXILIA O RECEBIMENTO DA HORA; *)\n   37\n   38\n   39 (* ROTINA EXTERNA QUE EXECUTA COMANDO DCL                                     *)\n   40 PROCEDURE LIB$DO_COMMAND(CMDTXT : VARYING[A] OF CHAR); EXTERN;\n   41\n   42\n   43 (* FUNCAO EXTERNA QUE RETORNA DATA E HORA ATUAIS DO SISTEMA OPERACIONAL       *)\n   44 [EXTERNAL] FUNCTION SYS$ASCTIM(%REF NADA1 : $WORD := %IMMED 0;\n   45                                DATA_HORA : [CLASS_S]\n   46                                            PACKED ARRAY[L..U:INTEGER] OF CHAR;\n   47                                %REF NADA2 : $DATE_TIME := %IMMED 0;\n   48                                NADA3 : UNSIGNED := %IMMED 0):INTEGER; EXTERN;\n   49\n   50\n   51 (*1===========================================================================*)\n   52 (*1 ROTINAS: MOSTRA-TELA;                                                     *)\n   53 (*1 FINALIDADE: MOSTRA MENU AO USUARIO, PERGUNTANDO E RECERENDO O NIVEL DE    *)\n\n\nPROGRAMAS COMENT.PAS           DOC.NIVEL  3    DATA:  8-AUG-1988 16:00      PAG:   2\n\n   54 (*1             DOCUMENTACAO QUE ELE QUER E O NOME DO ARGUIVO A SER LIDO,     *)\n   55 (*1             PASSANDO ESSAS INFORMACOES AO PROGRAMA PRINCIPAL;             *)\n   56 (*1 ENTRADAS: NIVEL DE DOCUMENTACAO E NOME DO ARQUIVO A SER LIDO;             *)\n   57 (*1 EXPORTACOES GLOBAIS: NIVEL DE DOCUMENTACAO E NOME DO ARQUIVO A SER LIDO;  *)\n   58 (*1 CHAMADO POR: COMENTARIO;                                                  *)\n   59 (*1===========================================================================*)\n   60 PROCEDURE MOSTRA-TELA;\n   61 (*2 INICIO DE MOSTRA_TELA;                                                    *)\n   62 BEGIN\n   63 (*2 LIMPA A TELA                                                              *)\n   64     WRITE(CLS);\n   65 (*2 MOSTRA MENU DE OPCOES AO USUARIO                                          *)\n   66     WRITELN(' ':25,'DOCUMENTACAO DE SOFTWARE');\n   67     WRITELN(' ':25,'^^^^^^^^^^^^^^^^^^^^^^^^');\n   68     WRITELN;\n   69     WRITELN(' ':10,'VOCE PODE LISTAR 3 NIVEIS DE DOCUMENTACAO DE UM PROGRAMA.');\n   70     WRITELN(' ':10,'O PROGRAMA PODE ESTAR NUMA DAS SEGUINTES LINGUAGENS: ');\n   71     WRITELN;\n   72     WRITELN(' ':27,'[P]ASCAL   (DEFAULT)');\n   73     WRITELN(' ':27,'[C]OBOL');\n   74     WRITELN(' ':27,'[Z]IM');\n   75     WRITELN; WRITELN;\n   76     WRITELN(' ':26,'NIVEIS DE DOCUMENTACAO');\n   77     WRITELN;\n   78     WRITELN(' ':12,'1. DESCRICAO FUNCIONAL + FINALIDADES');\n   79     WRITELN(' ':12,'2. NIVEL 1 + PSEUDO-CODIGO');\n   80     WRITELN(' ':12,'3. NIVEIS 1 E 2 + CODIGO FONTE');\n   81     WRITELN(' ':12,'4. F I M');\n   82     WRITELN; WRITELN;\n   83     WRITE(' ':15,'SUA OPCAO E''        :');\n   84 (*2 LE OPCAO DO USUARIO                                                        *)\n   85     READLN(OPCAO);\n   86 (*2 OPCAO LIDA E' DE CONTINUAR A EXECUCAO ?                                    *)\n   87     IF ((OPCAO = 1) OR (OPCAO = 2) OR (OPCAO = 3 )) THEN\n   88       BEGIN\n   89           WRITELN;\n   90           WRITE(' ':15,'NOME DO ARQUIVO     : ');\n   91 (*2       LE NOME DO ARQUIVO DE ENTRADA                                       *)\n   92           READLN(NOMEARQ);\n   93           WRITELN;\n   94           WRITE(' ':15,'LINGUAGEM UTILIZADA : ');\n   95 (*2       LE NOME DA LINGUAGEM UTILIZADA NO PROGRAMA                          *)\n   96           READLN(LING);\n   97 (*2       LINGUAGEM NAO E* COBOL NEK ZIM?                                     *)\n   98           CASE LING OF\n   99              'C','C' : LING := 'C';\n  100              'Z','Z' : LING := 'Z';\n  101 (*2          ASSUME-SE PASCAL COMO LINGUAGEM UTILIZADA                        *)\n  102              OTHERWISE\n  103                 LING := 'P';\n  104              END; (* CASE *)\n  105            END; (* IF *)\n  106 (*2 FIM=-DE-LOSTRA-TELA                                                        *)\n  107 END;    (* MOSTRA TELA *)\n\n\n\fPROGRAMA: COMENT.PAS           DOC.NIVEL  3    DATA:  8-AUG-1988 16:00      PAG:   3\n\n  108\n  109\n  110\n  111 (*1===========================================================================*)\n  112 (*1 ROTINA: CABECALHO;                                                        *)\n  113 (*1 FINALIDACE: IMPRIMIR CABECALHO NO INICIO DE CADA PAGINA DO RELATORIO;     *)\n  114 (*1 IMPORTACOES GLOBAIS: NOME DO ARCGUIVO LIDOs NIVEL DE DOCUMENTACAO,        *)\n  115 (*1                      DATA E HORA ATUAIS;                                  *)\n  116 (*1 SAIDA: LINHA DE CABECALHO IMPRESSA NO ALTO DE CADA PAG. DA LISTAGEM;      *)\n  117 (*1 CHAMADO POR: COMENTARIO;                                                  *)\n  118 (*1===========================================================================*)\n  119 PROCEDURE CABECALHO;\n  120 BEGIN\n  121 (*2 INICIO DE CABECALHO;                                                      *)\n  122 (*2 PAGINA ESTA' CHEIA ?                                                      *)\n  123     IF LINPAG &gt; 57 THEN\n  124         BEGIN\n  125 (*2       ATUALIZA O NUMERO DA PAGINA. 2)                                     *)\n  126           NPAG := NPAG + 1;\n  127 (*2       RELATORIO JA' FOI INICIALIZADO ?                                    *)\n  128           IF NPAG &gt; 1 THEN\n  129 (*2           SALTA PAGINA                                                    *)\n  130               PAGE(SAIDA);\n  131 (*2       ESCREVE LINHA DE CABECALHO;                                         *)\n  132           WRITELN(SAIDA); WRITELN(SAIDA);\n  133           WRITE(SAIDA,'    PROGRAMA: ',NOMEARQ,' ':(22-NOMEARQ.LENGTH));\n  134           WRITE(SAIDA,'DOC.NIVEL ',OPCAO:2,'    DATA: ',DATA_HORA,'      PAG: ',NPAG:4);\n  135           WRITELN(SAIDA); WRITELN(SAIDA);\n  136           LINPAG := 4;\n  137           END; (* IF *)\n  138 (*2 FIM DE CABECALHO;                                                         *)\n  139 END; (* CABECALHO *)\n  140\n  141\n  142 (*1===========================================================================*)\n  143 (*1 ROTINA: RELAT;                                                            *)\n  144 (*1 FINALIDADE: FAZ LEITURA DO ARQUIVO DE ENTRADA (EM COBOL OU ZIM) E MONTA O *)\n  145 (*1             DE SAIDA;                                                     *)\n  146 (*1 IMPORTACOES: CARACTERE QUE IDENTIFICA A LINHA DE COMENTARIO NA LINGUAGEM  *)\n  147 (*1              UTILIZADA (COBOL OU ZIM);                                   *)\n  148 (*1 SAIDA  : COMENTARIOS DO PROGRAMA DE ENTRADA AO NIVEL DESEJADO;            *)\n  149 (*1 CHAMADO POR: COMENTARIO;                                                  *)\n  150 (*1===========================================================================*)\n  151 PROCEDURE RELAT(INI : CARACTERE);\n  152 VAR\n  153     IDENT1, IDENT2 : VARYING[2] OF CHAR;     (* CONTEM IDENTIFICADOR DE NIVEL *)\n  154\n  155 (*2 INICIO DE RELAT;                                                          *)\n  156 BEGIN\n  157     IDENT1 := INI + '1';\n  158     IDENT2 := INI + '2';\n  159 (*2 PARA CADA LINHA DO ARQUIVO DE ENTRADA :                                   *)\n  160     WHILE NOT EOF(ENTRADA) DO\n  161       BEGIN\n\n\n\fPROGRAMA: COMENT.PAS           DOC.NTVEL  3    DATA:  8-AUG-1988 16:00      PAG:   4\n\n  162 (*2     LE LINHA SEQUENCIALMENTE                                              *)\n  163         READLN(ENTRADA,LINPROG);\n  164 (*2     NUMERA A LINHA LIDA                                                   *)\n  165         NUMLIN := NUMLIN + 1;\n  166 (*2     DOCUMENTACAO E' DE NIVEL 3 ?                                          *)\n  167         IF OPCAO = 3 THEN\n  168             BEGIN\n  169 (*2           ESCREVE LINHA NO RELATORIO                                      *)\n  170               LINPAG := LINPAG + 1;\n  171               CABECALHO;\n  172               WRITELN(SAIDA,' ':4,NUMLIN:5,' ',LINPROG);\n  173               END\n  174 (*2       CASO CONTRARIO                                                      *)\n  175           ELSE\n  176             BEGIN\n  177 (*2           LINHA NAO E' NULA ?                                             *)\n  178               IF (LENGTH(LINPROG) &gt; 2) THEN\n  179                   BEGIN\n  180 (*2                 LINHA E' DE COMENTARIO NIVEL 1 ?                          *)\n  181                     IF (SUBSTR(LINPROG,1,2) = IDENT1) THEN\n  182                         BEGIN\n  183                           LINPAG := LINPAG + 1;\n  184                           CABECALHO;\n  185 (*2                       ESCREVE LINHA NO RELATORIO                          *)\n  186                           WRITELN(SAIDA,' ':4,NUMLIN:5,' ',SUBSTR(LINPROG,2,LENGTH(LINPROG)-1));\n  187                         END\n  188 (*2                   CASO CONTRARIO                                          *)\n  189                       ELSE\n  190 (*2                     E' DE COMENTARIO NIVEL 2 E USUARIO QUER NIVEL 2 ?     *)\n  191                         IF ((SUBSTR(LINPROG,1,2) = IDENT2) AND (OPCAO = 2)) THEN\n  192                             BEGIN\n  193                               LINPAG := LINPAG + 1;\n  194                               CABECALHO;\n  195 (*2                           ESCREVE LINHA NO RELATORIO                      *)\n  196                               WRITELN(SAIDA,' ':4,NUMLIN:5,' ',SUBSTR(LINPROG,2,LENGTH(LINPROG)-1));\n  197                               END;\n  198                   END; (* IF *)\n  199               END; (* IF *)\n  200         END; (* WHILE *)\n  201     WRITELN(SAIDA);\n  202 (*2 FIM DE RELAT                                                              *)\n  293 END; (* RELAT *)\n  204\n  205\n  206 (*1===========================================================================*)\n  207 (*1 ROTINA: RELATPAS;                                                         *)\n  208 (*1 FINALIDADE: FAZ LEITURA DO ARQUIVO DE ENTRADA (EM PASCAL) E MONTA O DE    *)\n  209 (*1             SAIDA;                                                        *)\n  210 (*1 SAIDA: COMENTARIOS DO FROGRAMA DE ENTRADA NO NIVEL DESEJADO;              *)\n  211 (*1 CHAMADO POR: COMENTARIO;                                                  *)\n  212 (*1===========================================================================*)\n  213 PROCEDURE RELATPAS;\n  214 (*2 INICIO DE RELATPAS                                                        *)\n  215 BEGIN\n\n\n\fPROGRAMAS COMENT.PAS           DOC.NIVEL  3    DATA:  8-AUG-1988 16:00      PAG:   5\n\n  216 (*2 PARA CADA LINHA DO ARQUIVO DE ENTRADA                                     *)\n  217     WHILE NOT EOF(ENTRADA) DO\n  218       BEGIN\n  219 (*2     LE LINHA SEQUENCIALMENTE                                              *)\n  220         READLN(ENTRADA,LINPROG);\n  221         NUMLIN := NUMLIN + 1;\n  222 (*2     DOCUMENTACAO E' DE NIVEL 3 ?                                          *)\n  223         IF OPCAO = 3 THEN\n  224             BEGIN\n  225 (*2           ESCREVE LINHA NO RELATORIO                                      *)\n  226               LINPAG := LINPAG + 1;\n  221               CABECALHOS\n  228               WRITELN(SAIDAS,' ',:4,NUMLIN:5,' ',LINPROG);\n  229               END\n  230 (*2       CASO CONTRARIO                                                      *)\n  231           ELSE\n  232             BEGIN\n  233 (*2           LINHA NAO Ef NULA 2                                             *)\n  234               IF (LENGTH(LINPROG) &gt; 3) THEN\n  235                   BEGIN\n  236 (*2                 LINHA E' DE COMENTARIO NIVEL 1 ?                          *)\n  237                     IF (SUBSTR(LINPROG,1,3) = '(*1') THEN\n  238                         BEGIN\n  239                           LINPAG := LINPAG + 1;\n  240                           CABECALHO;\n  241 (*2                       ESCREVE LINHA NO RELATORIO                           *)\n  242                           WRITELN(SAIDA,' ':4,NUMLIN:5,' ',SUBSTR(LINPROG,3,INDEX(LINPROG,'*)')-3))\n  243                           END\n  244 (*2                   CASO CONTRARIO                                           *)\n  245                       ELSE\n  246                         BEGIN\n  241 (*2                       E' DE COMENTARIO NIVEL 2 E USUARIO QUER NIVEL 2 ?    *)\n  248                           IF ((SUBSTR(LINPROG,1,3) = '(*2') AND (OPCAO = 2)) THEN\n  249                               BEGIN\n  250                                 LINPAG := LINPAG + 1;\n  251                                 CABECALHO;\n  250 (*2                             ESCREVE LINHA NO RELATORIO                    *)\n  253                                 WRITELN(SAIDA,' ':4,NUMLIN:5,' ',SUBSTR(LINPROG,3,INDEX(LINPROG,'*)')-3));\n  254                                 END;\n  255                           END;\n  256                     END; (* IF *)\n  251               END; (* IF *)\n  258         END; (* WHILE *)\n  259     WRITELN(SAIDA);\n  260 (*2 FIM DE RELATPAS                                                            *)\n  261 END; (* RELATPAS *)\n  262\n  263\n  264 (*2----------------------------------------------------------------------------*)\n  265 (*2                  P R O G R A M A    P R I N C I P A L                      *)\n  266 (*2----------------------------------------------------------------------------*)\n  267 (*2 INICIO DE COMENTARIO                                                       *)\n  268 BEGIN\n  269     OPCAO = 0;\n\n\n\fPROGRAMA: COMENT.PAS           DOC.NIVEL  3    DATA:  8-AUG-1988 16:00      PAG:   6\n\n  270     DATA_HORA := '                 ';\n  271     NUMLIN := 0;\n  272 (*2 EXIBE TELA DE ENTRADA                                                     *)\n  273     MOSTRA_TELA;\n  274 (*2 OPCAO DO USUARIO E' CONTINUAR ?                                           *)\n  275     IF ((OPCAO &gt; 0) AND (OPCAO &lt; 4)) THEN\n  276         BEGIN\n  277 (*2       ABRE ARQUIVOS DE ENTRADA E SATDA                                    *)\n  278           OPEN(ENTRADAS,NOMEARQ,\n  279                HISTORY := OLD,\n  280                ACCESS_METHOD := SEQUENTIAL);\n  281                OPEN(SAIDA,'COMMENT.LIS',HISTORY := NEW);\n  282           RESET(ENTRADA);\n  283           REWRITE((SAIDA);\n  284           RETORNO := SYS$ASCTIM(,DATA_HORA,,);\n  285           (* FORCA A IMPRESSAO DO CABECALHO NA PRIMEIRA PAGINA *)\n  286           LINPAG := 70;\n  287           CABECALHO;\n  288           END; (* IF *)\n  289 (*2 OPCAO DO USUARIO E' NIVEL 1 OU 2 ?                                        *)\n  290     CASE OPCAO OF\n  291       1,2,3 : BEGIN\n  292                 IF (NOMEARQ.LENGTH &gt; 20) THEN\n  293                     NOMEARQ := SUBSTR(NOMEARQ,1,20);\n  294 (*2             ENTRADA ESTA' EM PASCAL ?                                     *)\n  295                 IF (LING = 'P') THEN\n  296 (*2                  PROCESSA ARQUIVO EM PASCAL                               *)\n  297                      RELATPAS\n  298 (*2               CASO CONTRARIO                                              *)\n  299                   ELSE\n  300 (*2                 PROCESSA ARQUIVO EM COBOL OU ZIM                          *)\n  301                     IF (LING = 'C') THEN\n  302                         RELAT('*')\n  303                       ELSE\n  304                         RELAT('%');\n  305 (*              MANDA RELATORIO PARA A FILA DE IMPRESSAO                      *)\n  306 (*              COMANDO := 'PRINT COMMENT.LIS';  *)\n  307 (*              LIB$DO_COMMAND(COMANDO);         *)\n  308                 END; (* 1,2,3 *)\n  309       END; (* CASE *)\n  310 (*2 ALGUM ARGUIVO FOI ABERTO ?                                                *)\n  311     IF ((OPCAO &gt; 0) AND (OPCAO &lt; 4)) THEN\n  312         BEGIN\n  313 (*2       FECHA ARQUIVOS UTILIZADOS                                           *)\n  314           CLOSE(ENTRADA);\n  315           CLOSE(SAIDA);\n  316           END;\n  317 (*2 FIM DE COMENTARTO                                                         *)\n  318 END. (* COMENTARIO *)\n</code></pre>"},{"location":"books/bcomp/bcomp/","title":"Building a Compiler","text":"<p>My personal notes on the book \"A Constru\u00e7\u00e3o de um Compilador\" by Setzer&amp;Melo (in Portuguese). The book is hosted on the Internet Archive, and is also available on the author's page. It is a fundamental work for those who wish to understand the theory and practice of compiler construction. Published in 1989, the book remains current and approaches the subject in a didactic way, covering essential concepts, from lexical analysis to object code generation. It is an excellent reference for students and professionals in the field of computer science, offering a detailed and practical view of developer development.</p>"},{"location":"books/bcomp/bcomp/#parser-extension","title":"Parser extension","text":"<ul> <li>PINTO, T. T. S. GGLL: um gerador de analisadores sint\u00e1ticos para gram\u00e1ticas gr\u00e1ficas LL(1). 2014. Universidade de S\u00e3o Paulo, 2014. DOI: 10.11606/D.45.2014.tde-23012015-075452. Available at: http://www.teses.usp.br/teses/disponiveis/45/45134/tde-23012015-075452/.</li> </ul> <p>Abstract: This work focuses on the development of a top-down parser generator for LL(1) grammars with graphical input of the grammar, as well as a comparison of this generator with other generators in use in the market. As a result, a fully functional generator was obtained, and it was shown how it is superior to other parsers. Implementation details are described and a user manual for the system implemented in Java, independent of programming environments, was prepared.</p> <p>Sources:</p> <ul> <li>https://github.com/tassotirap/GGLL.UI</li> <li>https://github.com/tassotirap/GGLL.Core</li> </ul>"},{"location":"books/bcomp/bcomp/#revision-history","title":"Revision history","text":"<ul> <li>r1.2b - optimization and conversion to PDF/A-2B using: <code>$ ocrmypdf --skip-text --tesseract-timeout=0 --jbig2-lossy --optimize=3 in.pdf out.pdf</code></li> <li>r1.2a - the Initial View Navigation Tab has been changed from Page Only to Bookmarks Panel</li> <li>r1.2 - added Bookmarks</li> <li>r1.1 - OCRed</li> <li>r1.0 - original document scanned</li> </ul>"},{"location":"books/bcomp/bcomp/#references","title":"References","text":"<ul> <li>AHO, A. V.; ULLMAN, J. D. The Theory of Parsing, Translation, and Compiling. Later Printing edition. Englewood Cliffs, N.J: Prentice Hall, 1972. Available at: https://www.google.com.br/books/edition/_/EZImAAAAMAAJ/.</li> <li>BRESSAN, G. Linguagens de Implementa\u00e7\u00e3o de Sistemas e a Linguagem LAPA. 1977. text \u2013 Universidade de S\u00e3o Paulo, 1977. DOI 10.11606/D.45.1977.tde-20230303-172219. Available at: https://teses.usp.br/teses/disponiveis/45/45132/tde-20230303-172219/.</li> <li>FAPESP. Tomasz Kowaltowski - Biblioteca Virtual da FAPESP. [s. d.]. Available at: https://bv.fapesp.br/pt/pesquisador/92611/tomasz-kowaltowski/.</li> <li>GRIES, D. Compiler Construction for Digital Computers. New York: Wiley, 1971. Available at: https://www.google.com.br/books/edition/Compiler_Construction_for_Digital_Comput/CJUEAQAAIAAJ/.</li> <li>HOPCROFT, J. E.; ULLMAN, J. D. Formal languages and their relation to automata. USA: Addison-Wesley Longman Publishing Co., Inc., 1969. Available at: https://dl.acm.org/doi/book/10.5555/1096945.</li> <li>JENSEN, K.; WIRTH, N. PASCAL User Manual and Report. New York: Springer-Verlag, 1974. Available at: https://archive.org/details/h42_Pascal_User_Manual_and_Report_Second_Edition.</li> <li>KNUTH, D. E. The Art of Computer Programming. [S. l.]: Reading, Mass.\u202f: Addison-Wesley, 1997. Available at: http://archive.org/details/artofcomputerpro0001knut_l0h13rdedition.</li> <li>KOWALTOWSKI, T. Implementa\u00e7\u00e3o de linguagens de programa\u00e7\u00e3o. [S. l.]: Guanabara Dois, 1983. Available at: https://scholar.google.com/scholar?cluster=6128347645525656087&amp;hl=en&amp;oi=scholarr.</li> <li>LEWIS, P. M.; STEARNS, R. E. Syntax-Directed Transduction. J. ACM, vol. 15, no. 3, p. 465\u2013488, 1 Jul. 1968. DOI 10.1145/321466.321477. Available at: https://dl.acm.org/doi/10.1145/321466.321477.</li> <li>MELO, I. S. H. de. Alguns t\u00f3picos de compila\u00e7\u00e3o e uma implementa\u00e7\u00e3o da Linguagem Lapa para o Computador Pade. 1978. 1978. Available at: https://bdtd.ibict.br/vufind/Record/USP_25471acc314b810d90b5496267a6b02a.</li> <li>NAUR, P. Revised Report on the Algorithmic Language ALGOL 60. Annual Review in Automatic Programming, vol. 4, p. 217\u2013258, 1964. Available at: https://www.sciencedirect.com/science/article/pii/0066413864900205.</li> <li>RECHENBERG, P. Sackgassenfreie Syntaxanalyse. Elektronische Rechenanlagen, vol. 15, no. 3,4, p. 119-125,170-176, 1973. Available at: https://www.degruyter.com/document/doi/10.1524/itit.1973.15.16.119/pdf.</li> <li>RIPLEY, G. D.; DRUSEIKIS, F. C. Towards a Compiler Error Recovery Effectiveness Rating. Technical Report. Tucson, Arizona: Computer Science Department, The University of Arizona, Apr. 1970. Available at: https://www.amazon.com/Towards-compiler-recovery-effectiveness-rating/dp/B0006XBO2O.</li> <li>ROSENKRANTZ, D. J.; STEARNS, R. E. Properties of Deterministic Top-Down Grammars. Information and Control, vol. 17, no. 3, p. 226\u2013256, 1970. Available at: https://core.ac.uk/download/pdf/82034929.pdf.</li> <li>SALOMAA, A. Theory of Automata. Oxford: Pergamon Press, 1969. Available at: https://archive.org/details/theoryofautomata0000salo.</li> <li>SANCHES, M. M. Portabilidade de Compiladores. 1979. Master\u2019s Thesis \u2013 Instituto de Matem\u00e1tica e Estat\u00edstica da USP, S\u00e3o Paulo, 1979. Available at: https://repositorio.usp.br/item/000711147/.</li> <li>SETZER, V. W. Non-recursive Top-down Syntax Analysis. Software: Practice and Experience, vol. 9, no. 3, p. 237\u2013245, 1979. Available at: https://www.academia.edu/113474332/Non_recursive_top_down_syntax_analysis/.</li> <li>VELOSO, P. A. S. M\u00e1quinas e Linguagens: uma Introdu\u00e7\u00e3o \u00e0 Teoria de Aut\u00f4matos. S\u00e3o Paulo: Escola de Computa\u00e7\u00e3o, Instituto de Matem\u00e1tica e Estat\u00edstica da USP, 1979.</li> <li>WIJNGAARDEN, A. van; OTHERS. Revised Report on the Algorithmic Language ALGOL 68. Acta Informatica, vol. 5, no. 1\u20133, p. 1\u2013236, 1975. Available at: https://archive.org/details/revisedreportona0000unse.</li> <li>WIRTH, N. The Design of a PASCAL Compiler. Software: Practice and Experience, vol. 1, no. 4, p. 309\u2013333, 1971. DOI 10.1002/spe.4380010403. Available at: https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.4380010403.</li> <li>WIRTH, Niklaus. Algorithms + Data Structures = Programs. Englewood Cliffs, New York: Prentice-Hall, 1976. Available at: https://archive.org/details/algorithms-and-data-structures-niklaus-wirth/.</li> <li>WIRTH, Niklaus. On \u201cPASCAL\u201d, Code Generation, and the CDC 6000 Computer, n. STAN-CS-72-257. Stanford, California: Computer Science Department, Stanford University, Feb. 1972. Available at: https://archive.org/download/bitsavers_stanfordcs2576600PASCALFeb72_1515774/STAN-CS-72-257_6600_PASCAL_Feb72_text.pdf.</li> </ul>"},{"location":"blog/archive/2026/","title":"2026","text":""},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/archive/2023/","title":"2023","text":""},{"location":"blog/category/mkdocs/","title":"mkdocs","text":""},{"location":"blog/category/hpc/","title":"HPC","text":""},{"location":"blog/category/fortran/","title":"Fortran","text":""},{"location":"blog/category/linux/","title":"Linux","text":""},{"location":"blog/category/optimization/","title":"Optimization","text":""},{"location":"blog/category/pinn/","title":"PINN","text":""},{"location":"blog/category/ann/","title":"ANN","text":""},{"location":"blog/category/publication/","title":"Publication","text":""},{"location":"blog/category/tools/","title":"Tools","text":""},{"location":"blog/category/internals/","title":"Internals","text":""},{"location":"blog/category/classic/","title":"Classic","text":""},{"location":"blog/category/inpe/","title":"INPE","text":""},{"location":"blog/category/virtualization/","title":"Virtualization","text":""},{"location":"blog/page/2/","title":"Posts","text":""},{"location":"blog/page/3/","title":"Posts","text":""},{"location":"blog/archive/2025/page/2/","title":"2025","text":""},{"location":"blog/archive/2024/page/2/","title":"2024","text":""}]}